# Python and Jupyter Notebook Files Export
# Generated on: 2025-06-27 14:02:14
# Root directory: /Users/n00bcak/programming/AttentionNeuron
# Total files: 28
================================================================================


================================================================================
# File 1/28: agent_interp.ipynb
# Full path: /Users/n00bcak/programming/AttentionNeuron/agent_interp.ipynb
# File type: Jupyter Notebook
================================================================================

import os
import numpy as np
import torch
from pathlib import Path
from IPython.display import HTML
from copy import deepcopy
import numpy as np
import torch
import base64
from PIL import Image
import io
from moviepy.editor import VideoFileClip


# [Markdown Cell]
# ## TODO:
# 1. Look at the attention heads across trajectories.
# 2. Conduct ablation studies on the following components:
#     - Previous Action Signal (always 0??)
#     - LSTM (always 0???)


def load_trajectory_cache(cache_path, video_path):
    if not Path(cache_path).exists():
        raise FileNotFoundError(f"Cache file {cache_path} does not exist.")
    data = torch.load(cache_path, map_location='cpu')

    clip = VideoFileClip(str(video_path))
    fps = clip.fps

    for i in range(len(data)):
        data[i]['video_frame'] = clip.get_frame(i / fps)

    return data

# for cache in [ep_0_cache, ep_1_cache, ep_2_cache]:
#     print(type(cache))
#     print(len(cache))
#     print(cache[0]['pi_layer_activations'].keys())
#     print(cache[0]['net_activations'].keys())
ep_0_cache = load_trajectory_cache(Path('pretrained', 'cartpole_pi_perturb', 'default', 'hook_data', 'hook_data_ep_0.pt'), Path('pretrained', 'cartpole_pi_perturb', 'default', 'videos', 'video_ep_0.mp4'))
print(f"Loaded {len(ep_0_cache)} frames from ep_0_cache")
print(list(map(lambda x: x['permutation'], ep_0_cache[:500])))


# [Markdown Cell]
# ## Attention Heads Over Time


# # Let's plot the attention head over first few timesteps
# import matplotlib.pyplot as plt

# timesteps = 64
# shape = int(np.sqrt(timesteps))
# fig, ax = plt.subplots(figsize=(40, 40), nrows = shape, ncols = shape)
# for ts, cache in enumerate(ep_0_cache[:5 * timesteps:5]):
#     att_mat_tensor = cache['pi_layer_activations']['attention_matrix']
#     obs = np.concatenate([
#         cache['pi_layer_activations']['obs'], 
#         cache['pi_layer_activations']['prev_act']
#     ], axis = 0).squeeze()
#     obs = f'{obs[0]:.3f}, {obs[1]:.3f}, {obs[2]:.3f}, {obs[3]:.3f}'
#     # act = cache['pi_layer_activations']['act']
#     ax[ts // shape, ts % shape].imshow(att_mat_tensor, cmap='viridis', aspect='auto')
#     ax[ts // shape, ts % shape].set_title(f't={ts}, obs={obs}')#, act={cache["act"]}')
#     ax[ts // shape, ts % shape].set_xlabel('Observation Channels')
#     ax[ts // shape, ts % shape].set_ylabel('LSTM State')
#     for i in range(att_mat_tensor.shape[0]):
#         for j in range(att_mat_tensor.shape[1]):
#             ax[ts // shape, ts % shape].text(j, i, f'{att_mat_tensor[i, j]:.2f}', ha='center', va='center', color='white', fontsize=8)
#     ax[ts // shape, ts % shape].axis('off')
# plt.tight_layout()
# plt.show()

# timesteps = 64
# shape = int(np.sqrt(timesteps))
# fig, ax = plt.subplots(figsize=(40, 40), nrows = shape, ncols = shape)
# for ts, cache in enumerate(ep_2_cache[:5 * timesteps:5]):
#     att_mat_tensor = cache['pi_layer_activations']['attention_matrix']
#     obs = np.concatenate([
#         cache['pi_layer_activations']['obs'], 
#         cache['pi_layer_activations']['prev_act']
#     ], axis = 0).squeeze()
#     obs = f'{obs[0]:.3f}, {obs[1]:.3f}, {obs[2]:.3f}, {obs[3]:.3f}'
#     # act = cache['pi_layer_activations']['act']
#     ax[ts // shape, ts % shape].imshow(att_mat_tensor, cmap='viridis', aspect='auto')
#     ax[ts // shape, ts % shape].set_title(f't={ts}, obs={obs}')#, act={cache["act"]}')
#     ax[ts // shape, ts % shape].set_xlabel('Observation Channels')
#     ax[ts // shape, ts % shape].set_ylabel('LSTM State')
#     for i in range(att_mat_tensor.shape[0]):
#         for j in range(att_mat_tensor.shape[1]):
#             ax[ts // shape, ts % shape].text(j, i, f'{att_mat_tensor[i, j]:.2f}', ha='center', va='center', color='white', fontsize=8)
#     ax[ts // shape, ts % shape].axis('off')
# plt.tight_layout()
# plt.show()

# from IPython.display import HTML
# from copy import deepcopy

# def generate_html_slider(caches, labels, timesteps=64):
#     if not (len(caches) and isinstance(caches[0], list)):
#         caches = [caches]  # Ensure caches is a list of lists
#     if not (len(labels) and isinstance(labels, list)):
#         labels = [labels]

#     # Pad the caches to have the same length
#     max_length = max(len(cache) for cache in caches)
#     for i in range(len(caches)):
#         if len(caches[i]) < max_length:
#             # Pad with empty dictionaries if the cache is shorter than max_length
#             caches[i] += [{'pi_layer_activations': {}, 'net_activations': {}} for _ in range(max_length - len(caches[i]))]

#     # Ensure labels match caches
#     if len(labels) != len(caches):
#         labels = [f"Cache {i}" for i in range(len(caches))]
    
#     # Generate HTML
#     html = f"""
#     <!DOCTYPE html>
#     <html>
#     <head>
#         <style>
#             .container {{
#                 display: flex;
#                 flex-direction: column;
#                 align-items: center;
#                 width: 100%;
#             }}
#             .slider-container {{
#                 width: 80%;
#                 margin: 20px;
#             }}
#             .attention-maps {{
#                 display: flex;
#                 flex-wrap: wrap;
#                 justify-content: center;
#             }}
#             .attention-map {{
#                 margin: 10px;
#                 text-align: center;
#             }}
#             .map-container {{
#                 display: grid;
#                 border: 1px solid #ccc;
#                 width: 300px;
#                 height: 300px;
#             }}
#             .map-cell {{
#                 display: flex;
#                 align-items: center;
#                 justify-content: center;
#                 font-size: 12px;
#                 color: white;
#                 text-shadow: 1px 1px 1px black;
#             }}
#             .timestep-info {{
#                 margin-top: 10px;
#                 font-weight: bold;
#             }}
#         </style>
#     </head>
#     <body>
#         <div class="container">
#             <h2>Attention Maps Visualization</h2>
#             <div class="slider-container">
#                 <input type="range" min="0" max="{timesteps - 1}" value="0" class="slider" id="timestepSlider">
#                 <p>Timestep: <span id="timestepValue">0</span></p>
#             </div>
#             <div class="attention-maps" id="attentionMaps">
#             </div>
#         </div>

#         <script>
#             // Store attention data
#             const attentionData = {{}};
            
#             // Create color scale function (from blue to red)
#             function getColor(value) {{
#                 // Scale from -1 to 1
#                 const normalized = (value + 1) / 2;
                
#                 // Blue to green color scale
#                 const r = 0;
#                 const b = Math.floor((1 - normalized) * 255);
#                 const g = Math.floor(normalized * 255);
                
#                 return `rgb(${{r}}, ${{g}}, ${{b}})`;
#             }}
            
#             // Function to update attention maps
#             function updateAttentionMaps(timestep) {{
#                 const container = document.getElementById('attentionMaps');
#                 container.innerHTML = '';
                
#                 Object.keys(attentionData).forEach(label => {{
#                     const data = attentionData[label][timestep];
                    
#                     const mapDiv = document.createElement('div');
#                     mapDiv.className = 'attention-map';
                    
#                     const titleDiv = document.createElement('div');
#                     titleDiv.innerHTML = `<strong>${{label}}</strong>`;
#                     mapDiv.appendChild(titleDiv);
                    
#                     const mapContainer = document.createElement('div');
#                     mapContainer.className = 'map-container';
                    
#                     const matrix = data.matrix;
#                     const rows = matrix.length;
#                     const cols = matrix[0].length;
                    
#                     mapContainer.style.gridTemplateColumns = `repeat(${{cols}}, 1fr)`;
#                     mapContainer.style.gridTemplateRows = `repeat(${{rows}}, 1fr)`;
                    
#                     for (let i = 0; i < rows; i++) {{
#                         for (let j = 0; j < cols; j++) {{
#                             const cell = document.createElement('div');
#                             cell.className = 'map-cell';
#                             cell.textContent = matrix[i][j].toFixed(2);
#                             cell.style.backgroundColor = getColor(matrix[i][j]);
#                             mapContainer.appendChild(cell);
#                         }}
#                     }}
                    
#                     mapDiv.appendChild(mapContainer);
                    
#                     const infoDiv = document.createElement('div');
#                     infoDiv.className = 'timestep-info';
#                     infoDiv.textContent = `Obs: ${{data.obs}}, Act: ${{data.act}}`;
#                     mapDiv.appendChild(infoDiv);
                    
#                     container.appendChild(mapDiv);
#                 }});
#             }}
            
#             // Initialize data
#     """
    
#     dummy_dict = deepcopy(caches[0][0])

#     # Add data for each cache
#     html += "// Attention data\n"
    
#     for c_idx, (cache, label) in enumerate(zip(caches, labels)):
#         print(f"Processing cache for {label} with {len(cache)} timesteps.")
#         html += f"attentionData['{label}'] = ["
        
#         for ts in range(min(timesteps, len(cache))):
#             cache_item = cache[ts]
#             att_mat = cache_item.get('pi_layer_activations', {}).get('attention_matrix', torch.full_like(dummy_dict['pi_layer_activations']['attention_matrix'], fill_value = -1.)).numpy()
            
#             # Get observation values
#             obs = np.concatenate([
#                 cache_item.get('pi_layer_activations', {}).get('obs', torch.zeros_like((dummy_dict['pi_layer_activations']['obs']))).numpy(),
#                 cache_item.get('pi_layer_activations', {}).get('prev_act', torch.zeros_like((dummy_dict['pi_layer_activations']['prev_act']))).numpy()
#             ], axis=0).squeeze()
#             obs_str = ', '.join([f'{o:.3f}' for o in obs])
            
#             # Convert attention matrix to JavaScript array
#             matrix_js = "["
#             for i in range(att_mat.shape[0]):
#                 row = "["
#                 for j in range(att_mat.shape[1]):
#                     row += f"{float(att_mat[i, j]):.4f}"
#                     if j < att_mat.shape[1] - 1:
#                         row += ", "
#                 row += "]"
#                 if i < att_mat.shape[0] - 1:
#                     row += ", "
#                 matrix_js += row
#             matrix_js += "]"

#             act_value = f"{float(cache_item.get('act', np.zeros_like((dummy_dict['act'])))):.4f}"

#             html += f"{{'matrix': {matrix_js}, 'obs': '{obs_str}', 'act': '{act_value}'}}"
#             if ts < min(timesteps, len(cache)) - 1:
#                 html += ", "
        
#         html += "];\n"
    
#     # Complete the HTML with event listener for slider
#     html += """
#             // Set up slider
#             const slider = document.getElementById('timestepSlider');
#             const output = document.getElementById('timestepValue');
            
#             slider.oninput = function() {
#                 const timestep = parseInt(this.value);
#                 output.textContent = timestep;
#                 updateAttentionMaps(timestep);
#             }
            
#             // Initial update
#             updateAttentionMaps(0);
#         </script>
#     </body>
#     </html>
#     """
#     with open("test.html", "w") as f:
#         f.write(html)

# # Generate and display the HTML slider for the first episode
# generate_html_slider([ep_0_cache, ep_1_cache, ep_2_cache], ["Episode 0", "Episode 1", "Episode 2"], timesteps = 1000)
# # generate_html_slider([ep_0_cache], ["Episode 0"], timesteps=64)
# # generate_html_slider(ep_2_cache, "Episode 2", timesteps=64)
# # display(html_slider)

# # Generate like.
# # A MASSIVE number of caches.
# # And cook a HTML file to keep them all.

# EPISODE = 0

# caches = {}
# for row in range(15):
#     caches[f'row_{row}'] = load_trajectory_cache(Path("pretrained", "cartpole_pi_ablate_test", f"ablation_row_{row}", "hook_data", f"hook_data_ep_{EPISODE}.pt"))

# for col in range(4):
#     caches[f'col_{col}'] = load_trajectory_cache(Path("pretrained", "cartpole_pi_ablate_test", f"ablation_col_{col}", "hook_data", f"hook_data_ep_{EPISODE}.pt"))

# generate_html_slider(list(caches.values()), list(caches.keys()), timesteps=1000)

# Data Processing Module
def normalize_caches(caches):
    """Ensure caches is a list of lists with consistent structure."""
    if not (len(caches) and isinstance(caches[0], list)):
        caches = [caches]
    return caches

# def pad_caches_to_same_length(caches):
#     """Pad all caches to have the same length using empty dictionaries."""
#     max_length = max(len(cache) for cache in caches)
#     padded_caches = []
    
#     for cache in caches:
#         padded_cache = cache.copy()
#         if len(padded_cache) < max_length:
#             padding = [
#                 {'pi_layer_activations': {}, 'net_activations': {}} 
#                 for _ in range(max_length - len(padded_cache))
#             ]
#             padded_cache.extend(padding)
#         padded_caches.append(padded_cache)
    
#     return padded_caches

def pad_cache(caches, length = 1000):
    """Pad all caches to have the same length using empty dictionaries."""
    padded_caches = []
    
    for cache in caches:
        padded_cache = cache.copy()
        if len(padded_cache) < length:
            padding = [
                {'pi_layer_activations': {}, 'net_activations': {}} 
                for _ in range(length - len(padded_cache))
            ]
            padded_cache.extend(padding)
        padded_caches.append(padded_cache)
    
    return padded_caches

def generate_labels(caches, provided_labels):
    """Generate appropriate labels for caches."""
    if not (len(provided_labels) and isinstance(provided_labels, list)):
        provided_labels = [provided_labels]
    
    if len(provided_labels) != len(caches):
        return [f"Cache {i}" for i in range(len(caches))]
    
    return provided_labels

# Data Extraction Module
def extract_attention_matrix(cache_item, dummy_dict):
    """Extract attention matrix from cache item with fallback."""
    att_mat = cache_item.get('pi_layer_activations', {}).get(
        'attention_matrix', 
        torch.full_like(dummy_dict['pi_layer_activations']['attention_matrix'], fill_value=-1.)
    ).numpy()

    # Use the permutation information to format the observation data
    # perm = cache_item.get('permutation', np.arange(att_mat.shape[-1]))  # Fallback to identity permutation if not available
    # inv_perm = np.argsort(perm)

    # att_mat = att_mat[:, perm]  # Apply inverse permutation to the attention matrix
    return att_mat

def extract_observation_data(cache_item, dummy_dict):
    """Extract and format observation data."""
    obs = np.concatenate([
        cache_item.get('pi_layer_activations', {}).get(
            'obs', 
            torch.zeros_like(dummy_dict['pi_layer_activations']['obs'])
        ).numpy(),
        cache_item.get('pi_layer_activations', {}).get(
            'prev_act', 
            torch.zeros_like(dummy_dict['pi_layer_activations']['prev_act'])
        ).numpy()
    ], axis=0).squeeze()[:6]
    # assert obs.shape[0] == 6, f"Observation data shape mismatch: {obs.shape}, expected 6 elements."

    # Use the permutation information to format the observation data
    perm = cache_item.get('permutation', np.arange(5))  # Fallback to identity permutation if not available
    inv_perm = np.argsort(perm)
    # assert ((obs[inv_perm])[perm] == obs[:-1]).all(), f"Observation data permutation mismatch: {(obs[inv_perm])[perm]} != {obs[:-1]}, {perm=}, {inv_perm=}, {perm[inv_perm]=}"
    assert perm.shape[0] == 5, f"Permutation data shape mismatch: {perm} {perm.shape}, expected 5 elements."

    obs = np.concatenate([obs[inv_perm], obs[-1:]])  # Ensure the last element is included
    assert obs.shape[0] == 6, f"Observation data shape mismatch: {obs.shape}, expected 6 elements."

    return ', '.join([f'{o:.4f}' for o in obs])

def extract_output_value(cache_item, dummy_dict):
    """Extract output value with fallback."""
    output = cache_item.get('pi_layer_activations', {}).get('output', torch.zeros_like(dummy_dict['pi_layer_activations']['output'])).numpy().squeeze()

    # return ', '.join([f'{o:.4f}' for o in output])
    return output

def extract_action_value(cache_item, dummy_dict):
    """Extract action value with fallback."""
    return f"{float(cache_item.get('act', np.zeros_like(dummy_dict['act']))):.4f}"


def extract_video_frame(cache_item):
    """Extract video frame from cache item if available."""
    return cache_item.get('video_frame', None)

# Video Frame Processing Module
def numpy_to_base64_image(frame_array):
    """Convert numpy array to base64 encoded image string."""
    if frame_array is None:
        return None
    
    # Ensure the array is in the right format (0-255, uint8)
    if frame_array.dtype != np.uint8:
        # Normalize to 0-255 if needed
        if frame_array.max() <= 1.0:
            frame_array = (frame_array * 255).astype(np.uint8)
        else:
            frame_array = frame_array.astype(np.uint8)
    
    # Handle different array shapes
    if len(frame_array.shape) == 3:
        # RGB image
        if frame_array.shape[2] == 3:
            mode = 'RGB'
        elif frame_array.shape[2] == 4:
            mode = 'RGBA'
        else:
            raise ValueError(f"Unsupported number of channels: {frame_array.shape[2]}")
    elif len(frame_array.shape) == 2:
        # Grayscale image
        mode = 'L'
    else:
        raise ValueError(f"Unsupported array shape: {frame_array.shape}")
    
    # Convert to PIL Image
    pil_image = Image.fromarray(frame_array, mode=mode)
    
    # Convert to base64
    buffer = io.BytesIO()
    pil_image.save(buffer, format='PNG')
    img_str = base64.b64encode(buffer.getvalue()).decode()
    
    return f"data:image/png;base64,{img_str}"

# JavaScript Generation Module
def matrix_to_javascript_array(matrix):
    """Convert numpy matrix to JavaScript array string."""

    matrix_js = "["
    for i in range(matrix.shape[0]):
        row = "["
        for j in range(matrix.shape[1]):
            row += f"{float(matrix[i, j]):.4f}"
            if j < matrix.shape[1] - 1:
                row += ", "
        row += "]"
        if i < matrix.shape[0] - 1:
            row += ", "
        matrix_js += row
    matrix_js += "]"
    return matrix_js

def generate_cache_data_js(cache, label, dummy_dict, timesteps):
    """Generate JavaScript data for a single cache."""
    print(f"Processing cache for {label} with {len(cache)} timesteps.")
    
    js_data = f"attentionData['{label}'] = ["
    
    for ts in range(min(timesteps, len(cache))):
        cache_item = cache[ts]
        
        # Extract data using dedicated functions
        att_mat = extract_attention_matrix(cache_item, dummy_dict)
        obs_str = extract_observation_data(cache_item, dummy_dict)
        act_value = extract_action_value(cache_item, dummy_dict)
        output = extract_output_value(cache_item, dummy_dict)
        video_frame = extract_video_frame(cache_item)

        att_mat = np.concatenate([
            att_mat,
            output.reshape(-1, 1)  # Append output as the last column
        ], axis = 1)
        
        # Convert to JavaScript format
        matrix_js = matrix_to_javascript_array(att_mat)
        
        # Convert video frame to base64 if available
        frame_data = "null"
        if video_frame is not None:
            base64_image = numpy_to_base64_image(video_frame)
            if base64_image:
                frame_data = f"'{base64_image}'"
        
        js_data += f"{{'matrix': {matrix_js}, 'obs': '{obs_str}', 'act': '{act_value}', 'video_frame': {frame_data}, 'perm': '{cache_item.get('permutation', np.arange(att_mat.shape[-1]))}'}}"
        if ts < min(timesteps, len(cache)) - 1:
            js_data += ", "
    
    js_data += "];\n"
    return js_data

# HTML Template Module
def get_html_template(timesteps):
    """Generate the HTML template with CSS and basic structure."""
    return f"""
    <!DOCTYPE html>
    <html>
    <head>
        <style>
            .container {{
                display: flex;
                flex-direction: column;
                align-items: center;
                width: 100%;
                padding: 20px;
            }}
            .controls-container {{
                width: 80%;
                margin: 20px;
                text-align: center;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                border-radius: 15px;
                padding: 20px;
                box-shadow: 0 4px 15px rgba(0,0,0,0.2);
            }}
            .slider-section {{
                margin-bottom: 20px;
            }}
            .slider {{
                width: 100%;
                height: 8px;
                border-radius: 5px;
                background: rgba(255,255,255,0.3);
                outline: none;
                margin: 10px 0;
            }}
            .slider::-webkit-slider-thumb {{
                appearance: none;
                width: 20px;
                height: 20px;
                border-radius: 50%;
                background: #fff;
                cursor: pointer;
                box-shadow: 0 2px 5px rgba(0,0,0,0.3);
            }}
            .timestep-display {{
                color: white;
                font-size: 18px;
                font-weight: bold;
                margin: 10px 0;
            }}
            .play-controls {{
                display: flex;
                justify-content: center;
                align-items: center;
                gap: 15px;
                margin-top: 15px;
            }}
            .play-btn, .speed-btn {{
                background: rgba(255,255,255,0.2);
                border: 2px solid rgba(255,255,255,0.5);
                border-radius: 8px;
                color: white;
                padding: 10px 20px;
                cursor: pointer;
                font-size: 16px;
                font-weight: bold;
                transition: all 0.3s ease;
                backdrop-filter: blur(10px);
            }}
            .play-btn:hover, .speed-btn:hover {{
                background: rgba(255,255,255,0.3);
                border-color: rgba(255,255,255,0.8);
                transform: translateY(-2px);
            }}
            .play-btn.playing {{
                background: rgba(255,0,0,0.3);
                border-color: rgba(255,0,0,0.8);
            }}
            .speed-display {{
                color: white;
                font-size: 14px;
                min-width: 60px;
            }}
            .loading-indicator {{
                color: white;
                font-size: 14px;
                margin-top: 10px;
                display: none;
            }}
            .loading-indicator.show {{
                display: block;
            }}
            .attention-table {{
                border-collapse: collapse;
                margin: 20px 0;
                width: 100%;
                max-width: 1400px;
                background: white;
                border-radius: 10px;
                overflow: hidden;
                box-shadow: 0 4px 15px rgba(0,0,0,0.1);
            }}
            .attention-table th, .attention-table td {{
                border: 1px solid #ddd;
                padding: 15px;
                text-align: center;
                vertical-align: top;
            }}
            .attention-table th {{
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
                font-weight: bold;
                font-size: 16px;
            }}
            .cache-row {{
                width: 50px
                background-color: #fafafa;
                transition: background-color 0.3s ease;
            }}
            .cache-row:nth-child(even) {{
                background-color: #f5f5f5;
            }}
            .cache-row:hover {{
                background-color: #e8f4f8;
            }}
            .attention-content {{
                display: flex;
                align-items: flex-start;
                justify-content: center;
                gap: 10px;
            }}
            .attention-map {{
                text-align: center;
            }}
            .map-container {{
                display: grid;
                border: 2px solid #ddd;
                border-radius: 8px;
                width: 400px;
                height: 300px;
                margin: 0 auto;
                overflow: hidden;
                box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            }}
            .map-cell {{
                display: flex;
                align-items: center;
                justify-content: center;
                font-size: 10px;
                color: white;
                text-shadow: 1px 1px 1px black;
                font-weight: bold;
            }}
            .video-frame {{
                text-align: center;
            }}
            .video-frame img {{
                max-width: 250px;
                max-height: 250px;
                border: 2px solid #ddd;
                border-radius: 8px;
                box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            }}
            .info-section {{
                margin-top: 10px;
                font-size: 16px;
                max-width: 400px;
                word-wrap: break-word;
                background: #f8f9fa;
                padding: 10px;
                border-radius: 8px;
            }}
            .timestep-info {{
                font-weight: bold;
                margin-bottom: 5px;
                color: #495057;
            }}
            .cache-label {{
                font-size: 16px;
                font-weight: bold;
                color: #495057;
            }}
            .timestep-tables {{
                width: 100%;
                max-width: 1400px;
            }}
            .timestep-table {{
                display: none;
            }}
            .timestep-table.active {{
                display: block;
            }}
        </style>
    </head>
    <body>
        <div class="container">
            <h2 style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); -webkit-background-clip: text; -webkit-text-fill-color: transparent; font-size: 32px; margin-bottom: 30px;">Attention Maps Visualization</h2>
            
            <div class="controls-container">
                <div class="slider-section">
                    <input type="range" min="0" max="{timesteps - 1}" value="0" class="slider" id="timestepSlider">
                    <div class="timestep-display">Timestep: <span id="timestepValue">0</span> / {timesteps - 1}</div>
                </div>
                
                <div class="play-controls">
                    <button class="play-btn" id="playBtn">▶ Play</button>
                    <button class="speed-btn" id="speedBtn">1x</button>
                    <div class="speed-display">Speed: <span id="speedValue">5x</span></div>
                </div>
                
                <div class="loading-indicator" id="loadingIndicator">
                    <div>⏳ Pre-loading all timesteps...</div>
                    <div id="loadingProgress">0%</div>
                </div>
            </div>
            
            <div class="timestep-tables" id="timestepTables">
                <!-- Tables will be pre-generated here -->
            </div>
        </div>

        <script>
            // Store attention data and pre-built tables
            const attentionData = {{}};
            let prebuiltTables = {{}};
            let currentTimestep = 0;
            let isPlaying = false;
            let playInterval = null;
            let playSpeed = 5;
            const speedOptions = [1, 2.5, 5, 10, 25];
            let currentSpeedIndex = 2; // Start at 5 FPS
            const maxTimesteps = {timesteps};
            
            // Create color scale function (from blue to green)
            function getColor(value) {{
                // Scale from -1 to 1
                const normalized = (value + 1) / 2;
                
                // Blue to green color scale
                const r = 0;
                const b = Math.floor((1 - normalized) * 255);
                const g = Math.floor(normalized * 255);
                
                return `rgb(${{r}}, ${{g}}, ${{b}})`;
            }}
            
            // Function to create a table for a specific timestep
            function createTimestepTable(timestep) {{
                const table = document.createElement('table');
                table.className = 'attention-table timestep-table';
                table.id = `table-${{timestep}}`;
                
                // Create header
                const thead = document.createElement('thead');
                const headerRow = document.createElement('tr');
                ['Cache', 'Attention Map', 'Video Frame', 'Info'].forEach(header => {{
                    const th = document.createElement('th');
                    th.textContent = header;
                    headerRow.appendChild(th);
                }});
                thead.appendChild(headerRow);
                table.appendChild(thead);
                
                // Create body
                const tbody = document.createElement('tbody');
                
                Object.keys(attentionData).forEach(label => {{
                    const data = attentionData[label][timestep];
                    
                    // Create table row
                    const row = document.createElement('tr');
                    row.className = 'cache-row';
                    
                    // Cache label cell
                    const labelCell = document.createElement('td');
                    labelCell.innerHTML = `<div class="cache-label">${{label}}</div>`;
                    row.appendChild(labelCell);
                    
                    // Attention map cell
                    const mapCell = document.createElement('td');
                    const mapDiv = document.createElement('div');
                    mapDiv.className = 'attention-map';
                    
                    const mapContainer = document.createElement('div');
                    mapContainer.className = 'map-container';
                    
                    const matrix = data.matrix;
                    const rows = matrix.length;
                    const cols = matrix[0].length;
                    
                    mapContainer.style.gridTemplateColumns = `repeat(${{cols}}, 1fr)`;
                    mapContainer.style.gridTemplateRows = `repeat(${{rows}}, 1fr)`;
                    
                    for (let i = 0; i < rows; i++) {{
                        for (let j = 0; j < cols; j++) {{
                            const cell = document.createElement('div');
                            cell.className = 'map-cell';
                            cell.textContent = matrix[i][j].toFixed(2);
                            cell.style.backgroundColor = getColor(matrix[i][j]);
                            mapContainer.appendChild(cell);
                        }}
                    }}
                    
                    mapDiv.appendChild(mapContainer);
                    mapCell.appendChild(mapDiv);
                    row.appendChild(mapCell);
                    
                    // Video frame cell
                    const frameCell = document.createElement('td');
                    if (data.video_frame && data.video_frame !== null) {{
                        const frameDiv = document.createElement('div');
                        frameDiv.className = 'video-frame';
                        const img = document.createElement('img');
                        img.src = data.video_frame;
                        img.alt = 'Video Frame';
                        frameDiv.appendChild(img);
                        frameCell.appendChild(frameDiv);
                    }} else {{
                        frameCell.innerHTML = '<em>No video frame</em>';
                    }}
                    row.appendChild(frameCell);
                    
                    // Info cell
                    const infoCell = document.createElement('td');
                    const infoDiv = document.createElement('div');
                    infoDiv.className = 'info-section';
                    
                    const timestepInfo = document.createElement('div');
                    timestepInfo.className = 'timestep-info';
                    timestepInfo.textContent = `Timestep: ${{timestep}}`;
                    infoDiv.appendChild(timestepInfo);
                    
                    const obsInfo = document.createElement('div');
                    obsInfo.innerHTML = `<strong>Obs:</strong> ${{data.obs}}`;
                    infoDiv.appendChild(obsInfo);

                    const actInfo = document.createElement('div');
                    actInfo.innerHTML = `<strong>Act:</strong> ${{data.act}}`;
                    infoDiv.appendChild(actInfo);

                    const permInfo = document.createElement('div');
                    permInfo.innerHTML = `<strong>Perm:</strong> ${{data.perm}}`;
                    infoDiv.appendChild(permInfo);
                    
                    infoCell.appendChild(infoDiv);
                    row.appendChild(infoCell);
                    
                    tbody.appendChild(row);
                }});
                
                table.appendChild(tbody);
                return table;
            }}
            
            // Function to show specific timestep
            function showTimestep(timestep) {{
                // Hide all tables
                Object.values(prebuiltTables).forEach(table => {{
                    table.classList.remove('active');
                }});
                
                // Show target table
                if (prebuiltTables[timestep]) {{
                    prebuiltTables[timestep].classList.add('active');
                }}
                
                // Update slider and display
                document.getElementById('timestepSlider').value = timestep;
                document.getElementById('timestepValue').textContent = timestep;
                currentTimestep = timestep;
            }}
            
            // Pre-build all tables
            function preloadAllTables() {{
                const loadingIndicator = document.getElementById('loadingIndicator');
                const loadingProgress = document.getElementById('loadingProgress');
                const tablesContainer = document.getElementById('timestepTables');
                
                loadingIndicator.classList.add('show');
                
                for (let i = 0; i < maxTimesteps; i++) {{
                    setTimeout(() => {{
                        const table = createTimestepTable(i);
                        prebuiltTables[i] = table;
                        tablesContainer.appendChild(table);
                        
                        const progress = Math.round(((i + 1) / maxTimesteps) * 100);
                        loadingProgress.textContent = `${{progress}}%`;
                        
                        if (i === 0) {{
                            showTimestep(0);
                        }}
                        
                        if (i === maxTimesteps - 1) {{
                            loadingIndicator.classList.remove('show');
                        }}
                    }}, i * 10); // Small delay to prevent UI blocking
                }}
            }}
            
            // Play functionality
            function togglePlay() {{
                const playBtn = document.getElementById('playBtn');
                
                if (isPlaying) {{
                    // Stop playing
                    clearInterval(playInterval);
                    isPlaying = false;
                    playBtn.textContent = '▶ Play';
                    playBtn.classList.remove('playing');
                }} else {{
                    // Start playing
                    isPlaying = true;
                    playBtn.textContent = '⏸ Pause';
                    playBtn.classList.add('playing');
                    
                    playInterval = setInterval(() => {{
                        if (currentTimestep >= maxTimesteps - 1) {{
                            currentTimestep = 0;
                        }} else {{
                            currentTimestep++;
                        }}
                        showTimestep(currentTimestep);
                    }}, 1000 / playSpeed);
                }}
            }}
            
            // Speed control
            function changeSpeed() {{
                currentSpeedIndex = (currentSpeedIndex + 1) % speedOptions.length;
                playSpeed = speedOptions[currentSpeedIndex];
                document.getElementById('speedValue').textContent = `${{playSpeed}}x`;
                
                // Restart interval if playing
                if (isPlaying) {{
                    clearInterval(playInterval);
                    playInterval = setInterval(() => {{
                        if (currentTimestep >= maxTimesteps - 1) {{
                            currentTimestep = 0;
                        }} else {{
                            currentTimestep++;
                        }}
                        showTimestep(currentTimestep);
                    }}, 1000 / playSpeed);
                }}
            }}
            
            // Initialize data
    """

def get_html_footer():
    """Generate the HTML footer with event handlers."""
    return """
            // Set up event listeners
            document.getElementById('timestepSlider').addEventListener('input', function() {
                const timestep = parseInt(this.value);
                showTimestep(timestep);
                
                // Stop playing if user manually changes timestep
                if (isPlaying) {
                    togglePlay();
                }
            });
            
            document.getElementById('playBtn').addEventListener('click', togglePlay);
            document.getElementById('speedBtn').addEventListener('click', changeSpeed);
            
            // Keyboard controls
            document.addEventListener('keydown', function(e) {
                switch(e.key) {
                    case ' ':
                        e.preventDefault();
                        togglePlay();
                        break;
                    case 'ArrowLeft':
                        e.preventDefault();
                        if (currentTimestep > 0) {
                            showTimestep(currentTimestep - 1);
                        }
                        break;
                    case 'ArrowRight':
                        e.preventDefault();
                        if (currentTimestep < maxTimesteps - 1) {
                            showTimestep(currentTimestep + 1);
                        }
                        break;
                }
            });
            
            // Start preloading after data is loaded
            setTimeout(preloadAllTables, 100);
        </script>
    </body>
    </html>
    """

# File I/O Module
def save_html_to_file(html_content, filename="test.html"):
    """Save HTML content to file."""
    with open(filename, "w") as f:
        f.write(html_content)

# # Main Orchestration Function
# def generate_html_slider(caches, labels, timesteps=64, output_file="test.html"):
#     """
#     Generate an interactive HTML slider for visualizing attention maps with video frames.
    
#     Args:
#         caches: List of cache data or single cache
#         labels: List of labels or single label
#         timesteps: Number of timesteps to include
#         output_file: Output HTML filename
#     """
#     # Data preprocessing
#     caches = normalize_caches(caches)
#     caches = pad_caches_to_same_length(caches)
#     labels = generate_labels(caches, labels)
    
#     # Generate HTML template
#     html = get_html_template(timesteps)
    
#     # Create dummy template for fallback values
#     dummy_dict = deepcopy(caches[0][0])
    
#     # Generate JavaScript data for each cache
#     html += "// Attention data\n"
#     for cache, label in zip(caches, labels):
#         html += generate_cache_data_js(cache, label, dummy_dict, timesteps)
    
#     # Add HTML footer
#     html += get_html_footer()
    
#     # Save to file
#     save_html_to_file(html, output_file)
    
#     return html

# ep_cache = []
# for i in range(30):
#     ep_cache.append(load_trajectory_cache(Path("pretrained", "cartpole_pi_clean", "default", "hook_data", f"hook_data_ep_{i}.pt")))

# # Generate and display the HTML slider for multiple episodes
# generate_html_slider(
#     ep_cache,
#     [f"Episode {i}" for i in range(30)],
#     timesteps=1000,
#     output_file="lstm_ablate.html"
# )


# Main Orchestration Function
def generate_html_slider(paths, video_paths, labels, timesteps=64, output_file="test.html"):
    """
    Generate an interactive HTML slider for visualizing attention maps with video frames.
    
    Args:
        paths: List of cache data or single cache
        labels: List of labels or single label
        timesteps: Number of timesteps to include
        output_file: Output HTML filename
    """
    
    # Generate HTML template and dummy dictionary.
    html = [get_html_template(timesteps)]
    dummy_dict = None

    # To save memory, we load each cache sequentially.
    for i, (path, v_path, label) in enumerate(zip(paths, video_paths, labels)):
        cache = load_trajectory_cache(path, video_path = v_path)
        if dummy_dict is None:
            dummy_dict = deepcopy(cache[0])
            # print(dummy_dict.keys())

        # Normalize and pad the cache
        cache = normalize_caches(cache)
        # Pad the cache to 1000 steps.
        cache = pad_cache(cache)[0]
        
        # Generate JavaScript data for each cache
        html.append("// Attention data\n")
        html.append(generate_cache_data_js(cache, label, dummy_dict, timesteps))

        # Once done, delete cache.
        del cache
    
    # Add HTML footer
    html.append(get_html_footer())
    html = ''.join(html)

    # Save to file
    save_html_to_file(html, output_file)

# generate_html_slider(
#     # paths = [Path(
#     #         "pretrained", "cartpole_pi_ablate_test", f"ablation_row_{i}", "hook_data", f"hook_data_ep_0.pt"
#     #     ) 
#     #     for i in range(15)
#     # ] + [Path(
#     #     "pretrained", "cartpole_pi_ablate_test", f"ablation_col_{i}", "hook_data", f"hook_data_ep_0.pt") for i in range(4)],
#     paths = [
#         Path(
#             "pretrained", "cartpole_pi_clean", "default", "hook_data", f"hook_data_ep_{i}.pt"
#         ) for i in range(30)
#     ],
#     video_paths = [
#         Path(
#             "pretrained", "cartpole_pi_clean", "default", "videos", f"video_ep_{i}.mp4"
#         ) for i in range(30)
#     ],
#     labels=[f"Episode {i}" for i in range(30)],
#     timesteps=1000,
#     # output_file="lstm_ablate.html"
# )


generate_html_slider(
    paths = sum([[
        Path(
                "pretrained", "cartpole_pi_clean", "default", "hook_data", f"hook_data_ep_{ep}.pt"
            ),
        Path(
            "pretrained", "cartpole_pi_perturb", "default", "hook_data", f"hook_data_ep_{ep}.pt"
        )
    ] for ep in range(10)], []),
    video_paths = sum([[
        Path(
                "pretrained", "cartpole_pi_clean", "default", "videos", f"video_ep_{ep}.mp4"
            ),
        Path(
            "pretrained", "cartpole_pi_perturb", "default", "videos", f"video_ep_{ep}.mp4"
        )
    ] for ep in range(10)], []),
    labels=sum([[f"Clean Episode {i}", f"Perturbed Episode {i}"] for i in range(10)], []),
    timesteps=1000,
    output_file="dashboards/perturb.html"
)


generate_html_slider(
    paths = sum([[
        Path(
                "pretrained", "cartpole_pi_ablate_lstm", "default", "hook_data", f"hook_data_ep_{ep}.pt"
            ),
        Path(
            "pretrained", "cartpole_pi_ablate_lstm_perturb", "default", "hook_data", f"hook_data_ep_{ep}.pt"
        )
    ] for ep in range(20)], []),
    video_paths = sum([[
        Path(
                "pretrained", "cartpole_pi_ablate_lstm", "default", "videos", f"video_ep_{ep}.mp4"
            ),
        Path(
            "pretrained", "cartpole_pi_ablate_lstm_perturb", "default", "videos", f"video_ep_{ep}.mp4"
        )
    ] for ep in range(20)], []),
    labels=sum([[f"Clean Episode {i}", f"Perturbed Episode {i}"] for i in range(20)], []),
    timesteps=1000,
    output_file="dashboards/ablate_lstm_perturb.html"
)

generate_html_slider(
    paths = sum([[
        Path(
            "pretrained", "cartpole_pi_clean", "default", "hook_data", f"hook_data_ep_{ep}.pt"
        ),
        Path(
            "pretrained", "cartpole_pi_perturb", "default", "hook_data", f"hook_data_ep_{ep}.pt"
        ),
        Path(
            "pretrained", "cartpole_pi_perturb_shuffle_hs", "default", "hook_data", f"hook_data_ep_{ep}.pt"
        ),
        Path(
            "pretrained", "cartpole_pi_perturb_zero_hs", "default", "hook_data", f"hook_data_ep_{ep}.pt"
        ),
        
    ] for ep in range(10)], []),
    video_paths = sum([[
        Path(
            "pretrained", "cartpole_pi_clean", "default", "videos", f"video_ep_{ep}.mp4"
        ),
        Path(
            "pretrained", "cartpole_pi_perturb", "default", "videos", f"video_ep_{ep}.mp4"
        ),
        Path(
            "pretrained", "cartpole_pi_perturb_shuffle_hs", "default", "videos", f"video_ep_{ep}.mp4"
        ),
        Path(
            "pretrained", "cartpole_pi_perturb_zero_hs", "default", "videos", f"video_ep_{ep}.mp4"
        ),
    ] for ep in range(10)], []),
    labels=sum([[f"Clean Ep {i}", f"Perturb Ep {i}", f"Perturb (Shuffle) Ep {i}", f"Perturb (Zero) Ep {i}"] for i in range(10)], []),
    timesteps=1000,
    output_file="dashboards/perturb.html"
)


generate_html_slider(
    paths = sum([[
        Path(
                "pretrained", "cartpole_pi_clean", "default", "hook_data", f"hook_data_ep_{ep}.pt"
            ),
        Path(
            "pretrained", "cartpole_pi_left_horz_pole", "default", "hook_data", f"hook_data_ep_{ep}.pt"
        ),
        Path(
            "pretrained", "cartpole_pi_left_horz_pole_1", "default", "hook_data", f"hook_data_ep_{ep}.pt"
        ),
        Path(
            "pretrained", "cartpole_pi_left_horz_pole_mean", "default", "hook_data", f"hook_data_ep_{ep}.pt"
        ),
        
    ] for ep in range(10)], []),
    video_paths = sum([[
        Path(
                "pretrained", "cartpole_pi_clean", "default", "videos", f"video_ep_{ep}.mp4"
            ),
        Path(
            "pretrained", "cartpole_pi_left_horz_pole", "default", "videos", f"video_ep_{ep}.mp4"
        ),
        Path(
            "pretrained", "cartpole_pi_left_horz_pole_1", "default", "videos", f"video_ep_{ep}.mp4"
        ),
        Path(
            "pretrained", "cartpole_pi_left_horz_pole_mean", "default", "videos", f"video_ep_{ep}.mp4"
        ),
    ] for ep in range(10)], []),
    labels=sum([[f"Clean Ep {i}", f"Feat (4,0) = -1: Ep {i}", f"Feat (4,0) = 1: Ep {i}", f"Feat (4,0) = Mean: Ep {i}"] for i in range(10)], []),
    timesteps=1000,
    output_file="dashboards/left_horz_pole.html"
)

generate_html_slider(
    paths = sum([[
        Path(
            "pretrained", "cartpole_pi_GOLEFT", "default", "hook_data", f"hook_data_ep_{ep}.pt"
        ),
    ] for ep in range(10)], []),
    video_paths = sum([[
        Path(
            "pretrained", "cartpole_pi_GOLEFT", "default", "videos", f"video_ep_{ep}.mp4"
        ),
    ] for ep in range(10)], []),
    labels=sum([[f"GOLEFT Ep {i}"] for i in range(10)], []),
    timesteps=1000,
    output_file="dashboards/GOLEFT.html"
)

generate_html_slider(
    paths = sum([[
        Path(
                "pretrained", "cartpole_pi_clean", "default", "hook_data", f"hook_data_ep_{ep}.pt"
            ),
        Path(
            "pretrained", "cartpole_pi_GOLEFT", "default", "hook_data", f"hook_data_ep_{ep}.pt"
        ),
        
    ] for ep in range(10)], []),
    video_paths = sum([[
        Path(
                "pretrained", "cartpole_pi_clean", "default", "videos", f"video_ep_{ep}.mp4"
            ),
        Path(
            "pretrained", "cartpole_pi_GOLEFT", "default", "videos", f"video_ep_{ep}.mp4"
        ),
    ] for ep in range(10)], []),
    labels=sum([[f"Clean Ep {i}", f"GOLEFT Ep {i}"] for i in range(10)], []),
    timesteps=1000,
    output_file="dashboards/GOLEFT.html"
)

from tqdm import tqdm
for ep in tqdm(range(20)):
    generate_html_slider(
        paths = [Path(
                        "pretrained", "cartpole_pi_clean", "default", "hook_data", f"hook_data_ep_{ep}.pt"
                    )
                ] + [Path(
                        "pretrained", "cartpole_pi_ablate_test", f"ablation_col_{i}", "hook_data", f"hook_data_ep_{ep}.pt"
                    ) for i in range(5)
                ],
        video_paths = [Path(
                        "pretrained", "cartpole_pi_clean", "default", "videos", f"video_ep_{ep}.mp4"
                    )
                ] + [Path(
                        "pretrained", "cartpole_pi_ablate_test", f"ablation_col_{i}", "videos", f"video_ep_{ep}.mp4"
                    ) for i in range(5)],
        labels=[
            f"Clean_ep_{ep}"
        ] + [
            f"Ablation Column {i}_ep_{ep}" for i in range(5)
        ],
        timesteps=1000,
        output_file=f"dashboards/col_ablations_episode_{ep}.html"
    )

from tqdm import tqdm
for ep in tqdm(range(20)):
    generate_html_slider(
        paths = [Path(
                        "pretrained", "cartpole_pi_ablate_lstm", "default", "hook_data", f"hook_data_ep_{ep}.pt"
                    )
                ] + [Path(
                        "pretrained", "cartpole_pi_ablate_lstm_rc", f"ablation_col_{i}", "hook_data", f"hook_data_ep_{ep}.pt"
                    ) for i in range(5)
                ],
        video_paths = [Path(
                        "pretrained", "cartpole_pi_ablate_lstm", "default", "videos", f"video_ep_{ep}.mp4"
                    )
                ] + [Path(
                        "pretrained", "cartpole_pi_ablate_lstm_rc", f"ablation_col_{i}", "videos", f"video_ep_{ep}.mp4"
                    ) for i in range(5)],
        labels=[
            f"Clean_NO_LSTM_ep_{ep}"
        ] + [
            f"Ablation Column {i}_ep_{ep}" for i in range(5)
        ],
        timesteps=1000,
        output_file=f"dashboards/col_ablations_nolstm_episode_{ep}.html"
    )

from tqdm import tqdm
for ep in tqdm(range(20)):
    generate_html_slider(
        paths = [Path(
                        "pretrained", "cartpole_pi_ablate_lstm", "default", "hook_data", f"hook_data_ep_{ep}.pt"
                    )
                ] + [Path(
                        "pretrained", "cartpole_pi_ablate_lstm_rc", f"ablation_row_{i}", "hook_data", f"hook_data_ep_{ep}.pt"
                    ) for i in range(16)
                ],
        video_paths = [Path(
                        "pretrained", "cartpole_pi_ablate_lstm", "default", "videos", f"video_ep_{ep}.mp4"
                    )
                ] + [Path(
                        "pretrained", "cartpole_pi_ablate_lstm_rc", f"ablation_row_{i}", "videos", f"video_ep_{ep}.mp4"
                    ) for i in range(16)],
        labels=[
            f"Clean_NO_LSTM_ep_{ep}"
        ] + [
            f"Ablation Row {i}_ep_{ep}" for i in range(16)
        ],
        timesteps=1000,
        output_file=f"dashboards/row_ablations_nolstm_episode_{ep}.html"
    )


# [Markdown Cell]
# ## Permutation Robustness


# Seeds from random.org
# 3361	2721	1577	2712	6896	498	9531	9588	2926	777
from itertools import product
import argparse
import eval_agent_with_hooks
import pandas as pd
import seaborn
import gin

SEEDS = [42] #[3361, 2721, 1577, 2712, 6896, 498, 9531, 9588, 2926, 777]
DEFAULT_ARGS = {
    'log_dir': None,
    'model_filename': 'model.npz',
    'n_episodes': 30,
    'seed': 1,
    'prefix': 'default',
    'pos': 2,
    'dim': 0,
}

# Parameters:
# Permutation Frequency: [500, 333, 250, 200, 167, 143] (Approximately harmonic)
# Strategy: [As-is, Shuffle, Zero]

results = []

for seed in SEEDS:
    args = DEFAULT_ARGS
    args.update({
        'log_dir': str(Path("pretrained", f"cartpole_pi_clean")),
        'prefix': f'rigormaxx_{seed}',
        'seed': seed,
    })

    args = argparse.Namespace(**args)
    print(args)
    gin.parse_config_file(os.path.join(args.log_dir, 'config.gin'))
    mean, sdom = eval_agent_with_hooks.main(args)
    results.append({'freq': None, 'strat': 'clean', 'seed': seed, 'mean': mean, 'sdom': sdom})

# Parameters:
# Permutation Frequency: [500, 333, 250, 200, 167, 143] (Approximately harmonic)
# Strategy: [As-is, Shuffle, Zero]
model_path = Path("pretrained", "cartpole_pi_clean", "model.npz")

experiment_params = list(product(
    [500, 333, 250, 200, 167, 143],
    ["perturb", "perturb_shuffle_hs", "perturb_zero_hs"],
    SEEDS
))

gin_template = lambda freq, strat: f"""
import util
import solutions.torch_solutions
import tasks.rl_tasks


# Solution configurations
torch_solutions.HookedPIFCSolution.act_dim = 1
torch_solutions.HookedPIFCSolution.hidden_dim = 16
torch_solutions.HookedPIFCSolution.msg_dim = 32
torch_solutions.HookedPIFCSolution.pos_em_dim = 8
torch_solutions.HookedPIFCSolution.num_hidden_layers = 0
torch_solutions.HookedPIFCSolution.pi_layer_bias = False
torch_solutions.HookedPIFCSolution.pi_layer_scale = False
util.create_solution.solution_loader = @torch_solutions.HookedPIFCSolution


# Task configurations
rl_tasks.CartPoleSwingUpRandPermuteTask.num_noise_channels = 0
rl_tasks.CartPoleSwingUpRandPermuteTask.shuffle_on_reset = True
rl_tasks.CartPoleSwingUpRandPermuteTask.render_mode = 'rgb_array'
rl_tasks.CartPoleSwingUpRandPermuteTask.v = True
rl_tasks.CartPoleSwingUpRandPermuteTask.permute_freq = {freq}
rl_tasks.CartPoleSwingUpRandPermuteTask.shuffle_hs_on_permute = {"shuffle" in strat}
rl_tasks.CartPoleSwingUpRandPermuteTask.zero_hs_on_permute = {"zero" in strat}
util.create_task.task_loader = @rl_tasks.CartPoleSwingUpRandPermuteTask()
"""

perturbed_results = []

for freq, strat, seed in tqdm(experiment_params):
    gin_str = gin_template(freq, strat)
    gin_dirname = f"cartpole_pi_{strat}"
    gin_path = Path("pretrained", gin_dirname, f"gin_{freq}_{strat}.gin")
    gin_path.parent.mkdir(parents=True, exist_ok=True)
    with open(gin_path, "w") as f:
        f.write(gin_str)
    os.copy(model_path, gin_path.parent / "model.npz")

    args = DEFAULT_ARGS
    args.update({
        'log-dir': gin_dirname,
        'seed': seed,
        'n-episodes': 30,
    })

    args = argparse.Namespace(**args)
    print(args)
    gin.parse_config_file(os.path.join(args.log_dir, 'config.gin'))
    mean, sdom = eval_agent_with_hooks.main(args)
    perturbed_results.append({'freq': freq, 'strat': strat, 'seed': seed, 'mean': mean, 'sdom': sdom})

print(results)

================================================================================
# End of file: agent_interp.ipynb
================================================================================


================================================================================
# File 2/28: ant_bc_collect_data.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/ant_bc_collect_data.py
# File type: Python
================================================================================

import gin
import os
import util
import numpy as np
import gym


def main(log_dir):
    logger = util.create_logger(name='data_collection')

    solution = util.create_solution(device='cpu:0')
    model_file = os.path.join(log_dir, 'model.npz')
    solution.load(model_file)

    trajectories = []
    env = gym.make('AntBulletEnv-v0')

    # Collect trajectories from rollouts.
    max_ep_cnt = 1000
    traj_len = 500
    ep_saved = 0
    while ep_saved < max_ep_cnt:
        ep_reward = 0
        ep_steps = 0
        obs = env.reset()
        prev_act = np.zeros(8)
        ep_traj = []
        done = False
        while not done and ep_steps < traj_len:
            act = solution.get_action(obs)
            ep_traj.append(np.concatenate([prev_act, obs, act], axis=0))
            obs, reward, done, info = env.step(act)
            ep_reward += reward
            ep_steps += 1
        logger.info(
            'Episode:{0}, steps:{1},  reward:{2:.2f}'.format(
                ep_saved + 1, ep_steps, ep_reward)
        )
        if ep_steps >= traj_len:
            trajectories.append(np.vstack(ep_traj))
            ep_saved += 1
        else:
            logger.info('Trajectory too short, discard.')

    trajectories = np.stack(trajectories)
    logger.info('trajectories.shape={}'.format(trajectories.shape))
    np.savez(os.path.join(log_dir, 'data.npz'), data=trajectories)


if __name__ == '__main__':
    model_dir = 'pretrained/ant_mlp'
    gin.parse_config_file(os.path.join(model_dir, 'config.gin'))
    main(model_dir)


================================================================================
# End of file: ant_bc_collect_data.py
================================================================================


================================================================================
# File 3/28: ant_bc_train.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/ant_bc_train.py
# File type: Python
================================================================================

import os
import util
import numpy as np

import torch
import torch.nn as nn
from solutions.torch_modules import AttentionNeuronLayer


ACT_DIM = 8


class PIStudent(nn.Module):
    """Permutation invariant student policy."""

    def __init__(self, act_dim, hidden_dim, msg_dim, pos_em_dim):
        super(PIStudent, self).__init__()

        self.attention_neuron = AttentionNeuronLayer(
            act_dim=act_dim,
            hidden_dim=hidden_dim,
            msg_dim=msg_dim,
            pos_em_dim=pos_em_dim,
        )
        self.policy_net = nn.Sequential(
            nn.Linear(in_features=hidden_dim, out_features=hidden_dim),
            nn.Tanh(),
            nn.Linear(in_features=hidden_dim, out_features=hidden_dim),
            nn.Tanh(),
            nn.Linear(in_features=hidden_dim, out_features=act_dim),
            nn.Tanh(),
        )

    def forward(self, obs, prev_act):
        msg = self.attention_neuron(obs=obs, prev_act=prev_act)
        return self.policy_net(msg.T)


def load_data(data_file):
    with np.load(data_file, 'r') as data:
        trajectories = data['data']
    return trajectories


def sample_batch_data(data, batch_size, seed=0):
    num_rollouts, traj_len, data_dim = data.shape
    rnd = np.random.RandomState(seed=seed)
    while True:
        rollout_ix = rnd.choice(num_rollouts, batch_size, replace=False)
        yield data[rollout_ix]


def save_model(model, i):
    params = []
    for p in model.parameters():
        params.append(p.cpu().data.numpy().ravel())
    params = np.concatenate(params, axis=0)
    np.savez(
        'pretrained/ant_pi/bc_train_iter{0:06d}.npz'.format(i), params=params)


def main(log_dir):
    logger = util.create_logger(name='bc_training', log_dir='pretrained/ant_pi')

    device = torch.device('cuda:0')
    policy = PIStudent(
        act_dim=ACT_DIM,
        msg_dim=32,
        pos_em_dim=8,
        hidden_dim=32,
    ).to(device)

    batch_size = 8
    data = load_data(os.path.join(log_dir, 'data.npz'))
    batches = sample_batch_data(data, batch_size=batch_size)

    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(policy.parameters(), lr=3e-4)

    max_iter = 1000000
    noise_sd = 0.1
    for i in range(max_iter):
        batch_data = torch.from_numpy(next(batches)).float().to(device)
        optimizer.zero_grad()

        # This is only to show how BC training works, it is inefficient.
        seq_len = batch_data.shape[1]
        losses = []
        for traj in batch_data:
            pred_act = []
            policy.attention_neuron.reset()  # Reset AttentionNeuron's hx.
            for t in range(seq_len):
                prev_act, obs = traj[t][:ACT_DIM], traj[t][ACT_DIM:-ACT_DIM]
                prev_act = prev_act + torch.randn(ACT_DIM).to(device) * noise_sd
                pred_act.append(policy(obs, prev_act))
            pred_act = torch.vstack(pred_act)
            act = traj[:, -ACT_DIM:]
            losses.append(criterion(input=pred_act, target=act))
        loss = sum(losses) / batch_size
        loss.backward()
        torch.nn.utils.clip_grad_norm_(policy.parameters(), max_norm=.1)
        optimizer.step()

        logger.info('iter={}, loss={}'.format(i, loss.item()))
        if i % 1000 == 0:
            save_model(policy, i)

    save_model(policy, max_iter)


if __name__ == '__main__':
    model_dir = 'pretrained/ant_mlp'
    main(model_dir)


================================================================================
# End of file: ant_bc_train.py
================================================================================


================================================================================
# File 4/28: eval_agent.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/eval_agent.py
# File type: Python
================================================================================

import argparse
import gin
import os
import util
import numpy as np
import time


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--log-dir', help='Directory of logs.')
    parser.add_argument(
        '--model-filename', default='model.npz',
        help='File name of the model to evaluate.')
    parser.add_argument(
        '--n-episodes', help='Number of episodes to evaluate.',
        type=int, default=3)
    parser.add_argument(
        '--seed', help='Random seed for evaluation.', type=int, default=1)
    config, _ = parser.parse_known_args()
    return config


def main(config):
    logger = util.create_logger(name='test_solution', log_dir=config.log_dir)
    task = util.create_task(logger=logger)
    task.seed(config.seed)

    solution = util.create_solution(device='cpu:0')
    model_file = os.path.join(config.log_dir, config.model_filename)
    solution.load(model_file)

    rewards = []
    time_costs = []
    for ep in range(config.n_episodes):
        start_time = time.perf_counter()
        reward = task.rollout(solution=solution, evaluation=True)
        time_cost = time.perf_counter() - start_time
        rewards.append(reward)
        time_costs.append(time_cost)
        logger.info('Episode: {0}, reward: {1:.2f}'.format(ep + 1, reward))

    logger.info('Avg reward: {0:.2f}, sd: {1:.2f}'.format(
        np.mean(rewards), np.std(rewards)))
    logger.info('Time per rollout: {}s'.format(np.mean(time_costs)))


if __name__ == '__main__':
    args = parse_args()
    gin.parse_config_file(os.path.join(args.log_dir, 'config.gin'))
    main(args)


================================================================================
# End of file: eval_agent.py
================================================================================


================================================================================
# File 5/28: eval_agent_with_hooks.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/eval_agent_with_hooks.py
# File type: Python
================================================================================

import argparse
import gin
import os
import util
import numpy as np
import time
import torch
from pathlib import Path
import matplotlib as mpl
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import ImageSequenceClip

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--log-dir', help='Directory of logs.')
    parser.add_argument(
        '--model-filename', default='model.npz',
        help='File name of the model to evaluate.')
    parser.add_argument(
        '--n-episodes', help='Number of episodes to evaluate.',
        type=int, default=3)
    parser.add_argument(
        '--seed', help='Random seed for evaluation.', type=int, default=1)
    parser.add_argument(
        '--prefix', default='default',
        help = 'Prefix for logging and video names.'
    )
    parser.add_argument(
        '--pos', type=int, default=2,
        help='Position to ablate in the attention matrix.'
    )
    parser.add_argument(
        '--dim', type=int, default=0,
        help='Dimension to ablate in the attention matrix.'
    )
    config, _ = parser.parse_known_args()
    return config

def main(config):

    EXPT = Path(config.log_dir, config.prefix)
    EXPT.mkdir(parents=True, exist_ok=True)

    logger = util.create_logger(name=f'test_log', log_dir=config.log_dir)
    task = util.create_task(logger=logger)
    task.seed(config.seed)

    def get_permutation_ix():
        """
        Get the permutation index for the task.
        """
        # This is a hack to get the permutation index from the task.
        # The task should have a method to get the permutation index.
        return task.perm_ix

    def mask(pos, dim=1):
        """
        Mask out the activations at that specific position.
        """
        def ablation(x):
            # Mask out the activations at the specified position in the tensor x
            if dim == 1:
                newp = get_permutation_ix().tolist().index(pos)
            else:
                newp = pos
            x.index_fill_(dim=dim, index=torch.tensor([newp]), value=-1)
            # print(x)
            return x

        return ablation
    
    def set_to(pos, dim = 1, to_val = 1):
        """
        Set the activations at that specific position to a value.
        """
        def ablation(x):
            # Set the activations at the specified position in the tensor x
            if dim == 1:
                newp = get_permutation_ix().tolist().index(pos)
            else:
                newp = pos
            x.index_fill_(dim=dim, index=torch.tensor([newp]), value = to_val)
            return x

        return ablation

    def zero_lstm_state():
        """
        Zero out the activations.
        """
        def ablation(x):
            x[0].zero_()
            x[1].zero_()
            return x

        return ablation
    
    def mean_ablate(lst):
        """
        Ablate the activations in the tensor x by taking the mean of the specified entries.
        The first entry should be the new value, and the
        second entry should be the coordinates to modify.
        """
        def ablation(x):
            for i, coords in enumerate(lst):
                # print(f'Modifying {i}th entry with value {new_value} at coords {coords}')
                coords = (coords[0], get_permutation_ix().tolist().index(coords[1]))
                x[coords] = x.mean()
            return x

        return ablation

    def modify(lst):
        """
        Modify the activations in the tensor x.
        The first entry should be the new value, and the
        second entry should be the coordinates to modify.
        """
        def ablation(x):
            for i, (new_value, coords) in enumerate(lst):
                # print(f'Modifying {i}th entry with value {new_value} at coords {coords}')
                coords = (coords[0], get_permutation_ix().tolist().index(coords[1]))
                x[coords] = new_value
            return x

        return ablation
    
    def output_modify(lst):
        """
        Modify the output of the model.
        The first entry should be the new value, and the
        second entry should be the coordinates to modify.
        """
        def ablation(x):
            for i, (new_value, coords) in enumerate(lst):
                # print(f'Modifying {i}th entry with value {new_value} at coords {coords}')
                x[coords] = new_value
            return x

        return ablation
    
    def all_but_one(pos):
        """
        Set all but one position in the output to -1.
        """
        def ablation(x):
            for i in range(x.shape[0]):
                if i != pos:
                    x[i] = -1
            return x

        return ablation
    
    def zero_everything():
        """
        Zero out all activations in the tensor x.
        """
        def ablation(x):
            x.zero_()
            return x

        return ablation

    def compose(ablations):
        """
        Compose multiple ablation functions.
        """
        def ablation(x):
            for fn in reversed(ablations):
                x = fn(x)
            return x

        return ablation

    hook_fns = {
        'pi_layer_activations': {
            # 'attention_matrix': mask(config.pos, dim = config.dim),
            # 'hx_prev': zero_lstm_state(),

            # Remove a crucial part of how the model recognizes it is moving left with the 
            # pole at an angle of -pi/2.
            # THEORETICALLY, since the information never makes it into the LSTM,
            # the model will never recognize when it is in this state.
            # 'attention_matrix': modify([(-1., (0, 4))])
            # 'attention_matrix': modify([(1., (0, 4))])

            # Mean Ablation
            # 'attention_matrix': mean_ablate([(0, 4)])
            # 'attention_matrix': compose([
            #     set_to(0, 1, -1),
            #     set_to(1, 1, -1),
            #     set_to(2, 1, -1),
            #     set_to(3, 1, -1),
            #     set_to(4, 1, -1),
            # ])
            # 'attention_matrix': all_but_one(7)

            # There seems to be a pretty strange pattern in the attention matrix.
            # There are distinct activation patterns for when the pole is tilted slightly to the left or right.
            # 'attention_matrix': compose([
            #     modify([
            #         (1., (6, 3)), (1., (6, 0)), (1., (6, 1)),
            #         (1., (15, 4)), (1., (15, 0)), (1., (15, 2)),
            #     ]),
            #     set_to(0, 0, 1), set_to(1, 0, 1), set_to(2, 0, 1),
            #     set_to(6, 0, 1), set_to(7, 0, 1), set_to(8, 0, 1), 
            #     set_to(13, 0, 1), set_to(14, 0, 1),
            #     mask(3, 0), mask(4, 0), mask(5, 0), 
            #     mask(9, 0), mask(10, 0), mask(11, 0), 
            #     mask(12, 0), mask(15, 0)
            # ])
            
            # 'attention_matrix': compose(
            # [
            #     modify([
            #         (1., (0, 1)), (1., (6, 1)), (1., (12, 1)), (1., (13, 1)), (1., (14, 2)), (1., (14, 3)),
            #         # *[(1, (i, 1)) for i in range(15)],
            #         *[(1, (i, 4)) for i in range(15)]
            #     ]),
            # ]
            # )
            # 'output': output_modify([
            #     # (1., (0, )),
            #     # (1., (1, )),
            #     # (1., (2, )),
            #     (-1., (3, )),
            #     (-1., (4, )),   
            #     (-1., (5, )),
            #     # (1., (6, )),
            #     # (1., (7, )),
            #     # (1., (8, )),
            #     (-1., (9, )),
            #     (-1., (10, )),
            #     (-1., (11, )),
            #     (-1., (12, )),
            #     # (-1., (13, )),
            #     # (-1., (14, )),
            #     (-1., (15, )),

            # ])
            # 'output': all_but_one(0),
            # 'output': zero_everything(),
        },
    }


    solution = util.create_solution(device='cpu:0', hook_fns = hook_fns)
    model_file = os.path.join(config.log_dir, config.model_filename)
    solution.load(model_file)

    print(f'Loaded model from {model_file}')
    print(solution.pi_layer)
    print(solution.net)

    for name, module in solution.pi_layer.named_modules():
        print(name, module)

    ATTENTION_CMAP = mpl.colormaps.get_cmap('viridis')
    def attention_to_rgb(attention_matrix):
        """
        Convert attention matrix to RGB image.
        Expected shape: (batch, d_feats, d_obspos)
        """
        attention_matrix = attention_matrix.squeeze()
        rgb_image = ATTENTION_CMAP(attention_matrix)[..., :3]  # Drop alpha channel
        return (rgb_image * 255).astype(np.uint8)

    VIDEOS = Path(EXPT, 'videos')
    VIDEOS.mkdir(parents=True, exist_ok=True)


    HOOK_DATA = Path(EXPT, 'hook_data')
    HOOK_DATA.mkdir(parents=True, exist_ok=True)
    def make_video(frames, filename):
        """
        Save frames as a video.
        """

        clip = ImageSequenceClip(list(frames), fps=24)
        clip.write_videofile(str(filename), codec='libx264', audio=False)

    rewards = []
    time_costs = []
    for ep in range(config.n_episodes):
        start_time = time.perf_counter()
        reward, frames, permutations = task.rollout(solution=solution, evaluation=True)

        # Shape: (n_frames, d_feats, d_obspos)
        # attention_matrices = np.array([
        #     x['pi_layer_activations']['attention_matrix'].numpy() 
        #     for x in solution.full_hook_data
        # ])

        # Scale the matrix to the desired size.
        # attention_matrices = np.kron(attention_matrices, np.ones((1, 16, 16)))

        # Shape: (n_frames, h, w, c)
        frames = np.array(frames[:-1])
        # Attach the frames to the hook data.
        for i in range(len(solution.full_hook_data)):
            solution.full_hook_data[i]['permutation'] = permutations[i]
        # for i, frame in enumerate(frames):
            # solution.full_hook_data[i]['permutation'] = task.perm_ix
            # solution.full_hook_data[i]['video_frame'] = frame

        # print(attention_matrices.shape, frames.shape)
        # Now shape: (n_frames, d_feats, d_obspos, 3)
        # attention_matrices = attention_to_rgb(attention_matrices)
        # # print("RENDERED SHAPE")
        # # print(attention_matrices.shape, frames.shape)

        # pad_width = (frames.shape[1] - attention_matrices.shape[1])
        # pad_height = (frames.shape[2] // 2 - attention_matrices.shape[2])
        # # Now hopefully, shape: (n_frames, h, w, 3)
        # attention_matrices = np.pad(
        #     attention_matrices,
        #     ((0, 0), (pad_width, 0), (pad_height // 2, pad_height // 2), (0, 0)),
        #     mode='constant', constant_values = 255
        # )
        # print("POST-PADDING SHAPE")
        # print(attention_matrices.shape, frames.shape)

        # def add_text(frame, text, position = (10, 10), font_size=20):
        #     """
        #     Add text to a frame.
        #     """
        #     img = Image.fromarray(frame.copy())
        #     draw = ImageDraw.Draw(img)
        #     font = ImageFont.load_default(size = font_size)
        #     draw.text(position, text, fill=(0, 0, 0), font=font)
        #     return np.array(img)

        # obs = [[round(x[0], 4) for x in solution.full_hook_data[i]["pi_layer_activations"]["obs"].tolist()] for i in range(len(solution.full_hook_data))]
        # print(obs)
        # Add the observation space to the frames.
        # frames = np.array([
        #     add_text(frame, f'x,v,t,w\n{obs[i]}', position = (20, 20))
        #     for i, frame in enumerate(frames)
        # ])

        # frames = np.concatenate([frames, attention_matrices], axis=-2)
        # Save as video.
        make_video(frames, VIDEOS / f'video_ep_{ep}.mp4')
        # Save the hook data.
        torch.save(solution.full_hook_data, 
            HOOK_DATA / f'hook_data_ep_{ep}.pt'
        )
        
        time_cost = time.perf_counter() - start_time
        rewards.append(reward)
        time_costs.append(time_cost)
        logger.info(f'Episode: {ep + 1}, reward: {reward:.2f}')

    logger.info(f'Avg reward: {np.mean(rewards):.2f}, sd of mean: {np.std(rewards) / np.sqrt(len(rewards)):.2f}')
    logger.info(f'Time per rollout: {np.mean(time_costs)}s')
    return np.mean(rewards), np.std(rewards) / np.sqrt(len(rewards))

if __name__ == '__main__':
    args = parse_args()
    print(os.path.join(args.log_dir, 'config.gin'))
    gin.parse_config_file(os.path.join(args.log_dir, 'config.gin'))
    main(args)


================================================================================
# End of file: eval_agent_with_hooks.py
================================================================================


================================================================================
# File 6/28: pretrained/cartpole_pi_GOLEFT/eval_agent_with_hooks.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/pretrained/cartpole_pi_GOLEFT/eval_agent_with_hooks.py
# File type: Python
================================================================================

import argparse
import gin
import os
import util
import numpy as np
import time
import torch
from pathlib import Path
import matplotlib as mpl
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import ImageSequenceClip

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--log-dir', help='Directory of logs.')
    parser.add_argument(
        '--model-filename', default='model.npz',
        help='File name of the model to evaluate.')
    parser.add_argument(
        '--n-episodes', help='Number of episodes to evaluate.',
        type=int, default=3)
    parser.add_argument(
        '--seed', help='Random seed for evaluation.', type=int, default=1)
    parser.add_argument(
        '--prefix', default='default',
        help = 'Prefix for logging and video names.'
    )
    parser.add_argument(
        '--pos', type=int, default=2,
        help='Position to ablate in the attention matrix.'
    )
    parser.add_argument(
        '--dim', type=int, default=0,
        help='Dimension to ablate in the attention matrix.'
    )
    config, _ = parser.parse_known_args()
    return config

def main(config):

    EXPT = Path(config.log_dir, config.prefix)
    EXPT.mkdir(parents=True, exist_ok=True)

    logger = util.create_logger(name=f'test_log', log_dir=config.log_dir)
    task = util.create_task(logger=logger)
    task.seed(config.seed)

    def get_permutation_ix():
        """
        Get the permutation index for the task.
        """
        # This is a hack to get the permutation index from the task.
        # The task should have a method to get the permutation index.
        return task.perm_ix

    def mask(pos, dim=1):
        """
        Mask out the activations at that specific position.
        """
        def ablation(x):
            # Mask out the activations at the specified position in the tensor x
            if dim == 1:
                newp = get_permutation_ix().tolist().index(pos)
            else:
                newp = pos
            x.index_fill_(dim=dim, index=torch.tensor([newp]), value=-1)
            # print(x)
            return x

        return ablation
    
    def set_to(pos, dim = 1, to_val = 1):
        """
        Set the activations at that specific position to a value.
        """
        def ablation(x):
            # Set the activations at the specified position in the tensor x
            if dim == 1:
                newp = get_permutation_ix().tolist().index(pos)
            else:
                newp = pos
            x.index_fill_(dim=dim, index=torch.tensor([newp]), value = to_val)
            return x

        return ablation

    def zero_lstm_state():
        """
        Zero out the activations.
        """
        def ablation(x):
            x[0].zero_()
            x[1].zero_()
            return x

        return ablation
    
    def mean_ablate(lst):
        """
        Ablate the activations in the tensor x by taking the mean of the specified entries.
        The first entry should be the new value, and the
        second entry should be the coordinates to modify.
        """
        def ablation(x):
            for i, coords in enumerate(lst):
                # print(f'Modifying {i}th entry with value {new_value} at coords {coords}')
                coords = (coords[0], get_permutation_ix().tolist().index(coords[1]))
                x[coords] = x.mean()
            return x

        return ablation

    def modify(lst):
        """
        Modify the activations in the tensor x.
        The first entry should be the new value, and the
        second entry should be the coordinates to modify.
        """
        def ablation(x):
            for i, (new_value, coords) in enumerate(lst):
                # print(f'Modifying {i}th entry with value {new_value} at coords {coords}')
                coords = (coords[0], get_permutation_ix().tolist().index(coords[1]))
                x[coords] = new_value
            return x

        return ablation

    def compose(ablations):
        """
        Compose multiple ablation functions.
        """
        def ablation(x):
            for fn in reversed(ablations):
                x = fn(x)
            return x

        return ablation

    hook_fns = {
        'pi_layer_activations': {
            # There seems to be a pretty strange pattern in the attention matrix.
            # There are distinct activation patterns for when the pole is tilted slightly to the left or right.
            # Since this pattern induces the model to move in the same direction of the tilt so as to
            # correct it, we call this the "NOPE" pattern.
            'attention_matrix': compose([
                modify([
                    (1., (6, 3)), (1., (6, 0)), (1., (6, 1)),
                    (1., (15, 4)), (1., (15, 0)), (1., (15, 2)),
                ]),
                set_to(0, 0, 1), set_to(1, 0, 1), set_to(2, 0, 1),
                set_to(6, 0, 1), set_to(7, 0, 1), set_to(8, 0, 1), 
                set_to(13, 0, 1), set_to(14, 0, 1),
                mask(3, 0), mask(4, 0), mask(5, 0), 
                mask(9, 0), mask(10, 0), mask(11, 0), 
                mask(12, 0), mask(15, 0)
            ])
            
            # 'attention_matrix': compose(
            # [
            #     modify([
            #         (1., (0, 1)), (1., (6, 1)), (1., (12, 1)), (1., (13, 1)), (1., (14, 2)), (1., (14, 3)),
            #         # *[(1, (i, 1)) for i in range(15)],
            #         *[(1, (i, 4)) for i in range(15)]
            #     ]),
            # ]
            # )
        },
    }


    solution = util.create_solution(device='cpu:0', hook_fns = hook_fns)
    model_file = os.path.join(config.log_dir, config.model_filename)
    solution.load(model_file)

    print(f'Loaded model from {model_file}')
    print(solution.pi_layer)
    print(solution.net)

    for name, module in solution.pi_layer.named_modules():
        print(name, module)

    ATTENTION_CMAP = mpl.colormaps.get_cmap('viridis')
    def attention_to_rgb(attention_matrix):
        """
        Convert attention matrix to RGB image.
        Expected shape: (batch, d_feats, d_obspos)
        """
        attention_matrix = attention_matrix.squeeze()
        rgb_image = ATTENTION_CMAP(attention_matrix)[..., :3]  # Drop alpha channel
        return (rgb_image * 255).astype(np.uint8)

    VIDEOS = Path(EXPT, 'videos')
    VIDEOS.mkdir(parents=True, exist_ok=True)


    HOOK_DATA = Path(EXPT, 'hook_data')
    HOOK_DATA.mkdir(parents=True, exist_ok=True)
    def make_video(frames, filename):
        """
        Save frames as a video.
        """

        clip = ImageSequenceClip(list(frames), fps=24)
        clip.write_videofile(str(filename), codec='libx264', audio=False)

    rewards = []
    time_costs = []
    for ep in range(config.n_episodes):
        start_time = time.perf_counter()
        reward, frames, permutations = task.rollout(solution=solution, evaluation=True)

        # Shape: (n_frames, d_feats, d_obspos)
        attention_matrices = np.array([
            x['pi_layer_activations']['attention_matrix'].numpy() 
            for x in solution.full_hook_data
        ])

        # Scale the matrix to the desired size.
        attention_matrices = np.kron(attention_matrices, np.ones((1, 16, 16)))

        # Shape: (n_frames, h, w, c)
        frames = np.array(frames[:-1])
        # Attach the frames to the hook data.
        for i in range(len(solution.full_hook_data)):
            solution.full_hook_data[i]['permutation'] = permutations[i]
        # for i, frame in enumerate(frames):
            # solution.full_hook_data[i]['permutation'] = task.perm_ix
            # solution.full_hook_data[i]['video_frame'] = frame

        # print(attention_matrices.shape, frames.shape)
        # Now shape: (n_frames, d_feats, d_obspos, 3)
        # attention_matrices = attention_to_rgb(attention_matrices)
        # # print("RENDERED SHAPE")
        # # print(attention_matrices.shape, frames.shape)

        # pad_width = (frames.shape[1] - attention_matrices.shape[1])
        # pad_height = (frames.shape[2] // 2 - attention_matrices.shape[2])
        # # Now hopefully, shape: (n_frames, h, w, 3)
        # attention_matrices = np.pad(
        #     attention_matrices,
        #     ((0, 0), (pad_width, 0), (pad_height // 2, pad_height // 2), (0, 0)),
        #     mode='constant', constant_values = 255
        # )
        # print("POST-PADDING SHAPE")
        # print(attention_matrices.shape, frames.shape)

        # def add_text(frame, text, position = (10, 10), font_size=20):
        #     """
        #     Add text to a frame.
        #     """
        #     img = Image.fromarray(frame.copy())
        #     draw = ImageDraw.Draw(img)
        #     font = ImageFont.load_default(size = font_size)
        #     draw.text(position, text, fill=(0, 0, 0), font=font)
        #     return np.array(img)

        # obs = [[round(x[0], 4) for x in solution.full_hook_data[i]["pi_layer_activations"]["obs"].tolist()] for i in range(len(solution.full_hook_data))]
        # print(obs)
        # Add the observation space to the frames.
        # frames = np.array([
        #     add_text(frame, f'x,v,t,w\n{obs[i]}', position = (20, 20))
        #     for i, frame in enumerate(frames)
        # ])

        # frames = np.concatenate([frames, attention_matrices], axis=-2)
        # Save as video.
        make_video(frames, VIDEOS / f'video_ep_{ep}.mp4')
        # Save the hook data.
        torch.save(solution.full_hook_data, 
            HOOK_DATA / f'hook_data_ep_{ep}.pt'
        )
        
        time_cost = time.perf_counter() - start_time
        rewards.append(reward)
        time_costs.append(time_cost)
        logger.info(f'Episode: {ep + 1}, reward: {reward:.2f}')

    logger.info(f'Avg reward: {np.mean(rewards):.2f}, sd of mean: {np.std(rewards) / np.sqrt(len(rewards)):.2f}')
    logger.info(f'Time per rollout: {np.mean(time_costs)}s')


if __name__ == '__main__':
    args = parse_args()
    gin.parse_config_file(os.path.join(args.log_dir, 'config.gin'))
    main(args)


================================================================================
# End of file: pretrained/cartpole_pi_GOLEFT/eval_agent_with_hooks.py
================================================================================


================================================================================
# File 7/28: pretrained/cartpole_pi_NOPE/eval_agent_with_hooks.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/pretrained/cartpole_pi_NOPE/eval_agent_with_hooks.py
# File type: Python
================================================================================

import argparse
import gin
import os
import util
import numpy as np
import time
import torch
from pathlib import Path
import matplotlib as mpl
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import ImageSequenceClip

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--log-dir', help='Directory of logs.')
    parser.add_argument(
        '--model-filename', default='model.npz',
        help='File name of the model to evaluate.')
    parser.add_argument(
        '--n-episodes', help='Number of episodes to evaluate.',
        type=int, default=3)
    parser.add_argument(
        '--seed', help='Random seed for evaluation.', type=int, default=1)
    parser.add_argument(
        '--prefix', default='default',
        help = 'Prefix for logging and video names.'
    )
    parser.add_argument(
        '--pos', type=int, default=2,
        help='Position to ablate in the attention matrix.'
    )
    parser.add_argument(
        '--dim', type=int, default=0,
        help='Dimension to ablate in the attention matrix.'
    )
    config, _ = parser.parse_known_args()
    return config

def main(config):

    EXPT = Path(config.log_dir, config.prefix)
    EXPT.mkdir(parents=True, exist_ok=True)

    logger = util.create_logger(name=f'test_log', log_dir=config.log_dir)
    task = util.create_task(logger=logger)
    task.seed(config.seed)

    def get_permutation_ix():
        """
        Get the permutation index for the task.
        """
        # This is a hack to get the permutation index from the task.
        # The task should have a method to get the permutation index.
        return task.perm_ix

    def mask(pos, dim=1):
        """
        Mask out the activations at that specific position.
        """
        def ablation(x):
            # Mask out the activations at the specified position in the tensor x
            if dim == 1:
                newp = get_permutation_ix().tolist().index(pos)
            else:
                newp = pos
            x.index_fill_(dim=dim, index=torch.tensor([newp]), value=-1)
            # print(x)
            return x

        return ablation
    
    def set_to(pos, dim = 1, to_val = 1):
        """
        Set the activations at that specific position to a value.
        """
        def ablation(x):
            # Set the activations at the specified position in the tensor x
            if dim == 1:
                newp = get_permutation_ix().tolist().index(pos)
            else:
                newp = pos
            x.index_fill_(dim=dim, index=torch.tensor([newp]), value = to_val)
            return x

        return ablation

    def zero_lstm_state():
        """
        Zero out the activations.
        """
        def ablation(x):
            x[0].zero_()
            x[1].zero_()
            return x

        return ablation
    
    def mean_ablate(lst):
        """
        Ablate the activations in the tensor x by taking the mean of the specified entries.
        The first entry should be the new value, and the
        second entry should be the coordinates to modify.
        """
        def ablation(x):
            for i, coords in enumerate(lst):
                # print(f'Modifying {i}th entry with value {new_value} at coords {coords}')
                coords = (coords[0], get_permutation_ix().tolist().index(coords[1]))
                x[coords] = x.mean()
            return x

        return ablation

    def modify(lst):
        """
        Modify the activations in the tensor x.
        The first entry should be the new value, and the
        second entry should be the coordinates to modify.
        """
        def ablation(x):
            for i, (new_value, coords) in enumerate(lst):
                # print(f'Modifying {i}th entry with value {new_value} at coords {coords}')
                coords = (coords[0], get_permutation_ix().tolist().index(coords[1]))
                x[coords] = new_value
            return x

        return ablation

    def compose(ablations):
        """
        Compose multiple ablation functions.
        """
        def ablation(x):
            for fn in reversed(ablations):
                x = fn(x)
            return x

        return ablation

    hook_fns = {
        'pi_layer_activations': {
            # There seems to be a pretty strange pattern in the attention matrix.
            # There are distinct activation patterns for when the pole is tilted slightly to the left or right.
            # Since this pattern induces the model to move in the same direction of the tilt so as to
            # correct it, we call this the "NOPE" pattern.
            'attention_matrix': compose([
                modify([
                    (1., (6, 3)), (1., (6, 0)), (1., (6, 1)),
                    (1., (15, 4)), (1., (15, 0)), (1., (15, 2)),
                ]),
                set_to(0, 0, 1), set_to(1, 0, 1), set_to(2, 0, 1),
                set_to(6, 0, 1), set_to(7, 0, 1), set_to(8, 0, 1), 
                set_to(13, 0, 1), set_to(14, 0, 1),
                mask(3, 0), mask(4, 0), mask(5, 0), 
                mask(9, 0), mask(10, 0), mask(11, 0), 
                mask(12, 0), mask(15, 0)
            ])
            
            # 'attention_matrix': compose(
            # [
            #     modify([
            #         (1., (0, 1)), (1., (6, 1)), (1., (12, 1)), (1., (13, 1)), (1., (14, 2)), (1., (14, 3)),
            #         # *[(1, (i, 1)) for i in range(15)],
            #         *[(1, (i, 4)) for i in range(15)]
            #     ]),
            # ]
            # )
        },
    }


    solution = util.create_solution(device='cpu:0', hook_fns = hook_fns)
    model_file = os.path.join(config.log_dir, config.model_filename)
    solution.load(model_file)

    print(f'Loaded model from {model_file}')
    print(solution.pi_layer)
    print(solution.net)

    for name, module in solution.pi_layer.named_modules():
        print(name, module)

    ATTENTION_CMAP = mpl.colormaps.get_cmap('viridis')
    def attention_to_rgb(attention_matrix):
        """
        Convert attention matrix to RGB image.
        Expected shape: (batch, d_feats, d_obspos)
        """
        attention_matrix = attention_matrix.squeeze()
        rgb_image = ATTENTION_CMAP(attention_matrix)[..., :3]  # Drop alpha channel
        return (rgb_image * 255).astype(np.uint8)

    VIDEOS = Path(EXPT, 'videos')
    VIDEOS.mkdir(parents=True, exist_ok=True)


    HOOK_DATA = Path(EXPT, 'hook_data')
    HOOK_DATA.mkdir(parents=True, exist_ok=True)
    def make_video(frames, filename):
        """
        Save frames as a video.
        """

        clip = ImageSequenceClip(list(frames), fps=24)
        clip.write_videofile(str(filename), codec='libx264', audio=False)

    rewards = []
    time_costs = []
    for ep in range(config.n_episodes):
        start_time = time.perf_counter()
        reward, frames, permutations = task.rollout(solution=solution, evaluation=True)

        # Shape: (n_frames, d_feats, d_obspos)
        attention_matrices = np.array([
            x['pi_layer_activations']['attention_matrix'].numpy() 
            for x in solution.full_hook_data
        ])

        # Scale the matrix to the desired size.
        attention_matrices = np.kron(attention_matrices, np.ones((1, 16, 16)))

        # Shape: (n_frames, h, w, c)
        frames = np.array(frames[:-1])
        # Attach the frames to the hook data.
        for i in range(len(solution.full_hook_data)):
            solution.full_hook_data[i]['permutation'] = permutations[i]
        # for i, frame in enumerate(frames):
            # solution.full_hook_data[i]['permutation'] = task.perm_ix
            # solution.full_hook_data[i]['video_frame'] = frame

        # print(attention_matrices.shape, frames.shape)
        # Now shape: (n_frames, d_feats, d_obspos, 3)
        # attention_matrices = attention_to_rgb(attention_matrices)
        # # print("RENDERED SHAPE")
        # # print(attention_matrices.shape, frames.shape)

        # pad_width = (frames.shape[1] - attention_matrices.shape[1])
        # pad_height = (frames.shape[2] // 2 - attention_matrices.shape[2])
        # # Now hopefully, shape: (n_frames, h, w, 3)
        # attention_matrices = np.pad(
        #     attention_matrices,
        #     ((0, 0), (pad_width, 0), (pad_height // 2, pad_height // 2), (0, 0)),
        #     mode='constant', constant_values = 255
        # )
        # print("POST-PADDING SHAPE")
        # print(attention_matrices.shape, frames.shape)

        # def add_text(frame, text, position = (10, 10), font_size=20):
        #     """
        #     Add text to a frame.
        #     """
        #     img = Image.fromarray(frame.copy())
        #     draw = ImageDraw.Draw(img)
        #     font = ImageFont.load_default(size = font_size)
        #     draw.text(position, text, fill=(0, 0, 0), font=font)
        #     return np.array(img)

        # obs = [[round(x[0], 4) for x in solution.full_hook_data[i]["pi_layer_activations"]["obs"].tolist()] for i in range(len(solution.full_hook_data))]
        # print(obs)
        # Add the observation space to the frames.
        # frames = np.array([
        #     add_text(frame, f'x,v,t,w\n{obs[i]}', position = (20, 20))
        #     for i, frame in enumerate(frames)
        # ])

        # frames = np.concatenate([frames, attention_matrices], axis=-2)
        # Save as video.
        make_video(frames, VIDEOS / f'video_ep_{ep}.mp4')
        # Save the hook data.
        torch.save(solution.full_hook_data, 
            HOOK_DATA / f'hook_data_ep_{ep}.pt'
        )
        
        time_cost = time.perf_counter() - start_time
        rewards.append(reward)
        time_costs.append(time_cost)
        logger.info(f'Episode: {ep + 1}, reward: {reward:.2f}')

    logger.info(f'Avg reward: {np.mean(rewards):.2f}, sd of mean: {np.std(rewards) / np.sqrt(len(rewards)):.2f}')
    logger.info(f'Time per rollout: {np.mean(time_costs)}s')


if __name__ == '__main__':
    args = parse_args()
    gin.parse_config_file(os.path.join(args.log_dir, 'config.gin'))
    main(args)


================================================================================
# End of file: pretrained/cartpole_pi_NOPE/eval_agent_with_hooks.py
================================================================================


================================================================================
# File 8/28: pretrained/cartpole_pi_ablate_lstm/eval_agent_with_hooks.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/pretrained/cartpole_pi_ablate_lstm/eval_agent_with_hooks.py
# File type: Python
================================================================================

import argparse
import gin
import os
import util
import numpy as np
import time
import torch
from pathlib import Path
import matplotlib as mpl
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import ImageSequenceClip

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--log-dir', help='Directory of logs.')
    parser.add_argument(
        '--model-filename', default='model.npz',
        help='File name of the model to evaluate.')
    parser.add_argument(
        '--n-episodes', help='Number of episodes to evaluate.',
        type=int, default=3)
    parser.add_argument(
        '--seed', help='Random seed for evaluation.', type=int, default=1)
    parser.add_argument(
        '--prefix', default='default',
        help = 'Prefix for logging and video names.'
    )
    parser.add_argument(
        '--pos', type=int, default=2,
        help='Position to ablate in the attention matrix.'
    )
    parser.add_argument(
        '--dim', type=int, default=0,
        help='Dimension to ablate in the attention matrix.'
    )
    config, _ = parser.parse_known_args()
    return config

def main(config):

    EXPT = Path(config.log_dir, config.prefix)
    EXPT.mkdir(parents=True, exist_ok=True)

    logger = util.create_logger(name=f'test_log', log_dir=config.log_dir)
    task = util.create_task(logger=logger)
    task.seed(config.seed)

    def get_permutation_ix():
        """
        Get the permutation index for the task.
        """
        # This is a hack to get the permutation index from the task.
        # The task should have a method to get the permutation index.
        return task.perm_ix

    def mask(pos, dim=1):
        """
        Mask out the activations at that specific position.
        """
        def ablation(x):
            # Mask out the activations at the specified position in the tensor x
            if dim == 1:
                newp = get_permutation_ix()[pos]
            else:
                newp = pos
            x.index_fill_(dim=dim, index=torch.tensor([newp]), value=-1)
            # print(x)
            return x

        return ablation

    def zero_cell_state():
        """
        Zero out the activations.
        """
        def ablation(x):
            # Zero out the activations in the tensor x
            x[1].zero_()
            return x

        return ablation

    def modify(lst):
        """
        Modify the activations in the tensor x.
        The first entry should be the new value, and the
        second entry should be the coordinates to modify.
        """
        def ablation(x):
            for i, (new_value, coords) in enumerate(lst):
                # print(f'Modifying {i}th entry with value {new_value} at coords {coords}')
                coords = (coords[0], get_permutation_ix()[coords[1]])
                x[coords] = new_value
            return x

        return ablation

    def compose(ablations):
        """
        Compose multiple ablation functions.
        """
        def ablation(x):
            for fn in reversed(ablations):
                x = fn(x)
            return x

        return ablation

    hook_fns = {
        'pi_layer_activations': {
            # 'attention_matrix': mask(config.pos, dim = config.dim),
            'hx': zero_cell_state(),
            # 'attention_matrix': compose(
            # [
            #     modify([
            #         (1., (0, 1)), (1., (6, 1)), (1., (12, 1)), (1., (13, 1)), (1., (14, 2)), (1., (14, 3)),
            #         # *[(1, (i, 1)) for i in range(15)],
            #         *[(1, (i, 4)) for i in range(15)]
            #     ]),
            # ]
            # )
        },
    }


    solution = util.create_solution(device='cpu:0', hook_fns = hook_fns)
    model_file = os.path.join(config.log_dir, config.model_filename)
    solution.load(model_file)

    print(f'Loaded model from {model_file}')
    print(solution.pi_layer)
    print(solution.net)

    for name, module in solution.pi_layer.named_modules():
        print(name, module)

    ATTENTION_CMAP = mpl.colormaps.get_cmap('viridis')
    def attention_to_rgb(attention_matrix):
        """
        Convert attention matrix to RGB image.
        Expected shape: (batch, d_feats, d_obspos)
        """
        attention_matrix = attention_matrix.squeeze()
        rgb_image = ATTENTION_CMAP(attention_matrix)[..., :3]  # Drop alpha channel
        return (rgb_image * 255).astype(np.uint8)

    VIDEOS = Path(EXPT, 'videos')
    VIDEOS.mkdir(parents=True, exist_ok=True)


    HOOK_DATA = Path(EXPT, 'hook_data')
    HOOK_DATA.mkdir(parents=True, exist_ok=True)
    def make_video(frames, filename):
        """
        Save frames as a video.
        """
        clip = ImageSequenceClip(list(frames), fps=24)
        clip.write_videofile(str(filename), codec='libx264', audio=False)

    rewards = []
    time_costs = []
    for ep in range(config.n_episodes):
        start_time = time.perf_counter()
        reward, frames = task.rollout(solution=solution, evaluation=True)

        # Shape: (n_frames, d_feats, d_obspos)
        attention_matrices = np.array([
            x['pi_layer_activations']['attention_matrix'].numpy() 
            for x in solution.full_hook_data
        ])

        # Scale the matrix to the desired size.
        attention_matrices = np.kron(attention_matrices, np.ones((1, 16, 16)))

        # Shape: (n_frames, h, w, c)
        frames = np.array(frames[:-1])
        # Attach the frames to the hook data.
        for i, frame in enumerate(frames):
            solution.full_hook_data[i]['permutation'] = task.perm_ix
            # solution.full_hook_data[i]['video_frame'] = frame

        # print(attention_matrices.shape, frames.shape)
        # Now shape: (n_frames, d_feats, d_obspos, 3)
        # attention_matrices = attention_to_rgb(attention_matrices)
        # # print("RENDERED SHAPE")
        # # print(attention_matrices.shape, frames.shape)

        # pad_width = (frames.shape[1] - attention_matrices.shape[1])
        # pad_height = (frames.shape[2] // 2 - attention_matrices.shape[2])
        # # Now hopefully, shape: (n_frames, h, w, 3)
        # attention_matrices = np.pad(
        #     attention_matrices,
        #     ((0, 0), (pad_width, 0), (pad_height // 2, pad_height // 2), (0, 0)),
        #     mode='constant', constant_values = 255
        # )
        # print("POST-PADDING SHAPE")
        # print(attention_matrices.shape, frames.shape)

        # def add_text(frame, text, position = (10, 10), font_size=20):
        #     """
        #     Add text to a frame.
        #     """
        #     img = Image.fromarray(frame.copy())
        #     draw = ImageDraw.Draw(img)
        #     font = ImageFont.load_default(size = font_size)
        #     draw.text(position, text, fill=(0, 0, 0), font=font)
        #     return np.array(img)

        # obs = [[round(x[0], 4) for x in solution.full_hook_data[i]["pi_layer_activations"]["obs"].tolist()] for i in range(len(solution.full_hook_data))]
        # print(obs)
        # Add the observation space to the frames.
        # frames = np.array([
        #     add_text(frame, f'x,v,t,w\n{obs[i]}', position = (20, 20))
        #     for i, frame in enumerate(frames)
        # ])

        # frames = np.concatenate([frames, attention_matrices], axis=-2)
        # Save as video.
        make_video(frames, VIDEOS / f'video_ep_{ep}.mp4')
        # Save the hook data.
        torch.save(solution.full_hook_data, 
            HOOK_DATA / f'hook_data_ep_{ep}.pt'
        )
        
        time_cost = time.perf_counter() - start_time
        rewards.append(reward)
        time_costs.append(time_cost)
        logger.info(f'Episode: {ep + 1}, reward: {reward:.2f}')

    logger.info(f'Avg reward: {np.mean(rewards):.2f}, sd of mean: {np.std(rewards) / np.sqrt(len(rewards)):.2f}')
    logger.info(f'Time per rollout: {np.mean(time_costs)}s')


if __name__ == '__main__':
    args = parse_args()
    gin.parse_config_file(os.path.join(args.log_dir, 'config.gin'))
    main(args)


================================================================================
# End of file: pretrained/cartpole_pi_ablate_lstm/eval_agent_with_hooks.py
================================================================================


================================================================================
# File 9/28: pretrained/cartpole_pi_ablate_lstm_perturb/eval_agent_with_hooks.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/pretrained/cartpole_pi_ablate_lstm_perturb/eval_agent_with_hooks.py
# File type: Python
================================================================================

import argparse
import gin
import os
import util
import numpy as np
import time
import torch
from pathlib import Path
import matplotlib as mpl
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import ImageSequenceClip

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--log-dir', help='Directory of logs.')
    parser.add_argument(
        '--model-filename', default='model.npz',
        help='File name of the model to evaluate.')
    parser.add_argument(
        '--n-episodes', help='Number of episodes to evaluate.',
        type=int, default=3)
    parser.add_argument(
        '--seed', help='Random seed for evaluation.', type=int, default=1)
    parser.add_argument(
        '--prefix', default='default',
        help = 'Prefix for logging and video names.'
    )
    parser.add_argument(
        '--pos', type=int, default=2,
        help='Position to ablate in the attention matrix.'
    )
    parser.add_argument(
        '--dim', type=int, default=0,
        help='Dimension to ablate in the attention matrix.'
    )
    config, _ = parser.parse_known_args()
    return config

def main(config):

    EXPT = Path(config.log_dir, config.prefix)
    EXPT.mkdir(parents=True, exist_ok=True)

    logger = util.create_logger(name=f'test_log', log_dir=config.log_dir)
    task = util.create_task(logger=logger)
    task.seed(config.seed)

    def get_permutation_ix():
        """
        Get the permutation index for the task.
        """
        # This is a hack to get the permutation index from the task.
        # The task should have a method to get the permutation index.
        return task.perm_ix

    def mask(pos, dim=1):
        """
        Mask out the activations at that specific position.
        """
        def ablation(x):
            # Mask out the activations at the specified position in the tensor x
            if dim == 1:
                newp = get_permutation_ix()[pos]
            else:
                newp = pos
            x.index_fill_(dim=dim, index=torch.tensor([newp]), value=-1)
            # print(x)
            return x

        return ablation

    def zero_cell_state():
        """
        Zero out the activations.
        """
        def ablation(x):
            # Zero out the activations in the tensor x
            x[1].zero_()
            return x

        return ablation

    def modify(lst):
        """
        Modify the activations in the tensor x.
        The first entry should be the new value, and the
        second entry should be the coordinates to modify.
        """
        def ablation(x):
            for i, (new_value, coords) in enumerate(lst):
                # print(f'Modifying {i}th entry with value {new_value} at coords {coords}')
                coords = (coords[0], get_permutation_ix()[coords[1]])
                x[coords] = new_value
            return x

        return ablation

    def compose(ablations):
        """
        Compose multiple ablation functions.
        """
        def ablation(x):
            for fn in reversed(ablations):
                x = fn(x)
            return x

        return ablation

    hook_fns = {
        'pi_layer_activations': {
            # 'attention_matrix': mask(config.pos, dim = config.dim),
            'hx': zero_cell_state(),
            # 'attention_matrix': compose(
            # [
            #     modify([
            #         (1., (0, 1)), (1., (6, 1)), (1., (12, 1)), (1., (13, 1)), (1., (14, 2)), (1., (14, 3)),
            #         # *[(1, (i, 1)) for i in range(15)],
            #         *[(1, (i, 4)) for i in range(15)]
            #     ]),
            # ]
            # )
        },
    }


    solution = util.create_solution(device='cpu:0', hook_fns = hook_fns)
    model_file = os.path.join(config.log_dir, config.model_filename)
    solution.load(model_file)

    print(f'Loaded model from {model_file}')
    print(solution.pi_layer)
    print(solution.net)

    for name, module in solution.pi_layer.named_modules():
        print(name, module)

    ATTENTION_CMAP = mpl.colormaps.get_cmap('viridis')
    def attention_to_rgb(attention_matrix):
        """
        Convert attention matrix to RGB image.
        Expected shape: (batch, d_feats, d_obspos)
        """
        attention_matrix = attention_matrix.squeeze()
        rgb_image = ATTENTION_CMAP(attention_matrix)[..., :3]  # Drop alpha channel
        return (rgb_image * 255).astype(np.uint8)

    VIDEOS = Path(EXPT, 'videos')
    VIDEOS.mkdir(parents=True, exist_ok=True)


    HOOK_DATA = Path(EXPT, 'hook_data')
    HOOK_DATA.mkdir(parents=True, exist_ok=True)
    def make_video(frames, filename):
        """
        Save frames as a video.
        """
        clip = ImageSequenceClip(list(frames), fps=24)
        clip.write_videofile(str(filename), codec='libx264', audio=False)

    rewards = []
    time_costs = []
    for ep in range(config.n_episodes):
        start_time = time.perf_counter()
        reward, frames = task.rollout(solution=solution, evaluation=True)

        # Shape: (n_frames, d_feats, d_obspos)
        attention_matrices = np.array([
            x['pi_layer_activations']['attention_matrix'].numpy() 
            for x in solution.full_hook_data
        ])

        # Scale the matrix to the desired size.
        attention_matrices = np.kron(attention_matrices, np.ones((1, 16, 16)))

        # Shape: (n_frames, h, w, c)
        frames = np.array(frames[:-1])
        # Attach the frames to the hook data.
        for i, frame in enumerate(frames):
            solution.full_hook_data[i]['permutation'] = task.perm_ix
            # solution.full_hook_data[i]['video_frame'] = frame

        # print(attention_matrices.shape, frames.shape)
        # Now shape: (n_frames, d_feats, d_obspos, 3)
        # attention_matrices = attention_to_rgb(attention_matrices)
        # # print("RENDERED SHAPE")
        # # print(attention_matrices.shape, frames.shape)

        # pad_width = (frames.shape[1] - attention_matrices.shape[1])
        # pad_height = (frames.shape[2] // 2 - attention_matrices.shape[2])
        # # Now hopefully, shape: (n_frames, h, w, 3)
        # attention_matrices = np.pad(
        #     attention_matrices,
        #     ((0, 0), (pad_width, 0), (pad_height // 2, pad_height // 2), (0, 0)),
        #     mode='constant', constant_values = 255
        # )
        # print("POST-PADDING SHAPE")
        # print(attention_matrices.shape, frames.shape)

        # def add_text(frame, text, position = (10, 10), font_size=20):
        #     """
        #     Add text to a frame.
        #     """
        #     img = Image.fromarray(frame.copy())
        #     draw = ImageDraw.Draw(img)
        #     font = ImageFont.load_default(size = font_size)
        #     draw.text(position, text, fill=(0, 0, 0), font=font)
        #     return np.array(img)

        # obs = [[round(x[0], 4) for x in solution.full_hook_data[i]["pi_layer_activations"]["obs"].tolist()] for i in range(len(solution.full_hook_data))]
        # print(obs)
        # Add the observation space to the frames.
        # frames = np.array([
        #     add_text(frame, f'x,v,t,w\n{obs[i]}', position = (20, 20))
        #     for i, frame in enumerate(frames)
        # ])

        # frames = np.concatenate([frames, attention_matrices], axis=-2)
        # Save as video.
        make_video(frames, VIDEOS / f'video_ep_{ep}.mp4')
        # Save the hook data.
        torch.save(solution.full_hook_data, 
            HOOK_DATA / f'hook_data_ep_{ep}.pt'
        )
        
        time_cost = time.perf_counter() - start_time
        rewards.append(reward)
        time_costs.append(time_cost)
        logger.info(f'Episode: {ep + 1}, reward: {reward:.2f}')

    logger.info(f'Avg reward: {np.mean(rewards):.2f}, sd of mean: {np.std(rewards) / np.sqrt(len(rewards)):.2f}')
    logger.info(f'Time per rollout: {np.mean(time_costs)}s')


if __name__ == '__main__':
    args = parse_args()
    gin.parse_config_file(os.path.join(args.log_dir, 'config.gin'))
    main(args)


================================================================================
# End of file: pretrained/cartpole_pi_ablate_lstm_perturb/eval_agent_with_hooks.py
================================================================================


================================================================================
# File 10/28: pretrained/cartpole_pi_clean/eval_agent_with_hooks.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/pretrained/cartpole_pi_clean/eval_agent_with_hooks.py
# File type: Python
================================================================================

import argparse
import gin
import os
import util
import numpy as np
import time
import torch
from pathlib import Path
import matplotlib as mpl
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import ImageSequenceClip

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--log-dir', help='Directory of logs.')
    parser.add_argument(
        '--model-filename', default='model.npz',
        help='File name of the model to evaluate.')
    parser.add_argument(
        '--n-episodes', help='Number of episodes to evaluate.',
        type=int, default=3)
    parser.add_argument(
        '--seed', help='Random seed for evaluation.', type=int, default=1)
    parser.add_argument(
        '--prefix', default='default',
        help = 'Prefix for logging and video names.'
    )
    parser.add_argument(
        '--pos', type=int, default=2,
        help='Position to ablate in the attention matrix.'
    )
    parser.add_argument(
        '--dim', type=int, default=0,
        help='Dimension to ablate in the attention matrix.'
    )
    config, _ = parser.parse_known_args()
    return config

def mask(pos, dim=1):
    """
    Mask out the activations at that specific position.
    """
    def ablation(x):
        # Mask out the activations at the specified position in the tensor x
        x.index_fill_(dim=dim, index=torch.tensor([pos]), value=-1)
        # print(x)
        return x

    return ablation

def main(config):

    hook_fns = {
        # 'pi_layer_activations': {
        #     'attention_matrix': mask(config.pos, dim = config.dim)
        # },
    }

    EXPT = Path(config.log_dir, config.prefix)
    EXPT.mkdir(parents=True, exist_ok=True)

    logger = util.create_logger(name=f'test_log', log_dir=config.log_dir)
    task = util.create_task(logger=logger)
    task.seed(config.seed)

    solution = util.create_solution(device='cpu:0', hook_fns = hook_fns)
    model_file = os.path.join(config.log_dir, config.model_filename)
    solution.load(model_file)

    print(f'Loaded model from {model_file}')
    print(solution.pi_layer)
    print(solution.net)

    for name, module in solution.pi_layer.named_modules():
        print(name, module)

    ATTENTION_CMAP = mpl.colormaps.get_cmap('viridis')
    def attention_to_rgb(attention_matrix):
        """
        Convert attention matrix to RGB image.
        Expected shape: (batch, d_feats, d_obspos)
        """
        attention_matrix = attention_matrix.squeeze()
        rgb_image = ATTENTION_CMAP(attention_matrix)[..., :3]  # Drop alpha channel
        return (rgb_image * 255).astype(np.uint8)

    VIDEOS = Path(EXPT, 'videos')
    VIDEOS.mkdir(parents=True, exist_ok=True)


    HOOK_DATA = Path(EXPT, 'hook_data')
    HOOK_DATA.mkdir(parents=True, exist_ok=True)
    def make_video(frames, filename):
        """
        Save frames as a video.
        """
        clip = ImageSequenceClip(list(frames), fps=24)
        clip.write_videofile(str(filename), codec='libx264', audio=False)

    rewards = []
    time_costs = []
    for ep in range(config.n_episodes):
        print(dir(solution))
        start_time = time.perf_counter()
        reward, frames = task.rollout(solution=solution, evaluation=True)

        # Shape: (n_frames, d_feats, d_obspos)
        attention_matrices = np.array([
            x['pi_layer_activations']['attention_matrix'].numpy() 
            for x in solution.full_hook_data
        ])

        # Scale the matrix to the desired size.
        attention_matrices = np.kron(attention_matrices, np.ones((1, 16, 16)))

        # Shape: (n_frames, h, w, c)
        frames = np.array(frames[:-1])
        # Attach the frames to the hook data.
        for i, frame in enumerate(frames):
            solution.full_hook_data[i]['permutation'] = task.perm_ix
            solution.full_hook_data[i]['video_frame'] = frame

        # print(attention_matrices.shape, frames.shape)
        # Now shape: (n_frames, d_feats, d_obspos, 3)
        attention_matrices = attention_to_rgb(attention_matrices)
        # print("RENDERED SHAPE")
        # print(attention_matrices.shape, frames.shape)

        pad_width = (frames.shape[1] - attention_matrices.shape[1])
        pad_height = (frames.shape[2] // 2 - attention_matrices.shape[2])
        # Now hopefully, shape: (n_frames, h, w, 3)
        attention_matrices = np.pad(
            attention_matrices,
            ((0, 0), (pad_width, 0), (pad_height // 2, pad_height // 2), (0, 0)),
            mode='constant', constant_values = 255
        )
        print("POST-PADDING SHAPE")
        print(attention_matrices.shape, frames.shape)

        def add_text(frame, text, position = (10, 10), font_size=20):
            """
            Add text to a frame.
            """
            img = Image.fromarray(frame.copy())
            draw = ImageDraw.Draw(img)
            font = ImageFont.load_default(size = font_size)
            draw.text(position, text, fill=(0, 0, 0), font=font)
            return np.array(img)

        obs = [[round(x[0], 4) for x in solution.full_hook_data[i]["pi_layer_activations"]["obs"].tolist()] for i in range(len(solution.full_hook_data))]
        # print(obs)
        # Add the observation space to the frames.
        frames = np.array([
            add_text(frame, f'x,v,t,w\n{obs[i]}', position = (20, 20))
            for i, frame in enumerate(frames)
        ])

        frames = np.concatenate([frames, attention_matrices], axis=-2)
        # Save as video.
        make_video(frames, VIDEOS / f'video_ep_{ep}.mp4')
        # Save the hook data.
        torch.save(solution.full_hook_data, 
            HOOK_DATA / f'hook_data_ep_{ep}.pt'
        )
        

        time_cost = time.perf_counter() - start_time
        rewards.append(reward)
        time_costs.append(time_cost)
        logger.info(f'Episode: {ep + 1}, reward: {reward:.2f}')

    logger.info(f'Avg reward: {np.mean(rewards):.2f}, sd of mean: {np.std(rewards) / np.sqrt(len(rewards)):.2f}')
    logger.info(f'Time per rollout: {np.mean(time_costs)}s')


if __name__ == '__main__':
    args = parse_args()
    gin.parse_config_file(os.path.join(args.log_dir, 'config.gin'))
    main(args)


================================================================================
# End of file: pretrained/cartpole_pi_clean/eval_agent_with_hooks.py
================================================================================


================================================================================
# File 11/28: pretrained/cartpole_pi_left_horz_pole/eval_agent_with_hooks.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/pretrained/cartpole_pi_left_horz_pole/eval_agent_with_hooks.py
# File type: Python
================================================================================

import argparse
import gin
import os
import util
import numpy as np
import time
import torch
from pathlib import Path
import matplotlib as mpl
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import ImageSequenceClip

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--log-dir', help='Directory of logs.')
    parser.add_argument(
        '--model-filename', default='model.npz',
        help='File name of the model to evaluate.')
    parser.add_argument(
        '--n-episodes', help='Number of episodes to evaluate.',
        type=int, default=3)
    parser.add_argument(
        '--seed', help='Random seed for evaluation.', type=int, default=1)
    parser.add_argument(
        '--prefix', default='default',
        help = 'Prefix for logging and video names.'
    )
    parser.add_argument(
        '--pos', type=int, default=2,
        help='Position to ablate in the attention matrix.'
    )
    parser.add_argument(
        '--dim', type=int, default=0,
        help='Dimension to ablate in the attention matrix.'
    )
    config, _ = parser.parse_known_args()
    return config

def mask(pos, dim=1):
    """
    Mask out the activations at that specific position.
    """
    def ablation(x):
        # Mask out the activations at the specified position in the tensor x
        x.index_fill_(dim=dim, index=torch.tensor([pos]), value=-1)
        # print(x)
        return x

    return ablation

def main(config):

    hook_fns = {
        # 'pi_layer_activations': {
        #     'attention_matrix': mask(config.pos, dim = config.dim)
        # },
    }

    EXPT = Path(config.log_dir, config.prefix)
    EXPT.mkdir(parents=True, exist_ok=True)

    logger = util.create_logger(name=f'test_log', log_dir=config.log_dir)
    task = util.create_task(logger=logger)
    task.seed(config.seed)

    solution = util.create_solution(device='cpu:0', hook_fns = hook_fns)
    model_file = os.path.join(config.log_dir, config.model_filename)
    solution.load(model_file)

    print(f'Loaded model from {model_file}')
    print(solution.pi_layer)
    print(solution.net)

    for name, module in solution.pi_layer.named_modules():
        print(name, module)

    ATTENTION_CMAP = mpl.colormaps.get_cmap('viridis')
    def attention_to_rgb(attention_matrix):
        """
        Convert attention matrix to RGB image.
        Expected shape: (batch, d_feats, d_obspos)
        """
        attention_matrix = attention_matrix.squeeze()
        rgb_image = ATTENTION_CMAP(attention_matrix)[..., :3]  # Drop alpha channel
        return (rgb_image * 255).astype(np.uint8)

    VIDEOS = Path(EXPT, 'videos')
    VIDEOS.mkdir(parents=True, exist_ok=True)


    HOOK_DATA = Path(EXPT, 'hook_data')
    HOOK_DATA.mkdir(parents=True, exist_ok=True)
    def make_video(frames, filename):
        """
        Save frames as a video.
        """
        clip = ImageSequenceClip(list(frames), fps=24)
        clip.write_videofile(str(filename), codec='libx264', audio=False)

    rewards = []
    time_costs = []
    for ep in range(config.n_episodes):
        print(dir(solution))
        start_time = time.perf_counter()
        reward, frames = task.rollout(solution=solution, evaluation=True)

        # Shape: (n_frames, d_feats, d_obspos)
        attention_matrices = np.array([
            x['pi_layer_activations']['attention_matrix'].numpy() 
            for x in solution.full_hook_data
        ])

        # Scale the matrix to the desired size.
        attention_matrices = np.kron(attention_matrices, np.ones((1, 16, 16)))

        # Shape: (n_frames, h, w, c)
        frames = np.array(frames[:-1])
        # Attach the frames to the hook data.
        for i, frame in enumerate(frames):
            solution.full_hook_data[i]['permutation'] = task.perm_ix
            solution.full_hook_data[i]['video_frame'] = frame

        # print(attention_matrices.shape, frames.shape)
        # Now shape: (n_frames, d_feats, d_obspos, 3)
        attention_matrices = attention_to_rgb(attention_matrices)
        # print("RENDERED SHAPE")
        # print(attention_matrices.shape, frames.shape)

        pad_width = (frames.shape[1] - attention_matrices.shape[1])
        pad_height = (frames.shape[2] // 2 - attention_matrices.shape[2])
        # Now hopefully, shape: (n_frames, h, w, 3)
        attention_matrices = np.pad(
            attention_matrices,
            ((0, 0), (pad_width, 0), (pad_height // 2, pad_height // 2), (0, 0)),
            mode='constant', constant_values = 255
        )
        print("POST-PADDING SHAPE")
        print(attention_matrices.shape, frames.shape)

        def add_text(frame, text, position = (10, 10), font_size=20):
            """
            Add text to a frame.
            """
            img = Image.fromarray(frame.copy())
            draw = ImageDraw.Draw(img)
            font = ImageFont.load_default(size = font_size)
            draw.text(position, text, fill=(0, 0, 0), font=font)
            return np.array(img)

        obs = [[round(x[0], 4) for x in solution.full_hook_data[i]["pi_layer_activations"]["obs"].tolist()] for i in range(len(solution.full_hook_data))]
        # print(obs)
        # Add the observation space to the frames.
        frames = np.array([
            add_text(frame, f'x,v,t,w\n{obs[i]}', position = (20, 20))
            for i, frame in enumerate(frames)
        ])

        frames = np.concatenate([frames, attention_matrices], axis=-2)
        # Save as video.
        make_video(frames, VIDEOS / f'video_ep_{ep}.mp4')
        # Save the hook data.
        torch.save(solution.full_hook_data, 
            HOOK_DATA / f'hook_data_ep_{ep}.pt'
        )
        

        time_cost = time.perf_counter() - start_time
        rewards.append(reward)
        time_costs.append(time_cost)
        logger.info(f'Episode: {ep + 1}, reward: {reward:.2f}')

    logger.info(f'Avg reward: {np.mean(rewards):.2f}, sd of mean: {np.std(rewards) / np.sqrt(len(rewards)):.2f}')
    logger.info(f'Time per rollout: {np.mean(time_costs)}s')


if __name__ == '__main__':
    args = parse_args()
    gin.parse_config_file(os.path.join(args.log_dir, 'config.gin'))
    main(args)


================================================================================
# End of file: pretrained/cartpole_pi_left_horz_pole/eval_agent_with_hooks.py
================================================================================


================================================================================
# File 12/28: pretrained/cartpole_pi_left_horz_pole_1/eval_agent_with_hooks.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/pretrained/cartpole_pi_left_horz_pole_1/eval_agent_with_hooks.py
# File type: Python
================================================================================

import argparse
import gin
import os
import util
import numpy as np
import time
import torch
from pathlib import Path
import matplotlib as mpl
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import ImageSequenceClip

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--log-dir', help='Directory of logs.')
    parser.add_argument(
        '--model-filename', default='model.npz',
        help='File name of the model to evaluate.')
    parser.add_argument(
        '--n-episodes', help='Number of episodes to evaluate.',
        type=int, default=3)
    parser.add_argument(
        '--seed', help='Random seed for evaluation.', type=int, default=1)
    parser.add_argument(
        '--prefix', default='default',
        help = 'Prefix for logging and video names.'
    )
    parser.add_argument(
        '--pos', type=int, default=2,
        help='Position to ablate in the attention matrix.'
    )
    parser.add_argument(
        '--dim', type=int, default=0,
        help='Dimension to ablate in the attention matrix.'
    )
    config, _ = parser.parse_known_args()
    return config

def mask(pos, dim=1):
    """
    Mask out the activations at that specific position.
    """
    def ablation(x):
        # Mask out the activations at the specified position in the tensor x
        x.index_fill_(dim=dim, index=torch.tensor([pos]), value=-1)
        # print(x)
        return x

    return ablation

def main(config):

    hook_fns = {
        # 'pi_layer_activations': {
        #     'attention_matrix': mask(config.pos, dim = config.dim)
        # },
    }

    EXPT = Path(config.log_dir, config.prefix)
    EXPT.mkdir(parents=True, exist_ok=True)

    logger = util.create_logger(name=f'test_log', log_dir=config.log_dir)
    task = util.create_task(logger=logger)
    task.seed(config.seed)

    solution = util.create_solution(device='cpu:0', hook_fns = hook_fns)
    model_file = os.path.join(config.log_dir, config.model_filename)
    solution.load(model_file)

    print(f'Loaded model from {model_file}')
    print(solution.pi_layer)
    print(solution.net)

    for name, module in solution.pi_layer.named_modules():
        print(name, module)

    ATTENTION_CMAP = mpl.colormaps.get_cmap('viridis')
    def attention_to_rgb(attention_matrix):
        """
        Convert attention matrix to RGB image.
        Expected shape: (batch, d_feats, d_obspos)
        """
        attention_matrix = attention_matrix.squeeze()
        rgb_image = ATTENTION_CMAP(attention_matrix)[..., :3]  # Drop alpha channel
        return (rgb_image * 255).astype(np.uint8)

    VIDEOS = Path(EXPT, 'videos')
    VIDEOS.mkdir(parents=True, exist_ok=True)


    HOOK_DATA = Path(EXPT, 'hook_data')
    HOOK_DATA.mkdir(parents=True, exist_ok=True)
    def make_video(frames, filename):
        """
        Save frames as a video.
        """
        clip = ImageSequenceClip(list(frames), fps=24)
        clip.write_videofile(str(filename), codec='libx264', audio=False)

    rewards = []
    time_costs = []
    for ep in range(config.n_episodes):
        print(dir(solution))
        start_time = time.perf_counter()
        reward, frames = task.rollout(solution=solution, evaluation=True)

        # Shape: (n_frames, d_feats, d_obspos)
        attention_matrices = np.array([
            x['pi_layer_activations']['attention_matrix'].numpy() 
            for x in solution.full_hook_data
        ])

        # Scale the matrix to the desired size.
        attention_matrices = np.kron(attention_matrices, np.ones((1, 16, 16)))

        # Shape: (n_frames, h, w, c)
        frames = np.array(frames[:-1])
        # Attach the frames to the hook data.
        for i, frame in enumerate(frames):
            solution.full_hook_data[i]['permutation'] = task.perm_ix
            solution.full_hook_data[i]['video_frame'] = frame

        # print(attention_matrices.shape, frames.shape)
        # Now shape: (n_frames, d_feats, d_obspos, 3)
        attention_matrices = attention_to_rgb(attention_matrices)
        # print("RENDERED SHAPE")
        # print(attention_matrices.shape, frames.shape)

        pad_width = (frames.shape[1] - attention_matrices.shape[1])
        pad_height = (frames.shape[2] // 2 - attention_matrices.shape[2])
        # Now hopefully, shape: (n_frames, h, w, 3)
        attention_matrices = np.pad(
            attention_matrices,
            ((0, 0), (pad_width, 0), (pad_height // 2, pad_height // 2), (0, 0)),
            mode='constant', constant_values = 255
        )
        print("POST-PADDING SHAPE")
        print(attention_matrices.shape, frames.shape)

        def add_text(frame, text, position = (10, 10), font_size=20):
            """
            Add text to a frame.
            """
            img = Image.fromarray(frame.copy())
            draw = ImageDraw.Draw(img)
            font = ImageFont.load_default(size = font_size)
            draw.text(position, text, fill=(0, 0, 0), font=font)
            return np.array(img)

        obs = [[round(x[0], 4) for x in solution.full_hook_data[i]["pi_layer_activations"]["obs"].tolist()] for i in range(len(solution.full_hook_data))]
        # print(obs)
        # Add the observation space to the frames.
        frames = np.array([
            add_text(frame, f'x,v,t,w\n{obs[i]}', position = (20, 20))
            for i, frame in enumerate(frames)
        ])

        frames = np.concatenate([frames, attention_matrices], axis=-2)
        # Save as video.
        make_video(frames, VIDEOS / f'video_ep_{ep}.mp4')
        # Save the hook data.
        torch.save(solution.full_hook_data, 
            HOOK_DATA / f'hook_data_ep_{ep}.pt'
        )
        

        time_cost = time.perf_counter() - start_time
        rewards.append(reward)
        time_costs.append(time_cost)
        logger.info(f'Episode: {ep + 1}, reward: {reward:.2f}')

    logger.info(f'Avg reward: {np.mean(rewards):.2f}, sd of mean: {np.std(rewards) / np.sqrt(len(rewards)):.2f}')
    logger.info(f'Time per rollout: {np.mean(time_costs)}s')


if __name__ == '__main__':
    args = parse_args()
    gin.parse_config_file(os.path.join(args.log_dir, 'config.gin'))
    main(args)


================================================================================
# End of file: pretrained/cartpole_pi_left_horz_pole_1/eval_agent_with_hooks.py
================================================================================


================================================================================
# File 13/28: pretrained/cartpole_pi_left_horz_pole_mean/eval_agent_with_hooks.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/pretrained/cartpole_pi_left_horz_pole_mean/eval_agent_with_hooks.py
# File type: Python
================================================================================

import argparse
import gin
import os
import util
import numpy as np
import time
import torch
from pathlib import Path
import matplotlib as mpl
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import ImageSequenceClip

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--log-dir', help='Directory of logs.')
    parser.add_argument(
        '--model-filename', default='model.npz',
        help='File name of the model to evaluate.')
    parser.add_argument(
        '--n-episodes', help='Number of episodes to evaluate.',
        type=int, default=3)
    parser.add_argument(
        '--seed', help='Random seed for evaluation.', type=int, default=1)
    parser.add_argument(
        '--prefix', default='default',
        help = 'Prefix for logging and video names.'
    )
    parser.add_argument(
        '--pos', type=int, default=2,
        help='Position to ablate in the attention matrix.'
    )
    parser.add_argument(
        '--dim', type=int, default=0,
        help='Dimension to ablate in the attention matrix.'
    )
    config, _ = parser.parse_known_args()
    return config

def main(config):

    EXPT = Path(config.log_dir, config.prefix)
    EXPT.mkdir(parents=True, exist_ok=True)

    logger = util.create_logger(name=f'test_log', log_dir=config.log_dir)
    task = util.create_task(logger=logger)
    task.seed(config.seed)

    def get_permutation_ix():
        """
        Get the permutation index for the task.
        """
        # This is a hack to get the permutation index from the task.
        # The task should have a method to get the permutation index.
        return task.perm_ix

    def mask(pos, dim=1):
        """
        Mask out the activations at that specific position.
        """
        def ablation(x):
            # Mask out the activations at the specified position in the tensor x
            if dim == 1:
                newp = get_permutation_ix().tolist().index(pos)
            else:
                newp = pos
            x.index_fill_(dim=dim, index=torch.tensor([newp]), value=-1)
            # print(x)
            return x

        return ablation

    def zero_lstm_state():
        """
        Zero out the activations.
        """
        def ablation(x):
            x[0].zero_()
            x[1].zero_()
            return x

        return ablation
    
    def mean_ablate(lst):
        """
        Ablate the activations in the tensor x by taking the mean of the specified entries.
        The first entry should be the new value, and the
        second entry should be the coordinates to modify.
        """
        def ablation(x):
            for i, coords in enumerate(lst):
                # print(f'Modifying {i}th entry with value {new_value} at coords {coords}')
                coords = (coords[0], get_permutation_ix().tolist().index(coords[1]))
                x[coords] = x.mean()
            return x

        return ablation

    def modify(lst):
        """
        Modify the activations in the tensor x.
        The first entry should be the new value, and the
        second entry should be the coordinates to modify.
        """
        def ablation(x):
            for i, (new_value, coords) in enumerate(lst):
                # print(f'Modifying {i}th entry with value {new_value} at coords {coords}')
                coords = (coords[0], get_permutation_ix().tolist().index(coords[1]))
                x[coords] = new_value
            return x

        return ablation

    def compose(ablations):
        """
        Compose multiple ablation functions.
        """
        def ablation(x):
            for fn in reversed(ablations):
                x = fn(x)
            return x

        return ablation

    hook_fns = {
        'pi_layer_activations': {
            # 'attention_matrix': mask(config.pos, dim = config.dim),
            # 'hx_prev': zero_lstm_state(),

            # Remove a crucial part of how the model recognizes it is moving left with the 
            # pole at an angle of -pi/2.
            # THEORETICALLY, since the information never makes it into the LSTM,
            # the model will never recognize when it is in this state.
            # 'attention_matrix': modify([(-1., (0, 4))])
            # 'attention_matrix': modify([(1., (0, 4))])

            # Mean Ablation
            'attention_matrix': mean_ablate([(0, 4)])
            
            # 'attention_matrix': compose(
            # [
            #     modify([
            #         (1., (0, 1)), (1., (6, 1)), (1., (12, 1)), (1., (13, 1)), (1., (14, 2)), (1., (14, 3)),
            #         # *[(1, (i, 1)) for i in range(15)],
            #         *[(1, (i, 4)) for i in range(15)]
            #     ]),
            # ]
            # )
        },
    }


    solution = util.create_solution(device='cpu:0', hook_fns = hook_fns)
    model_file = os.path.join(config.log_dir, config.model_filename)
    solution.load(model_file)

    print(f'Loaded model from {model_file}')
    print(solution.pi_layer)
    print(solution.net)

    for name, module in solution.pi_layer.named_modules():
        print(name, module)

    ATTENTION_CMAP = mpl.colormaps.get_cmap('viridis')
    def attention_to_rgb(attention_matrix):
        """
        Convert attention matrix to RGB image.
        Expected shape: (batch, d_feats, d_obspos)
        """
        attention_matrix = attention_matrix.squeeze()
        rgb_image = ATTENTION_CMAP(attention_matrix)[..., :3]  # Drop alpha channel
        return (rgb_image * 255).astype(np.uint8)

    VIDEOS = Path(EXPT, 'videos')
    VIDEOS.mkdir(parents=True, exist_ok=True)


    HOOK_DATA = Path(EXPT, 'hook_data')
    HOOK_DATA.mkdir(parents=True, exist_ok=True)
    def make_video(frames, filename):
        """
        Save frames as a video.
        """

        clip = ImageSequenceClip(list(frames), fps=24)
        clip.write_videofile(str(filename), codec='libx264', audio=False)

    rewards = []
    time_costs = []
    for ep in range(config.n_episodes):
        start_time = time.perf_counter()
        reward, frames, permutations = task.rollout(solution=solution, evaluation=True)

        # Shape: (n_frames, d_feats, d_obspos)
        attention_matrices = np.array([
            x['pi_layer_activations']['attention_matrix'].numpy() 
            for x in solution.full_hook_data
        ])

        # Scale the matrix to the desired size.
        attention_matrices = np.kron(attention_matrices, np.ones((1, 16, 16)))

        # Shape: (n_frames, h, w, c)
        frames = np.array(frames[:-1])
        # Attach the frames to the hook data.
        for i in range(len(solution.full_hook_data)):
            solution.full_hook_data[i]['permutation'] = permutations[i]
        # for i, frame in enumerate(frames):
            # solution.full_hook_data[i]['permutation'] = task.perm_ix
            # solution.full_hook_data[i]['video_frame'] = frame

        # print(attention_matrices.shape, frames.shape)
        # Now shape: (n_frames, d_feats, d_obspos, 3)
        # attention_matrices = attention_to_rgb(attention_matrices)
        # # print("RENDERED SHAPE")
        # # print(attention_matrices.shape, frames.shape)

        # pad_width = (frames.shape[1] - attention_matrices.shape[1])
        # pad_height = (frames.shape[2] // 2 - attention_matrices.shape[2])
        # # Now hopefully, shape: (n_frames, h, w, 3)
        # attention_matrices = np.pad(
        #     attention_matrices,
        #     ((0, 0), (pad_width, 0), (pad_height // 2, pad_height // 2), (0, 0)),
        #     mode='constant', constant_values = 255
        # )
        # print("POST-PADDING SHAPE")
        # print(attention_matrices.shape, frames.shape)

        # def add_text(frame, text, position = (10, 10), font_size=20):
        #     """
        #     Add text to a frame.
        #     """
        #     img = Image.fromarray(frame.copy())
        #     draw = ImageDraw.Draw(img)
        #     font = ImageFont.load_default(size = font_size)
        #     draw.text(position, text, fill=(0, 0, 0), font=font)
        #     return np.array(img)

        # obs = [[round(x[0], 4) for x in solution.full_hook_data[i]["pi_layer_activations"]["obs"].tolist()] for i in range(len(solution.full_hook_data))]
        # print(obs)
        # Add the observation space to the frames.
        # frames = np.array([
        #     add_text(frame, f'x,v,t,w\n{obs[i]}', position = (20, 20))
        #     for i, frame in enumerate(frames)
        # ])

        # frames = np.concatenate([frames, attention_matrices], axis=-2)
        # Save as video.
        make_video(frames, VIDEOS / f'video_ep_{ep}.mp4')
        # Save the hook data.
        torch.save(solution.full_hook_data, 
            HOOK_DATA / f'hook_data_ep_{ep}.pt'
        )
        
        time_cost = time.perf_counter() - start_time
        rewards.append(reward)
        time_costs.append(time_cost)
        logger.info(f'Episode: {ep + 1}, reward: {reward:.2f}')

    logger.info(f'Avg reward: {np.mean(rewards):.2f}, sd of mean: {np.std(rewards) / np.sqrt(len(rewards)):.2f}')
    logger.info(f'Time per rollout: {np.mean(time_costs)}s')


if __name__ == '__main__':
    args = parse_args()
    gin.parse_config_file(os.path.join(args.log_dir, 'config.gin'))
    main(args)


================================================================================
# End of file: pretrained/cartpole_pi_left_horz_pole_mean/eval_agent_with_hooks.py
================================================================================


================================================================================
# File 14/28: pretrained/cartpole_pi_perturb/eval_agent_with_hooks.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/pretrained/cartpole_pi_perturb/eval_agent_with_hooks.py
# File type: Python
================================================================================

import argparse
import gin
import os
import util
import numpy as np
import time
import torch
from pathlib import Path
import matplotlib as mpl
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import ImageSequenceClip

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--log-dir', help='Directory of logs.')
    parser.add_argument(
        '--model-filename', default='model.npz',
        help='File name of the model to evaluate.')
    parser.add_argument(
        '--n-episodes', help='Number of episodes to evaluate.',
        type=int, default=3)
    parser.add_argument(
        '--seed', help='Random seed for evaluation.', type=int, default=1)
    parser.add_argument(
        '--prefix', default='default',
        help = 'Prefix for logging and video names.'
    )
    parser.add_argument(
        '--pos', type=int, default=2,
        help='Position to ablate in the attention matrix.'
    )
    parser.add_argument(
        '--dim', type=int, default=0,
        help='Dimension to ablate in the attention matrix.'
    )
    config, _ = parser.parse_known_args()
    return config

def mask(pos, dim=1):
    """
    Mask out the activations at that specific position.
    """
    def ablation(x):
        # Mask out the activations at the specified position in the tensor x
        x.index_fill_(dim=dim, index=torch.tensor([pos]), value=-1)
        # print(x)
        return x

    return ablation

def main(config):

    hook_fns = {
        # 'pi_layer_activations': {
        #     'attention_matrix': mask(config.pos, dim = config.dim)
        # },
    }

    EXPT = Path(config.log_dir, config.prefix)
    EXPT.mkdir(parents=True, exist_ok=True)

    logger = util.create_logger(name=f'test_log', log_dir=config.log_dir)
    task = util.create_task(logger=logger)
    task.seed(config.seed)

    solution = util.create_solution(device='cpu:0', hook_fns = hook_fns)
    model_file = os.path.join(config.log_dir, config.model_filename)
    solution.load(model_file)

    print(f'Loaded model from {model_file}')
    print(solution.pi_layer)
    print(solution.net)

    for name, module in solution.pi_layer.named_modules():
        print(name, module)

    ATTENTION_CMAP = mpl.colormaps.get_cmap('viridis')
    def attention_to_rgb(attention_matrix):
        """
        Convert attention matrix to RGB image.
        Expected shape: (batch, d_feats, d_obspos)
        """
        attention_matrix = attention_matrix.squeeze()
        rgb_image = ATTENTION_CMAP(attention_matrix)[..., :3]  # Drop alpha channel
        return (rgb_image * 255).astype(np.uint8)

    VIDEOS = Path(EXPT, 'videos')
    VIDEOS.mkdir(parents=True, exist_ok=True)


    HOOK_DATA = Path(EXPT, 'hook_data')
    HOOK_DATA.mkdir(parents=True, exist_ok=True)
    def make_video(frames, filename):
        """
        Save frames as a video.
        """
        clip = ImageSequenceClip(list(frames), fps=24)
        clip.write_videofile(str(filename), codec='libx264', audio=False)

    rewards = []
    time_costs = []
    for ep in range(config.n_episodes):
        print(dir(solution))
        start_time = time.perf_counter()
        reward, frames = task.rollout(solution=solution, evaluation=True)

        # Shape: (n_frames, d_feats, d_obspos)
        attention_matrices = np.array([
            x['pi_layer_activations']['attention_matrix'].numpy() 
            for x in solution.full_hook_data
        ])

        # Scale the matrix to the desired size.
        attention_matrices = np.kron(attention_matrices, np.ones((1, 16, 16)))

        # Shape: (n_frames, h, w, c)
        frames = np.array(frames[:-1])
        # Attach the frames to the hook data.
        for i, frame in enumerate(frames):
            solution.full_hook_data[i]['permutation'] = task.perm_ix
            solution.full_hook_data[i]['video_frame'] = frame

        # print(attention_matrices.shape, frames.shape)
        # Now shape: (n_frames, d_feats, d_obspos, 3)
        attention_matrices = attention_to_rgb(attention_matrices)
        # print("RENDERED SHAPE")
        # print(attention_matrices.shape, frames.shape)

        pad_width = (frames.shape[1] - attention_matrices.shape[1])
        pad_height = (frames.shape[2] // 2 - attention_matrices.shape[2])
        # Now hopefully, shape: (n_frames, h, w, 3)
        attention_matrices = np.pad(
            attention_matrices,
            ((0, 0), (pad_width, 0), (pad_height // 2, pad_height // 2), (0, 0)),
            mode='constant', constant_values = 255
        )
        print("POST-PADDING SHAPE")
        print(attention_matrices.shape, frames.shape)

        def add_text(frame, text, position = (10, 10), font_size=20):
            """
            Add text to a frame.
            """
            img = Image.fromarray(frame.copy())
            draw = ImageDraw.Draw(img)
            font = ImageFont.load_default(size = font_size)
            draw.text(position, text, fill=(0, 0, 0), font=font)
            return np.array(img)

        obs = [[round(x[0], 4) for x in solution.full_hook_data[i]["pi_layer_activations"]["obs"].tolist()] for i in range(len(solution.full_hook_data))]
        # print(obs)
        # Add the observation space to the frames.
        frames = np.array([
            add_text(frame, f'x,v,t,w\n{obs[i]}', position = (20, 20))
            for i, frame in enumerate(frames)
        ])

        frames = np.concatenate([frames, attention_matrices], axis=-2)
        # Save as video.
        make_video(frames, VIDEOS / f'video_ep_{ep}.mp4')
        # Save the hook data.
        torch.save(solution.full_hook_data, 
            HOOK_DATA / f'hook_data_ep_{ep}.pt'
        )
        

        time_cost = time.perf_counter() - start_time
        rewards.append(reward)
        time_costs.append(time_cost)
        logger.info(f'Episode: {ep + 1}, reward: {reward:.2f}')

    logger.info(f'Avg reward: {np.mean(rewards):.2f}, sd of mean: {np.std(rewards) / np.sqrt(len(rewards)):.2f}')
    logger.info(f'Time per rollout: {np.mean(time_costs)}s')


if __name__ == '__main__':
    args = parse_args()
    gin.parse_config_file(os.path.join(args.log_dir, 'config.gin'))
    main(args)


================================================================================
# End of file: pretrained/cartpole_pi_perturb/eval_agent_with_hooks.py
================================================================================


================================================================================
# File 15/28: pretrained/cartpole_pi_perturb_shuffle_hs/eval_agent_with_hooks.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/pretrained/cartpole_pi_perturb_shuffle_hs/eval_agent_with_hooks.py
# File type: Python
================================================================================

import argparse
import gin
import os
import util
import numpy as np
import time
import torch
from pathlib import Path
import matplotlib as mpl
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import ImageSequenceClip

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--log-dir', help='Directory of logs.')
    parser.add_argument(
        '--model-filename', default='model.npz',
        help='File name of the model to evaluate.')
    parser.add_argument(
        '--n-episodes', help='Number of episodes to evaluate.',
        type=int, default=3)
    parser.add_argument(
        '--seed', help='Random seed for evaluation.', type=int, default=1)
    parser.add_argument(
        '--prefix', default='default',
        help = 'Prefix for logging and video names.'
    )
    parser.add_argument(
        '--pos', type=int, default=2,
        help='Position to ablate in the attention matrix.'
    )
    parser.add_argument(
        '--dim', type=int, default=0,
        help='Dimension to ablate in the attention matrix.'
    )
    config, _ = parser.parse_known_args()
    return config

def mask(pos, dim=1):
    """
    Mask out the activations at that specific position.
    """
    def ablation(x):
        # Mask out the activations at the specified position in the tensor x
        x.index_fill_(dim=dim, index=torch.tensor([pos]), value=-1)
        # print(x)
        return x

    return ablation

def main(config):

    hook_fns = {
        # 'pi_layer_activations': {
        #     'attention_matrix': mask(config.pos, dim = config.dim)
        # },
    }

    EXPT = Path(config.log_dir, config.prefix)
    EXPT.mkdir(parents=True, exist_ok=True)

    logger = util.create_logger(name=f'test_log', log_dir=config.log_dir)
    task = util.create_task(logger=logger)
    task.seed(config.seed)

    solution = util.create_solution(device='cpu:0', hook_fns = hook_fns)
    model_file = os.path.join(config.log_dir, config.model_filename)
    solution.load(model_file)

    print(f'Loaded model from {model_file}')
    print(solution.pi_layer)
    print(solution.net)

    for name, module in solution.pi_layer.named_modules():
        print(name, module)

    ATTENTION_CMAP = mpl.colormaps.get_cmap('viridis')
    def attention_to_rgb(attention_matrix):
        """
        Convert attention matrix to RGB image.
        Expected shape: (batch, d_feats, d_obspos)
        """
        attention_matrix = attention_matrix.squeeze()
        rgb_image = ATTENTION_CMAP(attention_matrix)[..., :3]  # Drop alpha channel
        return (rgb_image * 255).astype(np.uint8)

    VIDEOS = Path(EXPT, 'videos')
    VIDEOS.mkdir(parents=True, exist_ok=True)


    HOOK_DATA = Path(EXPT, 'hook_data')
    HOOK_DATA.mkdir(parents=True, exist_ok=True)
    def make_video(frames, filename):
        """
        Save frames as a video.
        """
        clip = ImageSequenceClip(list(frames), fps=24)
        clip.write_videofile(str(filename), codec='libx264', audio=False)

    rewards = []
    time_costs = []
    for ep in range(config.n_episodes):
        print(dir(solution))
        start_time = time.perf_counter()
        reward, frames = task.rollout(solution=solution, evaluation=True)

        # Shape: (n_frames, d_feats, d_obspos)
        attention_matrices = np.array([
            x['pi_layer_activations']['attention_matrix'].numpy() 
            for x in solution.full_hook_data
        ])

        # Scale the matrix to the desired size.
        attention_matrices = np.kron(attention_matrices, np.ones((1, 16, 16)))

        # Shape: (n_frames, h, w, c)
        frames = np.array(frames[:-1])
        # Attach the frames to the hook data.
        for i, frame in enumerate(frames):
            solution.full_hook_data[i]['permutation'] = task.perm_ix
            solution.full_hook_data[i]['video_frame'] = frame

        # print(attention_matrices.shape, frames.shape)
        # Now shape: (n_frames, d_feats, d_obspos, 3)
        attention_matrices = attention_to_rgb(attention_matrices)
        # print("RENDERED SHAPE")
        # print(attention_matrices.shape, frames.shape)

        pad_width = (frames.shape[1] - attention_matrices.shape[1])
        pad_height = (frames.shape[2] // 2 - attention_matrices.shape[2])
        # Now hopefully, shape: (n_frames, h, w, 3)
        attention_matrices = np.pad(
            attention_matrices,
            ((0, 0), (pad_width, 0), (pad_height // 2, pad_height // 2), (0, 0)),
            mode='constant', constant_values = 255
        )
        print("POST-PADDING SHAPE")
        print(attention_matrices.shape, frames.shape)

        def add_text(frame, text, position = (10, 10), font_size=20):
            """
            Add text to a frame.
            """
            img = Image.fromarray(frame.copy())
            draw = ImageDraw.Draw(img)
            font = ImageFont.load_default(size = font_size)
            draw.text(position, text, fill=(0, 0, 0), font=font)
            return np.array(img)

        obs = [[round(x[0], 4) for x in solution.full_hook_data[i]["pi_layer_activations"]["obs"].tolist()] for i in range(len(solution.full_hook_data))]
        # print(obs)
        # Add the observation space to the frames.
        frames = np.array([
            add_text(frame, f'x,v,t,w\n{obs[i]}', position = (20, 20))
            for i, frame in enumerate(frames)
        ])

        frames = np.concatenate([frames, attention_matrices], axis=-2)
        # Save as video.
        make_video(frames, VIDEOS / f'video_ep_{ep}.mp4')
        # Save the hook data.
        torch.save(solution.full_hook_data, 
            HOOK_DATA / f'hook_data_ep_{ep}.pt'
        )
        

        time_cost = time.perf_counter() - start_time
        rewards.append(reward)
        time_costs.append(time_cost)
        logger.info(f'Episode: {ep + 1}, reward: {reward:.2f}')

    logger.info(f'Avg reward: {np.mean(rewards):.2f}, sd of mean: {np.std(rewards) / np.sqrt(len(rewards)):.2f}')
    logger.info(f'Time per rollout: {np.mean(time_costs)}s')


if __name__ == '__main__':
    args = parse_args()
    gin.parse_config_file(os.path.join(args.log_dir, 'config.gin'))
    main(args)


================================================================================
# End of file: pretrained/cartpole_pi_perturb_shuffle_hs/eval_agent_with_hooks.py
================================================================================


================================================================================
# File 16/28: pretrained/cartpole_pi_perturb_zero_hs/eval_agent_with_hooks.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/pretrained/cartpole_pi_perturb_zero_hs/eval_agent_with_hooks.py
# File type: Python
================================================================================

import argparse
import gin
import os
import util
import numpy as np
import time
import torch
from pathlib import Path
import matplotlib as mpl
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import ImageSequenceClip

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--log-dir', help='Directory of logs.')
    parser.add_argument(
        '--model-filename', default='model.npz',
        help='File name of the model to evaluate.')
    parser.add_argument(
        '--n-episodes', help='Number of episodes to evaluate.',
        type=int, default=3)
    parser.add_argument(
        '--seed', help='Random seed for evaluation.', type=int, default=1)
    parser.add_argument(
        '--prefix', default='default',
        help = 'Prefix for logging and video names.'
    )
    parser.add_argument(
        '--pos', type=int, default=2,
        help='Position to ablate in the attention matrix.'
    )
    parser.add_argument(
        '--dim', type=int, default=0,
        help='Dimension to ablate in the attention matrix.'
    )
    config, _ = parser.parse_known_args()
    return config

def mask(pos, dim=1):
    """
    Mask out the activations at that specific position.
    """
    def ablation(x):
        # Mask out the activations at the specified position in the tensor x
        x.index_fill_(dim=dim, index=torch.tensor([pos]), value=-1)
        # print(x)
        return x

    return ablation

def main(config):

    hook_fns = {
        # 'pi_layer_activations': {
        #     'attention_matrix': mask(config.pos, dim = config.dim)
        # },
    }

    EXPT = Path(config.log_dir, config.prefix)
    EXPT.mkdir(parents=True, exist_ok=True)

    logger = util.create_logger(name=f'test_log', log_dir=config.log_dir)
    task = util.create_task(logger=logger)
    task.seed(config.seed)

    solution = util.create_solution(device='cpu:0', hook_fns = hook_fns)
    model_file = os.path.join(config.log_dir, config.model_filename)
    solution.load(model_file)

    print(f'Loaded model from {model_file}')
    print(solution.pi_layer)
    print(solution.net)

    for name, module in solution.pi_layer.named_modules():
        print(name, module)

    ATTENTION_CMAP = mpl.colormaps.get_cmap('viridis')
    def attention_to_rgb(attention_matrix):
        """
        Convert attention matrix to RGB image.
        Expected shape: (batch, d_feats, d_obspos)
        """
        attention_matrix = attention_matrix.squeeze()
        rgb_image = ATTENTION_CMAP(attention_matrix)[..., :3]  # Drop alpha channel
        return (rgb_image * 255).astype(np.uint8)

    VIDEOS = Path(EXPT, 'videos')
    VIDEOS.mkdir(parents=True, exist_ok=True)


    HOOK_DATA = Path(EXPT, 'hook_data')
    HOOK_DATA.mkdir(parents=True, exist_ok=True)
    def make_video(frames, filename):
        """
        Save frames as a video.
        """
        clip = ImageSequenceClip(list(frames), fps=24)
        clip.write_videofile(str(filename), codec='libx264', audio=False)

    rewards = []
    time_costs = []
    for ep in range(config.n_episodes):
        print(dir(solution))
        start_time = time.perf_counter()
        reward, frames = task.rollout(solution=solution, evaluation=True)

        # Shape: (n_frames, d_feats, d_obspos)
        attention_matrices = np.array([
            x['pi_layer_activations']['attention_matrix'].numpy() 
            for x in solution.full_hook_data
        ])

        # Scale the matrix to the desired size.
        attention_matrices = np.kron(attention_matrices, np.ones((1, 16, 16)))

        # Shape: (n_frames, h, w, c)
        frames = np.array(frames[:-1])
        # Attach the frames to the hook data.
        for i, frame in enumerate(frames):
            solution.full_hook_data[i]['permutation'] = task.perm_ix
            solution.full_hook_data[i]['video_frame'] = frame

        # print(attention_matrices.shape, frames.shape)
        # Now shape: (n_frames, d_feats, d_obspos, 3)
        attention_matrices = attention_to_rgb(attention_matrices)
        # print("RENDERED SHAPE")
        # print(attention_matrices.shape, frames.shape)

        pad_width = (frames.shape[1] - attention_matrices.shape[1])
        pad_height = (frames.shape[2] // 2 - attention_matrices.shape[2])
        # Now hopefully, shape: (n_frames, h, w, 3)
        attention_matrices = np.pad(
            attention_matrices,
            ((0, 0), (pad_width, 0), (pad_height // 2, pad_height // 2), (0, 0)),
            mode='constant', constant_values = 255
        )
        print("POST-PADDING SHAPE")
        print(attention_matrices.shape, frames.shape)

        def add_text(frame, text, position = (10, 10), font_size=20):
            """
            Add text to a frame.
            """
            img = Image.fromarray(frame.copy())
            draw = ImageDraw.Draw(img)
            font = ImageFont.load_default(size = font_size)
            draw.text(position, text, fill=(0, 0, 0), font=font)
            return np.array(img)

        obs = [[round(x[0], 4) for x in solution.full_hook_data[i]["pi_layer_activations"]["obs"].tolist()] for i in range(len(solution.full_hook_data))]
        # print(obs)
        # Add the observation space to the frames.
        frames = np.array([
            add_text(frame, f'x,v,t,w\n{obs[i]}', position = (20, 20))
            for i, frame in enumerate(frames)
        ])

        frames = np.concatenate([frames, attention_matrices], axis=-2)
        # Save as video.
        make_video(frames, VIDEOS / f'video_ep_{ep}.mp4')
        # Save the hook data.
        torch.save(solution.full_hook_data, 
            HOOK_DATA / f'hook_data_ep_{ep}.pt'
        )
        

        time_cost = time.perf_counter() - start_time
        rewards.append(reward)
        time_costs.append(time_cost)
        logger.info(f'Episode: {ep + 1}, reward: {reward:.2f}')

    logger.info(f'Avg reward: {np.mean(rewards):.2f}, sd of mean: {np.std(rewards) / np.sqrt(len(rewards)):.2f}')
    logger.info(f'Time per rollout: {np.mean(time_costs)}s')


if __name__ == '__main__':
    args = parse_args()
    gin.parse_config_file(os.path.join(args.log_dir, 'config.gin'))
    main(args)


================================================================================
# End of file: pretrained/cartpole_pi_perturb_zero_hs/eval_agent_with_hooks.py
================================================================================


================================================================================
# File 17/28: solutions/__init__.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/solutions/__init__.py
# File type: Python
================================================================================



================================================================================
# End of file: solutions/__init__.py
================================================================================


================================================================================
# File 18/28: solutions/base_solution.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/solutions/base_solution.py
# File type: Python
================================================================================

import abc


class BaseSolution(abc.ABC):
    """Base solution."""

    @abc.abstractmethod
    def get_action(self, obs):
        raise NotImplementedError()

    @abc.abstractmethod
    def get_params(self):
        raise NotImplementedError()

    @abc.abstractmethod
    def set_params(self, params):
        raise NotImplementedError()

    @abc.abstractmethod
    def get_num_params(self):
        raise NotImplementedError()

    @abc.abstractmethod
    def save(self, filename):
        raise NotImplementedError()

    @abc.abstractmethod
    def load(self, filename):
        raise NotImplementedError()

    @abc.abstractmethod
    def reset(self):
        raise NotImplementedError()


================================================================================
# End of file: solutions/base_solution.py
================================================================================


================================================================================
# File 19/28: solutions/torch_modules.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/solutions/torch_modules.py
# File type: Python
================================================================================

import numpy as np
import torch
import torch.nn as nn


def pos_table(n, dim):
    """Create a table of positional encodings."""

    def get_angle(x, h):
        return x / np.power(10000, 2 * (h // 2) / dim)

    def get_angle_vec(x):
        return [get_angle(x, j) for j in range(dim)]

    tab = np.array([get_angle_vec(i) for i in range(n)]).astype(float)
    tab[:, 0::2] = np.sin(tab[:, 0::2])
    tab[:, 1::2] = np.cos(tab[:, 1::2])
    return tab


class AttentionMatrix(nn.Module):
    """Self-attention matrix."""

    def __init__(self, dim_in_q, dim_in_k, msg_dim, bias=True, scale=True):
        super(AttentionMatrix, self).__init__()
        self.proj_q = nn.Linear(
            in_features=dim_in_q, out_features=msg_dim, bias=bias)
        self.proj_k = nn.Linear(
            in_features=dim_in_k, out_features=msg_dim, bias=bias)
        if scale:
            self.msg_dim = msg_dim
        else:
            self.msg_dim = 1

    def forward(self, data_q, data_k):
        q = self.proj_q(data_q)
        k = self.proj_k(data_k)
        if data_q.ndim == data_k.ndim == 2:
            dot = torch.matmul(q, k.T)
        else:
            dot = torch.bmm(q, k.permute(0, 2, 1))
        return torch.div(dot, np.sqrt(self.msg_dim))


class SelfAttentionMatrix(AttentionMatrix):
    """Self-attention matrix."""

    def __init__(self, dim_in, msg_dim, bias=True, scale=True):
        super(SelfAttentionMatrix, self).__init__(
            dim_in_q=dim_in,
            dim_in_k=dim_in,
            msg_dim=msg_dim,
            bias=bias,
            scale=scale,
        )


class AttentionLayer(nn.Module):
    """The attention mechanism."""

    def __init__(self, dim_in_q, dim_in_k, dim_in_v, msg_dim, out_dim):
        super(AttentionLayer, self).__init__()
        self.attention_matrix = AttentionMatrix(
            dim_in_q=dim_in_q,
            dim_in_k=dim_in_k,
            msg_dim=msg_dim,
        )
        self.proj_v = nn.Linear(in_features=dim_in_v, out_features=out_dim)
        self.mostly_attended_entries = None

    def forward(self, data_q, data_k, data_v):
        a = torch.softmax(
            self.attention_matrix(data_q=data_q, data_k=data_k), dim=-1)
        self.mostly_attended_entries = set(torch.argmax(a, dim=-1).numpy())
        v = self.proj_v(data_v)
        return torch.matmul(a, v)


class AttentionNeuronLayer(nn.Module):
    """Permutation invariant layer."""

    def __init__(self,
                 act_dim,
                 hidden_dim,
                 msg_dim,
                 pos_em_dim,
                 bias=True,
                 scale=True):
        super(AttentionNeuronLayer, self).__init__()
        self.act_dim = act_dim
        self.hidden_dim = hidden_dim
        self.msg_dim = msg_dim
        self.pos_em_dim = pos_em_dim
        self.pos_embedding = torch.from_numpy(
            pos_table(self.hidden_dim, self.pos_em_dim)
        ).float()
        self.hx = None
        self.lstm = nn.LSTMCell(
            input_size=1 + self.act_dim, hidden_size=pos_em_dim)
        self.attention = SelfAttentionMatrix(
            dim_in=pos_em_dim, msg_dim=self.msg_dim, bias=bias, scale=scale)

    def forward(self, obs, prev_act):
        if isinstance(obs, np.ndarray):
            x = torch.from_numpy(obs.copy()).float().unsqueeze(-1)
        else:
            x = obs.unsqueeze(-1)
        obs_dim = x.shape[0]

        x_aug = torch.cat([x, torch.vstack([prev_act] * obs_dim)], dim=-1)
        if self.hx is None:
            self.hx = (
                torch.zeros(obs_dim, self.pos_em_dim).to(x.device),
                torch.zeros(obs_dim, self.pos_em_dim).to(x.device),
            )
        self.hx = self.lstm(x_aug, self.hx)

        w = torch.tanh(self.attention(
            data_q=self.pos_embedding.to(x.device), data_k=self.hx[0]))
        output = torch.matmul(w, x)
        return torch.tanh(output)

    def reset(self):
        self.hx = None

class HookedAttentionNeuronLayer(AttentionNeuronLayer):
    """
    Hooked attention neuron layer for debugging.
    This layer exposes the internal state and allows for write-then-read access to the activations.
    In other words, you can edit the results of the forward pass before they
    are cached in the activations dictionary.
    """

    def __init__(self, hook_fns = None, **kwargs):
        super(HookedAttentionNeuronLayer, self).__init__(**kwargs)
        self.hook_fns = hook_fns if hook_fns is not None else {}

    def forward(self, obs, prev_act):
        activations_dict = {}
        if isinstance(obs, np.ndarray):
            x = torch.from_numpy(obs.copy()).float().unsqueeze(-1)
        else:
            x = obs.unsqueeze(-1)
        obs_dim = x.shape[0]

        # Edit and cache the current observation.
        x = self.hook_fns.get('obs', lambda x: x)(x)
        activations_dict['obs'] = x

        # Edit and cache the previous action.
        prev_act = self.hook_fns.get('prev_act', lambda x: x)(prev_act)
        activations_dict['prev_act'] = prev_act

        x_aug = torch.cat([x, torch.vstack([prev_act] * obs_dim)], dim=-1)

        # Edit and cache the augmented input.
        x_aug = self.hook_fns.get('x_aug', lambda x: x)(x_aug)
        activations_dict['x_aug'] = x_aug
        
        if self.hx is None:
            self.hx = (
                torch.zeros(obs_dim, self.pos_em_dim).to(x.device),
                torch.zeros(obs_dim, self.pos_em_dim).to(x.device),
            )

        # Edit and cache the previous hidden state.
        # For ease of debugging, we express the hidden state as a dictionary
        # instead of a tuple.
        self.hx = self.hook_fns.get('hx_prev', lambda x: x)(self.hx)
        activations_dict['hx_prev'] = {'hidden': self.hx[0], 'cell': self.hx[1]}
        self.hx = self.lstm(x_aug, self.hx)

        # Edit and cache the current hidden state.
        # Again, we express the hidden state as a dictionary.
        self.hx = self.hook_fns.get('hx', lambda x: x)(self.hx)
        activations_dict['hx'] = {'hidden': self.hx[0], 'cell': self.hx[1]}

        # Edit and cache the positional embedding.
        # This is actually used as the query vector in the attention mechanism.
        # You can modify it to check the meaning of each feature.
        self.pos_embedding = self.hook_fns.get('pos_embedding', lambda x: x)(self.pos_embedding)
        activations_dict['pos_embedding'] = self.pos_embedding.to(x.device)
        
        # Compute the attention matrix.
        # Somewhat atypically, this attention mechanism uses Tanh instead of Softmax.        
        w = torch.tanh(self.attention(
            data_q=self.pos_embedding.to(x.device), data_k=self.hx[0]))
        
        # Edit and cache the attention matrix.
        w = self.hook_fns.get('attention_matrix', lambda x: x)(w)
        activations_dict['attention_matrix'] = w

        # Compute the output.
        output = torch.matmul(w, x)
        output = self.hook_fns.get('output', lambda x: x)(output)
        activations_dict['output'] = torch.tanh(output)

        return torch.tanh(output), activations_dict
    
    def permute_hidden_states(self, perm_ix):
        """
        Permute the hidden state according to the given indices.
        This is useful for debugging and understanding the model's behavior.
        """
        # inv_perm = np.argsort(perm_ix)
        if self.hx is not None:
            self.hx = (
                self.hx[0][perm_ix],
                self.hx[1][perm_ix],
            )
        # Otherwise, no-op, which is okay because hx will be zeros anyway.
    
    def zero_hidden_states(self):
        """
        Reset the hidden states to zero.
        This is useful for debugging and understanding the model's behavior.
        """
        self.hx = (
            torch.zeros_like(self.hx[0]),
            torch.zeros_like(self.hx[1]),
        ) if self.hx is not None else None

    # def permute_pos_embed(self, perm_ix):
    #     """
    #     Permute the positional embedding according to the given indices.
    #     This is useful for debugging and understanding the model's behavior.
    #     """
    #     self.pos_embedding = self.pos_embedding[perm_ix]

class VisionAttentionNeuronLayer(nn.Module):
    """Permutation invariant layer for vision tasks."""

    def __init__(self,
                 act_dim,
                 hidden_dim,
                 msg_dim,
                 pos_em_dim,
                 patch_size=6,
                 stack_k=4,
                 with_learnable_ln_params=False,
                 stack_dim_first=False):
        super(VisionAttentionNeuronLayer, self).__init__()
        self.act_dim = act_dim
        self.hidden_dim = hidden_dim
        self.msg_dim = msg_dim
        self.patch_size = patch_size
        self.stack_k = stack_k
        self.stack_dim_first = stack_dim_first
        self.pos_em_dim = pos_em_dim
        self.pos_embedding = torch.from_numpy(
            pos_table(self.hidden_dim, self.pos_em_dim)
        ).float()
        self.attention = AttentionLayer(
            dim_in_q=self.pos_em_dim,
            dim_in_k=(self.stack_k - 1) * self.patch_size**2 + self.act_dim,
            dim_in_v=self.stack_k * self.patch_size**2,
            msg_dim=self.msg_dim,
            out_dim=self.msg_dim,
        )
        # The normalization layers have no learnable parameters.
        self.input_ln = nn.LayerNorm(
            normalized_shape=self.patch_size**2,
            elementwise_affine=with_learnable_ln_params,
        )
        self.input_ln.eval()
        self.output_ln = nn.LayerNorm(
            normalized_shape=self.msg_dim,
            elementwise_affine=with_learnable_ln_params,
        )
        self.output_ln.eval()

    def get_patches(self, x):
        h, w, c = x.size()
        patches = x.unfold(
            0, self.patch_size, self.patch_size).permute(0, 3, 1, 2)
        patches = patches.unfold(
            2, self.patch_size, self.patch_size).permute(0, 2, 1, 4, 3)
        return patches.reshape((-1, self.patch_size, self.patch_size, c))

    def forward(self, obs, prev_act):
        if isinstance(obs, dict):
            # Puzzle pong may drop some patches.
            patch_to_keep_ix = obs['patches_to_use']
            obs = obs['obs']
        else:
            patch_to_keep_ix = None

        k, h, w = obs.shape
        assert k == self.stack_k
        if patch_to_keep_ix is None:
            num_patches = (h // self.patch_size) * (w // self.patch_size)
        else:
            num_patches = patch_to_keep_ix.size

        # AttentionNeuron is the first layer, so obs is numpy array.
        x_obs = torch.div(torch.from_numpy(obs).float(), 255.)

        # Create Key.
        x_k = torch.diff(x_obs, dim=0).permute(1, 2, 0)
        x_k = self.get_patches(x_k)
        if patch_to_keep_ix is not None:
            x_k = x_k[patch_to_keep_ix]
        assert x_k.shape == (
            num_patches, self.patch_size, self.patch_size, self.stack_k - 1)
        if self.stack_dim_first:
            x_k = x_k.permute(0, 3, 1, 2)
        x_k = torch.cat([
            torch.flatten(x_k, start_dim=1),
            torch.repeat_interleave(prev_act, repeats=num_patches, dim=0)
        ], dim=-1)

        # Create Value.
        x_v = self.get_patches(x_obs.permute(1, 2, 0)).permute(0, 3, 1, 2)
        if patch_to_keep_ix is not None:
            x_v = x_v[patch_to_keep_ix]
        x_v = self.input_ln(torch.flatten(x_v, start_dim=2))

        x = self.attention(
            data_q=self.pos_embedding,
            data_k=x_k,
            data_v=x_v.reshape(num_patches, -1),
        )
        return self.output_ln(torch.relu(x))


================================================================================
# End of file: solutions/torch_modules.py
================================================================================


================================================================================
# File 20/28: solutions/torch_solutions.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/solutions/torch_solutions.py
# File type: Python
================================================================================

import gin
import numpy as np
import torch
import torch.nn as nn
from torchvision.transforms import transforms
from solutions.base_solution import BaseSolution
from solutions.torch_modules import SelfAttentionMatrix
from solutions.torch_modules import AttentionNeuronLayer, HookedAttentionNeuronLayer
from solutions.torch_modules import VisionAttentionNeuronLayer


torch.set_num_threads(1)


class BaseTorchSolution(BaseSolution):
    """Basic torch solution."""

    def __init__(self, device):
        self.modules_to_learn = []
        self.device = torch.device(device)

    def get_action(self, obs):
        with torch.no_grad():
            return self._get_action(obs)

    def get_params(self):
        params = []
        with torch.no_grad():
            for layer in self.modules_to_learn:
                for p in layer.parameters():
                    params.append(p.cpu().numpy().ravel())
        return np.concatenate(params)

    def set_params(self, params):
        assert isinstance(params, np.ndarray)
        ss = 0
        for layer in self.modules_to_learn:
            for p in layer.parameters():
                ee = ss + np.prod(p.shape)
                p.data = torch.from_numpy(
                    params[ss:ee].reshape(p.shape)
                ).float().to(self.device)
                ss = ee
        assert ss == params.size

    def save(self, filename):
        params = self.get_params()
        np.savez(filename, params=params)

    def load(self, filename):
        with np.load(filename) as data:
            params = data['params']
            self.set_params(params)

    def get_num_params(self):
        return self.get_params().size

    def _get_action(self, obs):
        raise NotImplementedError()

    def reset(self):
        pass


@gin.configurable
class MLPSolution(BaseTorchSolution):
    """MLP solution."""

    def __init__(self, device, obs_dim, act_dim, hidden_dim, num_hidden_layers):
        super(MLPSolution, self).__init__(device=device)
        hidden_layers = []
        for _ in range(num_hidden_layers):
            hidden_layers.extend([
                nn.Linear(in_features=hidden_dim, out_features=hidden_dim),
                nn.Tanh(),
            ])
        self.net = nn.Sequential(
            nn.Linear(in_features=obs_dim, out_features=hidden_dim),
            nn.Tanh(),
            *hidden_layers,
            nn.Linear(in_features=hidden_dim, out_features=act_dim),
            nn.Tanh(),
        ).to(self.device)
        self.modules_to_learn.append(self.net)
        print('device={}, #params={}'.format(
            self.device, self.get_num_params()))

    def _get_action(self, obs):
        x = torch.from_numpy(obs.copy()).float().to(self.device)
        return self.net(x).cpu().numpy()


@gin.configurable
class AttentionAgent(BaseTorchSolution):
    """Attention Agent solution."""

    def __init__(self,
                 device,
                 image_size=96,
                 patch_size=7,
                 patch_stride=4,
                 query_dim=4,
                 hidden_dim=16,
                 top_k=10):
        super(AttentionAgent, self).__init__(device=device)
        self.image_size = image_size
        self.patch_size = patch_size
        self.patch_stride = patch_stride
        self.query_dim = query_dim
        self.hidden_dim = hidden_dim
        self.top_k = top_k
        self.transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((image_size, image_size)),
            transforms.ToTensor(),
        ])

        n = int((image_size - patch_size) / patch_stride + 1)
        offset = self.patch_size // 2
        patch_centers = []
        for i in range(n):
            patch_center_row = offset + i * patch_stride
            for j in range(n):
                patch_center_col = offset + j * patch_stride
                patch_centers.append([patch_center_row, patch_center_col])
        self.patch_centers = torch.tensor(patch_centers).float()

        self.num_patches = n ** 2
        print('num_patches={}'.format(self.num_patches))
        self.attention = SelfAttentionMatrix(
            dim_in=3 * self.patch_size ** 2,
            msg_dim=query_dim,
        )
        self.modules_to_learn.append(self.attention)

        self.hx = None
        self.lstm = nn.LSTMCell(
            input_size=self.top_k * 2,
            hidden_size=hidden_dim,
        )
        self.modules_to_learn.append(self.lstm)

        self.output_fc = nn.Sequential(
            nn.Linear(in_features=hidden_dim, out_features=3),
            nn.Tanh(),
        )
        self.modules_to_learn.append(self.output_fc)

        print('num_params={}'.format(self.get_num_params()))

    def _get_action(self, obs):
        # ob.shape = (h, w, c)
        ob = self.transform(obs).permute(1, 2, 0)
        h, w, c = ob.size()
        patches = ob.unfold(
            0, self.patch_size, self.patch_stride).permute(0, 3, 1, 2)
        patches = patches.unfold(
            2, self.patch_size, self.patch_stride).permute(0, 2, 1, 4, 3)
        patches = patches.reshape((-1, self.patch_size, self.patch_size, c))

        # flattened_patches.shape = (1, n, p * p * c)
        flattened_patches = patches.reshape(
            (1, -1, c * self.patch_size ** 2))
        # attention_matrix.shape = (1, n, n)
        attention_matrix = self.attention(flattened_patches, flattened_patches)
        # patch_importance_matrix.shape = (n, n)
        patch_importance_matrix = torch.softmax(
            attention_matrix.squeeze(), dim=-1)
        # patch_importance.shape = (n,)
        patch_importance = patch_importance_matrix.sum(dim=0)
        # extract top k important patches
        ix = torch.argsort(patch_importance, descending=True)
        top_k_ix = ix[:self.top_k]

        centers = self.patch_centers[top_k_ix]
        centers = centers.flatten(0, -1)
        centers = centers / self.image_size

        if self.hx is None:
            self.hx = (
                torch.zeros(1, self.hidden_dim),
                torch.zeros(1, self.hidden_dim),
            )
        self.hx = self.lstm(centers.unsqueeze(0), self.hx)
        output = self.output_fc(self.hx[0]).squeeze(0)
        return output.cpu().numpy()

    def reset(self):
        self.hx = None


@gin.configurable
class PIFCSolution(BaseTorchSolution):
    """Permutation invariant solution."""

    def __init__(self,
                 device,
                 act_dim,
                 hidden_dim,
                 msg_dim,
                 pos_em_dim,
                 num_hidden_layers=1,
                 pi_layer_bias=True,
                 pi_layer_scale=True):
        super(PIFCSolution, self).__init__(device=device)
        self.act_dim = act_dim
        self.hidden_dim = hidden_dim
        self.msg_dim = msg_dim
        self.pos_em_dim = pos_em_dim
        self.prev_act = torch.zeros(1, self.act_dim)

        self.pi_layer = AttentionNeuronLayer(
            act_dim=act_dim,
            hidden_dim=hidden_dim,
            msg_dim=msg_dim,
            pos_em_dim=pos_em_dim,
            bias=pi_layer_bias,
            scale=pi_layer_scale,
        )
        self.modules_to_learn.append(self.pi_layer)

        hidden_layers = []
        for _ in range(num_hidden_layers):
            hidden_layers.extend([
                nn.Linear(in_features=hidden_dim, out_features=hidden_dim),
                nn.Tanh(),
            ])
        self.net = nn.Sequential(
            *hidden_layers,
            nn.Linear(in_features=hidden_dim, out_features=act_dim),
            nn.Tanh(),
        )
        self.modules_to_learn.append(self.net)

        print('#params={}'.format(self.get_num_params()))

    def _get_action(self, obs):
        x = self.pi_layer(obs=obs, prev_act=self.prev_act)
        self.prev_act = self.net(x.T)
        return self.prev_act.squeeze(0).cpu().numpy()

    def reset(self):
        self.prev_act = torch.zeros(1, self.act_dim)
        self.pi_layer.reset()

def activation_hook(module, input, output):
    """Hook to capture the activation of a module."""
    module.activation = output

@gin.configurable
class HookedPIFCSolution(BaseTorchSolution):
    def __init__(self,
                 device,
                 act_dim,
                 hidden_dim,
                 msg_dim,
                 pos_em_dim,
                 num_hidden_layers=1,
                 pi_layer_bias=True,
                 pi_layer_scale=True,
                 hook_fns = None,
        ):
        super(HookedPIFCSolution, self).__init__(device=device)
        self.act_dim = act_dim
        self.hidden_dim = hidden_dim
        self.msg_dim = msg_dim
        self.pos_em_dim = pos_em_dim
        self.prev_act = torch.zeros(1, self.act_dim)
        self.curr_step_hook_data = {'pi_layer_activations': None, 'net_activations': {}}

        self.full_hook_data = []

        self.pi_layer = HookedAttentionNeuronLayer(
            act_dim=act_dim,
            hidden_dim=hidden_dim,
            msg_dim=msg_dim,
            pos_em_dim=pos_em_dim,
            bias=pi_layer_bias,
            scale=pi_layer_scale,
            hook_fns = hook_fns['pi_layer_activations'] if hook_fns else None,
        )
        
        if hook_fns is None:
            self.hook_fns = {}
        else:
            self.hook_fns = hook_fns

        self.modules_to_learn.append(self.pi_layer)

        def hook_net(name):
            def hook_fn(module, input, output):
                output = self.hook_fns.get('net_activations', {}).get(name, lambda x: x)(output)
                self.curr_step_hook_data['net_activations'][name] = {
                    'input': input,
                    'output': output
                }
            return hook_fn

        hidden_layers = []
        for _ in range(num_hidden_layers):
            hidden_layers.extend([
                nn.Linear(in_features=hidden_dim, out_features=hidden_dim),
                nn.Tanh(),
            ])

        self.net = nn.Sequential(
            *hidden_layers,
            nn.Linear(in_features=hidden_dim, out_features=act_dim),
            nn.Tanh(),
        )
        self.modules_to_learn.append(self.net)

        for name, module in self.net.named_modules():
            if isinstance(module, nn.Linear):
                module.register_forward_hook(hook_net(name))

        print('#params={}'.format(self.get_num_params()))

    def _get_action(self, obs):
        x, self.curr_step_hook_data['pi_layer_activations'] = self.pi_layer(obs=obs, prev_act=self.prev_act)
        self.prev_act = self.net(x.T)
        self.curr_step_hook_data['act'] = self.prev_act.squeeze(0).cpu().numpy()
        self.full_hook_data.append(self.curr_step_hook_data)
        self.curr_step_hook_data = {'pi_layer_activations': None, 'net_activations': {}}
        return self.prev_act.squeeze(0).cpu().numpy()
    
    # def permute_pos_embed(self, perm_ix):
    #     self.pi_layer.permute_pos_embed(perm_ix)
    
    def permute_hidden_states(self, perm_ix):
        self.pi_layer.permute_hidden_states(perm_ix)

    def zero_hidden_states(self):
        self.pi_layer.zero_hidden_states()

    def reset(self):
        self.prev_act = torch.zeros(1, self.act_dim)
        self.pi_layer.reset()
        self.curr_step_hook_data = {'pi_layer_activations': None, 'net_activations': {}}
        self.full_hook_data = []

@gin.configurable
class PIAttentionAgent(BaseTorchSolution):
    """AttentionNeuron + AttentionAgent."""

    def __init__(self,
                 device,
                 act_dim,
                 msg_dim,
                 pos_em_dim,
                 patch_size=6,
                 stack_k=4,
                 aa_image_size=32,
                 aa_query_dim=4,
                 aa_hidden_dim=16,
                 aa_top_k=10):
        super(PIAttentionAgent, self).__init__(device)
        self.alpha = 0.
        self.attended_patch_ix = None
        self.act_dim = act_dim
        self.prev_act = torch.zeros(1, self.act_dim)
        self.hidden_dim = aa_image_size**2
        self.msg_dim = msg_dim
        self.prev_hidden = torch.zeros(self.hidden_dim, self.msg_dim)

        self.vision_pi_layer = VisionAttentionNeuronLayer(
            act_dim=act_dim,
            hidden_dim=aa_image_size**2,
            msg_dim=msg_dim,
            pos_em_dim=pos_em_dim,
            patch_size=patch_size,
            stack_k=stack_k,
        )
        self.modules_to_learn.append(self.vision_pi_layer)

        self.top_k = aa_top_k
        self.patch_centers = torch.div(torch.tensor(
            [[i, j] for i in range(aa_image_size) for j in range(aa_image_size)]
        ).float(), aa_image_size)
        self.attention = SelfAttentionMatrix(
            dim_in=self.msg_dim,
            msg_dim=aa_query_dim,
            scale=False,
        )
        self.modules_to_learn.append(self.attention)

        self.hx = None
        self.lstm_hidden_dim = aa_hidden_dim
        self.lstm = nn.LSTMCell(
            input_size=aa_top_k * 2,
            hidden_size=aa_hidden_dim,
        )
        self.modules_to_learn.append(self.lstm)

        self.output_fc = nn.Sequential(
            nn.Linear(in_features=aa_hidden_dim, out_features=act_dim),
            nn.Tanh(),
        )
        self.modules_to_learn.append(self.output_fc)

        self.mixing_fc = nn.Sequential(
            nn.Linear(
                in_features=aa_hidden_dim + self.act_dim,
                out_features=aa_hidden_dim,
            ),
            nn.Tanh(),
            nn.Linear(in_features=aa_hidden_dim, out_features=1),
            nn.Sigmoid(),
        )
        self.modules_to_learn.append(self.mixing_fc)

        print('#params={}'.format(self.get_params().size))

    def _get_action(self, obs):
        # Uncomment to confirm the agent is receiving shuffled obs.
        # import cv2
        # viz_obs = obs[0]
        # cv2.imshow('confirm', cv2.resize(viz_obs, (400, 400)))
        # cv2.waitKey(1)

        x = self.vision_pi_layer(obs=obs, prev_act=self.prev_act)
        self.attended_patch_ix = (
            self.vision_pi_layer.attention.mostly_attended_entries
        )
        x = (1 - self.alpha) * x + self.alpha * self.prev_hidden
        self.prev_hidden = x

        attention_matrix = self.attention(data_q=x, data_k=x)
        patch_importance_matrix = torch.softmax(attention_matrix, dim=-1)
        patch_importance = patch_importance_matrix.sum(dim=0)

        # Extract top k important patches
        ix = torch.argsort(patch_importance, descending=True)
        top_k_ix = ix[:self.top_k]
        centers = self.patch_centers[top_k_ix]
        centers = centers.flatten(0, -1)

        if self.hx is None:
            self.hx = (
                torch.zeros(1, self.lstm_hidden_dim),
                torch.zeros(1, self.lstm_hidden_dim),
            )
        self.hx = self.lstm(centers.unsqueeze(0), self.hx)
        output = self.output_fc(self.hx[0])
        self.prev_act = output

        self.alpha = self.mixing_fc(
            torch.cat([self.hx[0], self.prev_act], dim=-1).squeeze(0))

        return output.squeeze(0).cpu().numpy()

    def reset(self):
        self.alpha = 0.
        self.prev_act = torch.zeros(1, self.act_dim)
        self.prev_hidden = torch.zeros(self.hidden_dim, self.msg_dim)
        self.hx = None


@gin.configurable
class PuzzlePongSolution(BaseTorchSolution):
    """AttentionNeuron + Convnet."""

    def __init__(self,
                 device,
                 act_dim,
                 msg_dim,
                 pos_em_dim,
                 patch_size=6,
                 stack_k=4,
                 feat_dim=20):
        super(PuzzlePongSolution, self).__init__(device)
        self.act_dim = act_dim
        self.prev_action = None
        self.feat_dim = feat_dim
        self.msg_dim = msg_dim

        self.vision_pi_layer = VisionAttentionNeuronLayer(
            act_dim=act_dim,
            hidden_dim=feat_dim**2,
            msg_dim=msg_dim,
            pos_em_dim=pos_em_dim,
            patch_size=patch_size,
            stack_k=stack_k,
            with_learnable_ln_params=True,
            stack_dim_first=True,
        )
        self.modules_to_learn.append(self.vision_pi_layer)

        self.cnn = nn.Sequential(
            nn.Conv2d(
                in_channels=msg_dim,
                out_channels=64,
                kernel_size=(4, 4),
                stride=(2, 2),
            ),
            nn.ReLU(),
            nn.Conv2d(
                in_channels=64,
                out_channels=64,
                kernel_size=(3, 3),
                stride=(1, 1),
            ),
            nn.ReLU(),
            nn.Flatten(),
            nn.Linear(in_features=3136, out_features=512),
            nn.ReLU(),
            nn.Linear(in_features=512, out_features=act_dim),
        )
        self.modules_to_learn.append(self.cnn)

        print('#params={}'.format(self.get_params().size))

    def _get_action(self, obs):
        if self.prev_action is None:
            self.prev_action = torch.zeros(1, self.act_dim)
            self.prev_action[:, 3] = 1
        x = self.vision_pi_layer(obs=obs, prev_act=self.prev_action)
        assert x.shape == (self.feat_dim**2, self.msg_dim)

        # Reshape to input to convnet.
        x = x.reshape(self.feat_dim, self.feat_dim, self.msg_dim).unsqueeze(0)
        x = torch.relu(x.permute(0, 3, 1, 2))

        action = self.cnn(x)
        assert action.shape == (1, self.act_dim)
        action = torch.argmax(action, dim=-1)
        self.prev_action = torch.zeros(1, self.act_dim)
        self.prev_action[:, action[0]] = 1

        return action

    def reset(self):
        self.prev_action = None


================================================================================
# End of file: solutions/torch_solutions.py
================================================================================


================================================================================
# File 21/28: tasks/__init__.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/tasks/__init__.py
# File type: Python
================================================================================



================================================================================
# End of file: tasks/__init__.py
================================================================================


================================================================================
# File 22/28: tasks/atari_wrappers.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/tasks/atari_wrappers.py
# File type: Python
================================================================================

"""This code is based on
https://github.com/pfnet/pfrl/blob/master/pfrl/wrappers/atari_wrappers.py
and
https://github.com/pfnet/pfrl/blob/master/pfrl/wrappers/continuing_time_limit.py
"""

from collections import deque
import gym
import numpy as np
from gym import spaces
import cv2
cv2.ocl.setUseOpenCL(False)


class ContinuingTimeLimit(gym.Wrapper):
    """TimeLimit wrapper for continuing environments.
    This is similar gym.wrappers.TimeLimit, which sets a time limit for
    each episode, except that done=False is returned and that
    info['needs_reset'] is set to True when past the limit.
    Code that calls env.step is responsible for checking the info dict, the
    fourth returned value, and resetting the env if it has the 'needs_reset'
    key and its value is True.
    Args:
        env (gym.Env): Env to wrap.
        max_episode_steps (int): Maximum number of timesteps during an episode,
            after which the env needs a reset.
    """

    def __init__(self, env, max_episode_steps):
        super(ContinuingTimeLimit, self).__init__(env)
        self._max_episode_steps = max_episode_steps

        self._elapsed_steps = None

    def step(self, action):
        assert (
            self._elapsed_steps is not None
        ), "Cannot call env.step() before calling reset()"
        observation, reward, done, info = self.env.step(action)
        self._elapsed_steps += 1

        if self._max_episode_steps <= self._elapsed_steps:
            info["needs_reset"] = True

        return observation, reward, done, info

    def reset(self):
        self._elapsed_steps = 0
        return self.env.reset()
    
    
class NoopResetEnv(gym.Wrapper):
    def __init__(self, env, noop_max=30):
        """Sample initial states by taking random number of no-ops on reset.

        No-op is assumed to be action 0.
        """
        gym.Wrapper.__init__(self, env)
        self.noop_max = noop_max
        self.override_num_noops = None
        self.noop_action = 0
        assert env.unwrapped.get_action_meanings()[0] == "NOOP"

    def reset(self, **kwargs):
        """Do no-op action for a number of steps in [1, noop_max]."""
        self.env.reset(**kwargs)
        if self.override_num_noops is not None:
            noops = self.override_num_noops
        else:
            noops = self.unwrapped.np_random.randint(
                1, self.noop_max + 1
            )  # pylint: disable=E1101
        assert noops > 0
        obs = None
        for _ in range(noops):
            obs, _, done, info = self.env.step(self.noop_action)
            if done or info.get("needs_reset", False):
                obs = self.env.reset(**kwargs)
        return obs

    def step(self, ac):
        return self.env.step(ac)


class FireResetEnv(gym.Wrapper):
    def __init__(self, env):
        """Take action on reset for envs that are fixed until firing."""
        gym.Wrapper.__init__(self, env)
        assert env.unwrapped.get_action_meanings()[1] == "FIRE"
        assert len(env.unwrapped.get_action_meanings()) >= 3

    def reset(self, **kwargs):
        self.env.reset(**kwargs)
        obs, _, done, info = self.env.step(1)
        if done or info.get("needs_reset", False):
            self.env.reset(**kwargs)
        obs, _, done, info = self.env.step(2)
        if done or info.get("needs_reset", False):
            self.env.reset(**kwargs)
        return obs

    def step(self, ac):
        return self.env.step(ac)


class EpisodicLifeEnv(gym.Wrapper):
    def __init__(self, env):
        """Make end-of-life == end-of-episode, but only reset on true game end.

        Done by DeepMind for the DQN and co. since it helps value estimation.
        """
        gym.Wrapper.__init__(self, env)
        self.lives = 0
        self.needs_real_reset = True

    def step(self, action):
        obs, reward, done, info = self.env.step(action)
        self.needs_real_reset = done or info.get("needs_reset", False)
        # check current lives, make loss of life terminal,
        # then update lives to handle bonus lives
        lives = self.env.unwrapped.ale.lives()
        if lives < self.lives and lives > 0:
            # for Qbert sometimes we stay in lives == 0 condtion for a few
            # frames
            # so its important to keep lives > 0, so that we only reset once
            # the environment advertises done.
            done = True
        self.lives = lives
        return obs, reward, done, info

    def reset(self, **kwargs):
        """Reset only when lives are exhausted.

        This way all states are still reachable even though lives are episodic,
        and the learner need not know about any of this behind-the-scenes.
        """
        if self.needs_real_reset:
            obs = self.env.reset(**kwargs)
        else:
            # no-op step to advance from terminal/lost life state
            obs, _, _, _ = self.env.step(0)
        self.lives = self.env.unwrapped.ale.lives()
        return obs


class MaxAndSkipEnv(gym.Wrapper):
    def __init__(self, env, skip=4):
        """Return only every `skip`-th frame"""
        gym.Wrapper.__init__(self, env)
        # most recent raw observations (for max pooling across time steps)
        self._obs_buffer = np.zeros((2,) + env.observation_space.shape, dtype=np.uint8)
        self._skip = skip

    def step(self, action):
        """Repeat action, sum reward, and max over last observations."""
        total_reward = 0.0
        done = None
        for i in range(self._skip):
            obs, reward, done, info = self.env.step(action)
            if i == self._skip - 2:
                self._obs_buffer[0] = obs
            if i == self._skip - 1:
                self._obs_buffer[1] = obs
            total_reward += reward
            if done or info.get("needs_reset", False):
                break
        # Note that the observation on the done=True frame
        # doesn't matter
        max_frame = self._obs_buffer.max(axis=0)

        return max_frame, total_reward, done, info

    def reset(self, **kwargs):
        return self.env.reset(**kwargs)


class ClipRewardEnv(gym.RewardWrapper):
    def __init__(self, env):
        gym.RewardWrapper.__init__(self, env)

    def reward(self, reward):
        """Bin reward to {+1, 0, -1} by its sign."""
        return np.sign(reward)


class WarpFrame(gym.ObservationWrapper):
    def __init__(self, env, channel_order="hwc"):
        """Warp frames to 84x84 as done in the Nature paper and later work."""
        gym.ObservationWrapper.__init__(self, env)
        self.width = 84
        self.height = 84
        shape = {
            "hwc": (self.height, self.width, 1),
            "chw": (1, self.height, self.width),
        }
        self.observation_space = spaces.Box(
            low=0, high=255, shape=shape[channel_order], dtype=np.uint8
        )

    def observation(self, frame):
        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)
        frame = cv2.resize(
            frame, (self.width, self.height), interpolation=cv2.INTER_AREA
        )
        return frame.reshape(self.observation_space.low.shape)


class FrameStack(gym.Wrapper):
    def __init__(self, env, k, channel_order="hwc"):
        """Stack k last frames.

        Returns lazy array, which is much more memory efficient.

        See Also
        --------
        baselines.common.atari_wrappers.LazyFrames
        """
        gym.Wrapper.__init__(self, env)
        self.k = k
        self.frames = deque([], maxlen=k)
        self.stack_axis = {"hwc": 2, "chw": 0}[channel_order]
        orig_obs_space = env.observation_space
        low = np.repeat(orig_obs_space.low, k, axis=self.stack_axis)
        high = np.repeat(orig_obs_space.high, k, axis=self.stack_axis)
        self.observation_space = spaces.Box(
            low=low, high=high, dtype=orig_obs_space.dtype
        )

    def reset(self):
        ob = self.env.reset()
        for _ in range(self.k):
            self.frames.append(ob)
        return self._get_ob()

    def step(self, action):
        ob, reward, done, info = self.env.step(action)
        self.frames.append(ob)
        return self._get_ob(), reward, done, info

    def _get_ob(self):
        assert len(self.frames) == self.k
        return LazyFrames(list(self.frames), stack_axis=self.stack_axis)


class ScaledFloatFrame(gym.ObservationWrapper):
    """Divide frame values by 255.0 and return them as np.float32.

    Especially, when the original env.observation_space is np.uint8,
    this wrapper converts frame values into [0.0, 1.0] of dtype np.float32.
    """

    def __init__(self, env):
        assert isinstance(env.observation_space, spaces.Box)
        gym.ObservationWrapper.__init__(self, env)

        self.scale = 255.0

        orig_obs_space = env.observation_space
        self.observation_space = spaces.Box(
            low=self.observation(orig_obs_space.low),
            high=self.observation(orig_obs_space.high),
            dtype=np.float32,
        )

    def observation(self, observation):
        # careful! This undoes the memory optimization, use
        # with smaller replay buffers only.
        return np.array(observation).astype(np.float32) / self.scale


class LazyFrames(object):
    """Array-like object that lazily concat multiple frames.

    This object ensures that common frames between the observations are only
    stored once.  It exists purely to optimize memory usage which can be huge
    for DQN's 1M frames replay buffers.

    This object should only be converted to numpy array before being passed to
    the model.

    You'd not believe how complex the previous solution was.
    """

    def __init__(self, frames, stack_axis=2):
        self.stack_axis = stack_axis
        self._frames = frames

    def __array__(self, dtype=None):
        out = np.concatenate(self._frames, axis=self.stack_axis)
        if dtype is not None:
            out = out.astype(dtype)
        return out


class FlickerFrame(gym.ObservationWrapper):
    """Stochastically flicker frames."""

    def __init__(self, env):
        gym.ObservationWrapper.__init__(self, env)

    def observation(self, observation):
        if self.unwrapped.np_random.rand() < 0.5:
            return np.zeros_like(observation)
        else:
            return observation


def make_atari(env_id, max_frames=30 * 60 * 60):
    env = gym.make(env_id)
    assert "NoFrameskip" in env.spec.id
    assert isinstance(env, gym.wrappers.TimeLimit)
    # Unwrap TimeLimit wrapper because we use our own time limits
    env = env.env
    if max_frames:
        env = ContinuingTimeLimit(env, max_episode_steps=max_frames)
    env = NoopResetEnv(env, noop_max=30)
    env = MaxAndSkipEnv(env, skip=4)
    return env


def wrap_deepmind(
    env,
    episode_life=True,
    clip_rewards=True,
    frame_stack=True,
    scale=False,
    fire_reset=False,
    channel_order="chw",
    flicker=False,
    permute_obs=False,
    patch_size=6,
    rand_zero_out_ratio=0.0,
):
    """Configure environment for DeepMind-style Atari."""
    if episode_life:
        env = EpisodicLifeEnv(env)
    if fire_reset and "FIRE" in env.unwrapped.get_action_meanings():
        env = FireResetEnv(env)
    env = PermuteWarpFrame(
        env=env,
        channel_order=channel_order,
        permute_obs=permute_obs,
        rand_zero_out_ratio=rand_zero_out_ratio,
        patch_size=patch_size,
    )
    if scale:
        env = ScaledFloatFrame(env)
    if clip_rewards:
        env = ClipRewardEnv(env)
    if flicker:
        env = FlickerFrame(env)
    if frame_stack:
        env = FrameStack(env, 4, channel_order=channel_order)
    return env


class PermuteWarpFrame(gym.ObservationWrapper):
    def __init__(self,
                 env,
                 channel_order="hwc",
                 permute_obs=True,
                 rand_zero_out_ratio=0.,
                 patch_size=6):
        """Warp frames to 84x84 as done in the Nature paper and later work."""
        gym.ObservationWrapper.__init__(self, env)
        self.width = 84
        self.height = 84
        shape = {
            "hwc": (self.height, self.width, 1),
            "chw": (1, self.height, self.width),
        }
        self.observation_space = spaces.Box(
            low=0, high=255, shape=shape[channel_order], dtype=np.uint8
        )
        self.original_obs = None
        self.shuffled_obs = None
        self.gray_obs = None
        self.permute_obs = permute_obs
        self.rand_zero_out_ratio = rand_zero_out_ratio
        self.patch_size = patch_size
        self.num_patches = (84 // self.patch_size) ** 2
        self.perm_ix = np.arange(self.num_patches)
        self.zero_out_ix = np.arange(self.num_patches)
        self.np_random = np.random.RandomState(0)
        self.step_cnt = 0
        self.patch_to_keep_ix = None

    def observation(self, frame):
        self.original_obs = cv2.resize(
            frame, (self.width, self.height), interpolation=cv2.INTER_AREA
        )
        self.shuffled_obs = self.shuffle_patches(self.original_obs)
        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)
        frame = cv2.resize(
            frame, (self.width, self.height), interpolation=cv2.INTER_AREA
        )
        frame[:10] = 0   # Zero-out the score area.
        frame = self.shuffle_patches(frame)
        self.gray_obs = frame
        return frame.reshape(self.observation_space.low.shape)

    def seed(self, seed=None):
        self.np_random = np.random.RandomState(seed)
        return self.env.seed(seed)

    def reset(self, **kwargs):
        self.patch_to_keep_ix = None
        self.perm_ix = np.arange(self.num_patches)
        self.zero_out_ix = np.arange(self.num_patches)
        self.np_random.shuffle(self.zero_out_ix)
        # print(self.zero_out_ix)
        if self.permute_obs:
            self.np_random.shuffle(self.perm_ix)
        self.step_cnt = 0
        return super(PermuteWarpFrame, self).reset(**kwargs)

    def step(self, action):
        self.step_cnt += 1
        obs, reward, done, info = super(PermuteWarpFrame, self).step(action)
        return obs, reward, done, info

    def shuffle_patches(self, obs):
        shuffled_obs = np.zeros_like(obs)
        num_patches_per_dim = 84 // self.patch_size
        num_patches_to_zero_out = int(
            (num_patches_per_dim ** 2) * self.rand_zero_out_ratio)
        patch_ix_to_zero_out = self.zero_out_ix[:num_patches_to_zero_out]
        self.patch_to_keep_ix = self.zero_out_ix[num_patches_to_zero_out:]
        for pstart_r in range(num_patches_per_dim):
            for pstart_c in range(num_patches_per_dim):
                ix = pstart_r * num_patches_per_dim + pstart_c
                shuffled_ix = self.perm_ix[ix]
                spstart_r = shuffled_ix // num_patches_per_dim
                spstart_c = shuffled_ix % num_patches_per_dim
                if ix in patch_ix_to_zero_out:
                    pass
                else:
                    sr_ss = pstart_r * self.patch_size
                    sc_ss = pstart_c * self.patch_size
                    sr_ee = sr_ss + self.patch_size
                    sc_ee = sc_ss + self.patch_size
                    r_ss = spstart_r * self.patch_size
                    c_ss = spstart_c * self.patch_size
                    r_ee = r_ss + self.patch_size
                    c_ee = c_ss + self.patch_size
                    shuffled_obs[sr_ss:sr_ee, sc_ss:sc_ee] = (
                        obs[r_ss:r_ee, c_ss:c_ee]
                    )
        return shuffled_obs

    def render(self, mode='human', **kwargs):
        if mode == 'human':
            screen = np.concatenate(
                [self.original_obs, self.shuffled_obs], axis=1)
            resized_screen = cv2.resize(screen, (400, 200))[:, :, ::-1]
            cv2.imshow('Puzzle Pong', resized_screen)
            cv2.waitKey(1)
        else:
            return self.env.render(mode)


================================================================================
# End of file: tasks/atari_wrappers.py
================================================================================


================================================================================
# File 23/28: tasks/base_task.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/tasks/base_task.py
# File type: Python
================================================================================

import abc


class BaseTask(abc.ABC):
    """Base task."""

    @abc.abstractmethod
    def reset_for_rollout(self):
        raise NotImplementedError()

    @abc.abstractmethod
    def seed(self, seed=None):
        raise NotImplementedError()

    @abc.abstractmethod
    def rollout(self, solution, evaluation=False):
        raise NotImplementedError()


================================================================================
# End of file: tasks/base_task.py
================================================================================


================================================================================
# File 24/28: tasks/cartpole_env.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/tasks/cartpole_env.py
# File type: Python
================================================================================

"""
Cart pole swing-up: Original version from:
https://github.com/zuoxingdong/DeepPILCO/blob/master/cartpole_swingup.py
Modified so that done=True when x is outside of -2.4 to 2.4
Reward is also reshaped to be similar to PyBullet/roboschool version
"""

import logging
import math
import gym
from gym import spaces
from gym.utils import seeding
import numpy as np
import time
# logger = logging.getLogger(__name__)


class CartPoleSwingUpHarderEnv(gym.Env):
    metadata = {
        'render.modes': ['human', 'rgb_array'],
        'video.frames_per_second': 50
    }

    def __init__(self, simple=False, redundant_obs=False):
        self.simple = simple
        self.redundant_obs = redundant_obs
        self.g = 9.82  # gravity
        self.m_c = 0.5  # cart mass
        self.m_p = 0.5  # pendulum mass
        self.total_m = (self.m_p + self.m_c)
        self.l = 0.6  # pole's length
        self.m_p_l = (self.m_p * self.l)
        self.force_mag = 10.0
        self.dt = 0.01  # seconds between state updates
        self.b = 0.1  # friction coefficient

        self.t = 0  # timestep
        self.t_limit = 1000

        # Angle at which to fail the episode
        self.theta_threshold_radians = 12 * 2 * math.pi / 360
        self.x_threshold = 2.4

        high = np.array([
            np.finfo(np.float32).max,
            np.finfo(np.float32).max,
            np.finfo(np.float32).max,
            np.finfo(np.float32).max,
            np.finfo(np.float32).max])

        if self.redundant_obs:
            high = np.concatenate([high] * 2, axis=0)

        self.action_space = spaces.Box(-1.0, 1.0, shape=(1,))
        self.observation_space = spaces.Box(-high, high)

        self.np_random = None
        self.seed()
        self.viewer = None
        self.state = None
        self.prev_state = None

    def seed(self, seed=None):
        self.np_random, seed = seeding.np_random(seed)
        return [seed]

    def step(self, action):
        # Valid action
        action = np.clip(action, -1.0, 1.0)[0]
        action *= self.force_mag

        state = self.state
        x, x_dot, theta, theta_dot = state

        s = math.sin(theta)
        c = math.cos(theta)

        xdot_update = (
            (-2 * self.m_p_l * (theta_dot ** 2) * s +
             3 * self.m_p * self.g * s * c +
             4 * action - 4 * self.b * x_dot) /
            (4 * self.total_m - 3 * self.m_p * c ** 2)
        )
        thetadot_update = (
            (-3 * self.m_p_l * (theta_dot ** 2) * s * c +
             6 * self.total_m * self.g * s +
             6 * (action - self.b * x_dot) * c) /
            (4 * self.l * self.total_m - 3 * self.m_p_l * c ** 2)
        )

        x = x + x_dot * self.dt
        theta = theta + theta_dot * self.dt

        x_dot = x_dot + xdot_update * self.dt
        theta_dot = theta_dot + thetadot_update * self.dt

        self.state = (x, x_dot, theta, theta_dot)

        done = False
        if x < -self.x_threshold or x > self.x_threshold:
            done = True

        self.t += 1

        if self.t >= self.t_limit:
            done = True

        reward_theta = (np.cos(theta) + 1.0) / 2.0
        reward_x = np.cos((x / self.x_threshold) * (np.pi / 2.0))

        reward = reward_theta * reward_x

        prev_x, prev_x_dot, prev_theta, prev_theta_dot = self.prev_state

        c = np.cos(theta)
        s = np.sin(theta)

        # prev_c = np.cos(prev_theta)
        # prev_s = np.sin(prev_theta)

        # print("debug", theta-prev_theta, theta, prev_theta)

        # obs = np.array([x, (x-prev_x)/self.dt, c, s, (theta-prev_theta)/self.dt])
        obs = np.array([x, x_dot, c, s, theta_dot])
        # obs = np.array([x, x_dot, theta, theta_dot])
        if self.redundant_obs:
            obs = np.concatenate([obs] * 2, axis=0)

        self.prev_state = self.state

        return obs, reward, done, {}

    def reset(self):
        if self.simple:
            self.state = self.np_random.normal(
                loc=np.array([0.0, 0.0, np.pi, 0.0]),
                scale=np.array([0.2, 0.2, 0.2, 0.2]),
            )
        else:
            [rand_x, rand_x_dot, rand_theta, rand_theta_dot] = np.multiply(
                self.np_random.rand(4) * 2 - 1,
                [self.x_threshold, 10., np.pi / 2., 10.])
            self.state = np.array(
                [rand_x, rand_x_dot, np.pi + rand_theta, rand_theta_dot])
        self.prev_state = self.state
        self.t = 0  # timestep
        x, x_dot, theta, theta_dot = self.state
        obs = np.array([x, x_dot, np.cos(theta), np.sin(theta),
                        theta_dot])  # set zero for init differences
        # obs = np.array([x, x_dot, theta, theta_dot])  # set zero for init
        # differences
        if self.redundant_obs:
            obs = np.concatenate([obs] * 2, axis=0)
        return obs

    def render(self, mode='human', close=False, override_state=None):
        if close:
            if self.viewer is not None:
                self.viewer.close()
                self.viewer = None
            return

        if self.state is None: return None

        screen_width = 300
        screen_height = 300  # before was 400

        world_width = 5  # max visible position of cart
        scale = screen_width / world_width
        carty = screen_height / 2  # TOP OF CART
        polewidth = 6.0
        polelen = scale * self.l  # 0.6 or self.l
        cartwidth = 40.0
        cartheight = 20.0

        extra_color = 0.0
        if override_state != None:
            extra_color = 0.75

        if self.viewer is None:
            from gym.envs.classic_control import rendering
            self.viewer = rendering.Viewer(screen_width, screen_height)

            # real cart
            l, r, t, b = -cartwidth / 2, cartwidth / 2, cartheight / 2, -cartheight / 2
            self.cart = rendering.FilledPolygon(
                [(l, b), (l, t), (r, t), (r, b)])
            self.carttrans = rendering.Transform()
            self.cart.add_attr(self.carttrans)
            self.cart.set_color(1.0, extra_color, extra_color)
            self.viewer.add_geom(self.cart)

            l, r, t, b = -polewidth / 2, polewidth / 2, polelen - polewidth / 2, -polewidth / 2
            self.pole = rendering.FilledPolygon(
                [(l, b), (l, t), (r, t), (r, b)])
            self.pole.set_color(extra_color, extra_color, 1)
            self.poletrans = rendering.Transform(translation=(0, 0))
            self.pole.add_attr(self.poletrans)
            self.pole.add_attr(self.carttrans)
            self.viewer.add_geom(self.pole)

            self.axle = rendering.make_circle(polewidth / 2)
            self.axle.add_attr(self.poletrans)
            self.axle.add_attr(self.carttrans)
            self.axle.set_color(0.1, 1, 1)
            self.viewer.add_geom(self.axle)

            # Make another circle on the top of the pole
            self.pole_bob = rendering.make_circle(polewidth / 2)
            self.pole_bob_trans = rendering.Transform()
            self.pole_bob.add_attr(self.pole_bob_trans)
            self.pole_bob.add_attr(self.poletrans)
            self.pole_bob.add_attr(self.carttrans)
            self.pole_bob.set_color(0, 0, 0)
            self.viewer.add_geom(self.pole_bob)

            self.wheel_l = rendering.make_circle(cartheight / 4)
            self.wheel_r = rendering.make_circle(cartheight / 4)
            self.wheeltrans_l = rendering.Transform(
                translation=(-cartwidth / 2, -cartheight / 2))
            self.wheeltrans_r = rendering.Transform(
                translation=(cartwidth / 2, -cartheight / 2))
            self.wheel_l.add_attr(self.wheeltrans_l)
            self.wheel_l.add_attr(self.carttrans)
            self.wheel_r.add_attr(self.wheeltrans_r)
            self.wheel_r.add_attr(self.carttrans)
            self.wheel_l.set_color(0, 0, 0)  # Black, (B, G, R)
            self.wheel_r.set_color(0, 0, 0)  # Black, (B, G, R)
            self.viewer.add_geom(self.wheel_l)
            self.viewer.add_geom(self.wheel_r)

            # dream cart
            l, r, t, b = -cartwidth / 2, cartwidth / 2, cartheight / 2, -cartheight / 2
            dream_cart = rendering.PolyLine([(l, b), (l, t), (r, t), (r, b)],
                                            True)
            self.dream_carttrans = rendering.Transform()
            dream_cart.add_attr(self.dream_carttrans)
            dream_cart.set_color(0.25, 0.25, 0.25)
            self.viewer.add_geom(dream_cart)

            l, r, t, b = -polewidth / 2, polewidth / 2, polelen - polewidth / 2, -polewidth / 2
            dream_pole = rendering.PolyLine([(l, b), (l, t), (r, t), (r, b)],
                                            True)
            dream_pole.set_color(0.25, 0.25, 0.25)
            self.dream_poletrans = rendering.Transform(translation=(0, 0))
            dream_pole.add_attr(self.dream_poletrans)
            dream_pole.add_attr(self.dream_carttrans)
            self.viewer.add_geom(dream_pole)

            self.dream_axle = rendering.make_circle(polewidth / 2, filled=False)
            self.dream_axle.add_attr(self.dream_poletrans)
            self.dream_axle.add_attr(self.dream_carttrans)
            self.dream_axle.set_color(0.1, .25, .25)
            self.viewer.add_geom(self.dream_axle)

            # Make another circle on the top of the pole
            self.dream_pole_bob = rendering.make_circle(polewidth / 2,
                                                        filled=False)
            self.dream_pole_bob_trans = rendering.Transform()
            self.dream_pole_bob.add_attr(self.dream_pole_bob_trans)
            self.dream_pole_bob.add_attr(self.dream_poletrans)
            self.dream_pole_bob.add_attr(self.dream_carttrans)
            self.dream_pole_bob.set_color(0.25, 0.25, 0.25)
            self.viewer.add_geom(self.dream_pole_bob)

            self.dream_wheel_l = rendering.make_circle(
                cartheight / 4, filled=False)
            self.dream_wheel_r = rendering.make_circle(
                cartheight / 4, filled=False)
            self.dream_wheeltrans_l = rendering.Transform(
                translation=(-cartwidth / 2, -cartheight / 2))
            self.dream_wheeltrans_r = rendering.Transform(
                translation=(cartwidth / 2, -cartheight / 2))
            self.dream_wheel_l.add_attr(self.dream_wheeltrans_l)
            self.dream_wheel_l.add_attr(self.dream_carttrans)
            self.dream_wheel_r.add_attr(self.dream_wheeltrans_r)
            self.dream_wheel_r.add_attr(self.dream_carttrans)
            self.dream_wheel_l.set_color(0.25, 0.25, 0.25)
            self.dream_wheel_r.set_color(0.25, 0.25, 0.25)
            self.viewer.add_geom(self.dream_wheel_l)
            self.viewer.add_geom(self.dream_wheel_r)

            # others:

            self.track = rendering.Line(
                (screen_width / 2 - self.x_threshold * scale,
                 carty - cartheight / 2 - cartheight / 4),
                (screen_width / 2 + self.x_threshold * scale,
                 carty - cartheight / 2 - cartheight / 4)
            )
            self.track.set_color(0, 0, 0)
            self.viewer.add_geom(self.track)

        x = self.state
        dream_x = self.state
        if override_state != None:
            dream_x = override_state

        # flash when we peek
        self.cart.set_color(1.0, extra_color, extra_color)
        self.pole.set_color(extra_color, extra_color, 1)

        # real cart
        cartx = x[0] * scale + screen_width / 2.0  # MIDDLE OF CART
        self.carttrans.set_translation(cartx, carty)
        self.poletrans.set_rotation(x[2])
        self.pole_bob_trans.set_translation(-self.l * np.sin(x[2]),
                                            self.l * np.cos(x[2]))

        # dream cart
        dream_cartx = dream_x[0] * scale + screen_width / 2.0  # MIDDLE OF CART
        self.dream_carttrans.set_translation(dream_cartx, carty)
        self.dream_poletrans.set_rotation(dream_x[2])
        self.dream_pole_bob_trans.set_translation(-self.l * np.sin(dream_x[2]),
                                                  self.l * np.cos(dream_x[2]))

        return self.viewer.render(return_rgb_array=mode == 'rgb_array')

================================================================================
# End of file: tasks/cartpole_env.py
================================================================================


================================================================================
# File 25/28: tasks/rl_tasks.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/tasks/rl_tasks.py
# File type: Python
================================================================================

from collections import deque
import cv2
import os
import gin
import gym
import numpy as np
import time
import pybullet_envs
from tasks import atari_wrappers
from tasks.base_task import BaseTask
from tasks.cartpole_env import CartPoleSwingUpHarderEnv
from warnings import warn


class RLTask(BaseTask):
    """RL base task."""

    def __init__(self, v=True, render_mode='human'):
        self.env = None
        self.render_mode = render_mode
        self.step_cnt = 0
        self.eval_mode = False
        self.verbose = v

    def reset_for_rollout(self):
        self.step_cnt = 0

    def seed(self, seed=None):
        return self.env.seed(seed)

    def modify_obs(self, obs):
        return obs

    def modify_action(self, act):
        return act

    def modify_reward(self, reward, done):
        return reward

    def modify_done(self, reward, done):
        return done

    def show_gui(self):
        if self.render_mode is not None and hasattr(self.env, 'render'):
            return self.env.render(self.render_mode)

    def close(self):
        self.env.close()

    def rollout(self, solution, evaluation=False):
        self.eval_mode = evaluation
        self.reset_for_rollout()
        solution.reset()
        if hasattr(self, 'register_solution'):
            self.register_solution(solution)

        if self.render_mode is not None and hasattr(self.env, 'render'):
            frames = []
            permutations = []
        start_time = time.time()

        obs = self.env.reset()
        obs = self.modify_obs(obs)
        if self.render_mode is not None and hasattr(self.env, 'render'):
            frames.append(self.show_gui())
            permutations = [self.perm_ix.copy()]
        else:
            self.show_gui()
        ep_reward = 0
        done = False
        while not done:
            action = solution.get_action(obs)
            action = self.modify_action(action)
            obs, reward, done, info = self.env.step(action)
            obs = self.modify_obs(obs)
            reward = self.modify_reward(reward, done)
            done = self.modify_done(reward, done)

            self.step_cnt += 1
            ep_reward += reward
            if self.render_mode is not None and hasattr(self.env, 'render'):
                permutations.append(self.perm_ix.copy())
                frames.append(self.show_gui())
            else:
                self.show_gui()

        time_cost = time.time() - start_time
        if self.verbose:
            print('Rollout time={0:.2f}s, steps={1}, reward={2:.2f}'.format(
                time_cost, self.step_cnt, ep_reward))

        return (
            ep_reward, frames, permutations
            if self.render_mode is not None and hasattr(self.env, 'render') 
            else ep_reward
        )

@gin.configurable
class PyBulletTask(RLTask):

    def __init__(self, env_name, shuffle_on_reset=False, render_mode = 'human', v=True):
        super(PyBulletTask, self).__init__(v=v, render_mode=render_mode)
        self.env_name = env_name
        self.shuffle_on_reset = shuffle_on_reset
        self.perm_ix = 0
        self.env = gym.make(self.env_name)
        self.perm_ix = np.arange(self.env.observation_space.shape[0])
        if self.render_mode is not None and hasattr(self.env, 'render'):
            self.env.render(self.render_mode)

    def reset_for_rollout(self):
        self.perm_ix = np.arange(self.env.observation_space.shape[0])
        if self.shuffle_on_reset:
            np.random.shuffle(self.perm_ix)
        if self.verbose:
            print('perm_ix: {}'.format(self.perm_ix))
        return super(PyBulletTask, self).reset_for_rollout()

    def modify_reward(self, reward, done):
        if self.eval_mode:
            return reward
        else:
            return max(0, sum(self.env.rewards[1:]))

    def modify_obs(self, obs):
        return obs[self.perm_ix]

    def show_gui(self):
        if self.render_mode is not None:
            time.sleep(0.01)
            return super(PyBulletTask, self).show_gui()


@gin.configurable
class CartPoleSwingUpTask(RLTask):
    """Car-pole swing up task."""

    def __init__(self,
                 shuffle_on_reset=False,
                 render_mode = 'human',
                 v=True,
                 num_noise_channels=0):
        super(CartPoleSwingUpTask, self).__init__(v=v, render_mode = 'human')
        self.shuffle_on_reset = shuffle_on_reset
        self.perm_ix = 0
        self.render_mode = render_mode
        self.env = CartPoleSwingUpHarderEnv()
        self.perm_ix = np.arange(self.env.observation_space.shape[0])
        self.noise_std = 0.1
        self.num_noise_channels = num_noise_channels
        self.rnd = np.random.RandomState(seed=0)

    def seed(self, seed=None):
        self.rnd = np.random.RandomState(seed=seed)
        return super(CartPoleSwingUpTask, self).seed(seed)

    def reset_for_rollout(self):
        self.perm_ix = np.arange(self.env.observation_space.shape[0])
        if self.shuffle_on_reset:
            self.rnd.shuffle(self.perm_ix)
        if self.verbose:
            print('perm_ix: {}'.format(self.perm_ix))
        return super(CartPoleSwingUpTask, self).reset_for_rollout()

    def modify_obs(self, obs):
        obs = obs[self.perm_ix]
        if self.num_noise_channels > 0:
            noise_obs = self.rnd.randn(self.num_noise_channels) * self.noise_std
            obs = np.concatenate([obs, noise_obs], axis=0)
        return obs

@gin.configurable
class CartPoleSwingUpRandPermuteTask(CartPoleSwingUpTask):

    def __init__(self,
                 shuffle_on_reset=False,
                 render_mode = 'human',
                 v=True,
                 permute_freq=None,
                 shuffle_hs_on_permute = False,
                 zero_hs_on_permute=False,
                 num_noise_channels=0):
        super(CartPoleSwingUpRandPermuteTask, self).__init__(
            shuffle_on_reset=shuffle_on_reset, 
            v=v, 
            render_mode = 'human'
        )

        self.shuffle_on_reset = shuffle_on_reset
        self.perm_ix = 0
        self.render_mode = render_mode
        self.env = CartPoleSwingUpHarderEnv()
        self.perm_ix = np.arange(self.env.observation_space.shape[0])
        self.noise_std = 0.1
        self.num_noise_channels = num_noise_channels
        self.rnd = np.random.RandomState(seed=0)
        # Maintain a separate random state for perturbations.
        # This is to ensure that the perturbations are consistent across
        # different runs, while the permutation is randomized.
        self.perturb_rnd = np.random.RandomState(seed=12345)
        self.permute_freq = permute_freq
        self.shuffle_hs_on_permute = shuffle_hs_on_permute
        self.zero_hs_on_permute = zero_hs_on_permute

        if self.permute_freq is None:
            warn("permute_freq is None. I don't know why you would be using this environment THEN, but okay.")


    def seed(self, seed=None):
        self.perturb_rnd = np.random.RandomState(seed=seed + 12345)
        return super(CartPoleSwingUpRandPermuteTask, self).seed(seed)

    def modify_obs(self, obs):
        if self.permute_freq is not None and (self.step_cnt + 1) % self.permute_freq == 0:
            self.perturb_rnd.shuffle(self.perm_ix)
            if self.verbose:
                print('New perm_ix: {} Step: {}'.format(self.perm_ix, self.step_cnt + 1))
        return super(CartPoleSwingUpRandPermuteTask, self).modify_obs(obs)
    

    def rollout(self, solution, evaluation=False):
        self.eval_mode = evaluation
        self.reset_for_rollout()
        solution.reset()
        if hasattr(self, 'register_solution'):
            self.register_solution(solution)

        if self.render_mode is not None and hasattr(self.env, 'render'):
            frames = []
            permutations = []
        start_time = time.time()

        obs = self.env.reset()
        obs = self.modify_obs(obs)
        if self.render_mode is not None and hasattr(self.env, 'render'):
            frames.append(self.show_gui())
            permutations = [self.perm_ix.copy()]
        else:
            self.show_gui()
        ep_reward = 0
        done = False
        while not done:
            
            action = solution.get_action(obs)
            action = self.modify_action(action)

            obs, reward, done, info = self.env.step(action)

            obs = self.modify_obs(obs)
            if self.permute_freq is not None and self.shuffle_hs_on_permute and (self.step_cnt + 1) % self.permute_freq == 0:
                # print(f"Old Hidden State: {solution.pi_layer.hx}")
                solution.permute_hidden_states(self.perm_ix)
                # solution.permute_pos_embed(self.perm_ix)
                print('Permuting hidden states at step: {}'.format(self.step_cnt + 1))
                # print(f"New Hidden State: {solution.pi_layer.hx}")
            elif self.permute_freq is not None and self.zero_hs_on_permute and (self.step_cnt + 1) % self.permute_freq == 0:
                # print(f"Old Hidden State: {solution.pi_layer.hx}")
                solution.zero_hidden_states()
                print('Zeroing hidden states at step: {}'.format(self.step_cnt + 1))
                # print(f"New Hidden State: {solution.pi_layer.hx}")

            reward = self.modify_reward(reward, done)
            done = self.modify_done(reward, done)
            self.step_cnt += 1

            ep_reward += reward
            if self.render_mode is not None and hasattr(self.env, 'render'):
                permutations.append(self.perm_ix.copy())
                frames.append(self.show_gui())
            else:
                self.show_gui()

        time_cost = time.time() - start_time
        if self.verbose:
            print('Rollout time={0:.2f}s, steps={1}, reward={2:.2f}'.format(
                time_cost, self.step_cnt, ep_reward))

        return (
            ep_reward, frames, permutations
            if self.render_mode is not None and hasattr(self.env, 'render') 
            else ep_reward
        )

@gin.configurable
class CarRacingTask(RLTask):
    """Gym CarRacing-v0 task."""

    def __init__(self,
                 bkg=None,
                 permute_obs=False,
                 patch_size=6,
                 out_of_track_cap=20,
                 stack_k_frames=0,
                 render_mode = 'human'):
        super(CarRacingTask, self).__init__()

        self.permute_obs = permute_obs
        self.patch_size = patch_size
        self.bkg = bkg
        bkg_file = os.path.join(
            os.path.dirname(__file__), 'bkg/{}.jpg'.format(self.bkg))
        if os.path.exists(bkg_file):
            self.bkg = cv2.resize(cv2.imread(bkg_file), (96, 96))[:, :, ::-1]
        else:
            self.bkg = None
        self.original_obs = None
        self.shuffled_obs = None
        self.obs_perm_ix = np.arange((96 // self.patch_size)**2)
        self.rnd = np.random.RandomState(seed=0)
        self.solution = None
        
        self.render_mode = render_mode
        self._max_steps = 1000
        self._neg_reward_cnt = 0
        self._neg_reward_cap = out_of_track_cap
        self._action_high = np.array([1., 1., 1.])
        self._action_low = np.array([-1., 0., 0.])
        self.env = gym.make('CarRacing-v0')
        self.stack_k_frames = stack_k_frames
        if self.stack_k_frames > 0:
            self.obs_stack = deque(maxlen=self.stack_k_frames)
            
    def seed(self, seed=None):
        self.rnd = np.random.RandomState(seed=seed)
        return super(CarRacingTask, self).seed(seed)

    def modify_action(self, act):
        return (act * (self._action_high - self._action_low) / 2. +
                (self._action_high + self._action_low) / 2.)

    def reset_for_rollout(self):
        self.original_obs = None
        self.shuffled_obs = None
        self.obs_perm_ix = np.arange((96 // self.patch_size)**2)
        if self.permute_obs:
            self.rnd.shuffle(self.obs_perm_ix)
        if self.stack_k_frames > 0:
            self.obs_stack = deque(maxlen=self.stack_k_frames)
        self._neg_reward_cnt = 0
        return super(CarRacingTask, self).reset_for_rollout()

    def modify_done(self, reward, done):
        if self.eval_mode:
            return done
        if reward < 0:
            self._neg_reward_cnt += 1
        else:
            self._neg_reward_cnt = 0
        too_many_out_of_tracks = 0 < self._neg_reward_cap < self._neg_reward_cnt
        too_many_steps = 0 < self._max_steps <= self.step_cnt
        return done or too_many_out_of_tracks or too_many_steps

    def shuffle_obs_patches(self, obs):
        shuffled_obs = np.zeros_like(obs)
        p_size = self.patch_size
        num_patches_per_dim = 96 // p_size
        for pstart_r in range(num_patches_per_dim):
            for pstart_c in range(num_patches_per_dim):
                ix = pstart_r * num_patches_per_dim + pstart_c
                shuffled_ix = self.obs_perm_ix[ix]
                spstart_r = shuffled_ix // num_patches_per_dim
                spstart_c = shuffled_ix % num_patches_per_dim
                shuffled_obs[
                    pstart_r * p_size:(pstart_r + 1) * p_size,
                    pstart_c * p_size:(pstart_c + 1) * p_size
                ] = obs[
                    spstart_r * p_size:(spstart_r + 1) * p_size,
                    spstart_c * p_size:(spstart_c + 1) * p_size
                ]
        return shuffled_obs

    def modify_obs(self, obs):
        if self.bkg is not None:
            mask = ((obs[:, :, 0] == 102) &
                    (obs[:, :, 1] == 204) &
                    (obs[:, :, 2] == 102))
            mask |= ((obs[:, :, 0] == 102) &
                     (obs[:, :, 1] == 230) &
                     (obs[:, :, 2] == 102))
            obs[:, :, 0][mask] = self.bkg[:, :, 0][mask]
            obs[:, :, 1][mask] = self.bkg[:, :, 1][mask]
            obs[:, :, 2][mask] = self.bkg[:, :, 2][mask]

        # Keep original and shuffled screens for visualization.
        self.original_obs = obs
        self.shuffled_obs = obs

        if self.permute_obs:
            self.shuffled_obs = self.shuffle_obs_patches(obs)

        if self.stack_k_frames > 0:
            gray_obs = cv2.cvtColor(obs, cv2.COLOR_RGB2GRAY)
            gray_obs[-12:] = 0  # Zero-out the indicator.
            if self.permute_obs:
                gray_obs = self.shuffle_obs_patches(gray_obs)
            while len(self.obs_stack) < self.stack_k_frames:
                self.obs_stack.append(gray_obs)
            self.obs_stack.append(gray_obs)
            obs = np.stack(self.obs_stack)
            return obs
        else:
            return self.shuffled_obs

    def register_solution(self, solution):
        self.solution = solution

    def plot_white_patches(self, img, white_patch_ix):
        white_patch = np.ones([self.patch_size, self.patch_size, 3]) * 255
        num_patches = 96 // self.patch_size
        for ix in white_patch_ix:
            row_ix = ix // num_patches
            col_ix = ix % num_patches
            row_ss = row_ix * self.patch_size
            col_ss = col_ix * self.patch_size
            row_ee = row_ss + self.patch_size
            col_ee = col_ss + self.patch_size
            img[row_ss:row_ee, col_ss:col_ee] = (
                    0.5 * img[row_ss:row_ee, col_ss:col_ee] + 0.5 * white_patch)
        return img.astype(np.uint8)

    def show_gui(self):
        if self.render_mode is not None and hasattr(self.env, 'render'):
            if hasattr(self.solution, 'attended_patch_ix'):
                attended_patch_ix = self.solution.attended_patch_ix
            else:
                attended_patch_ix = None

            obs = self.shuffled_obs.copy()
            if attended_patch_ix is not None:
                obs = self.plot_white_patches(
                    img=obs, white_patch_ix=attended_patch_ix)

            org_obs = self.original_obs.copy()
            if attended_patch_ix is not None:
                org_obs = self.plot_white_patches(
                    img=org_obs,
                    white_patch_ix=[self.obs_perm_ix[i]
                                    for i in attended_patch_ix])

            img = np.concatenate([org_obs, obs], axis=1)
            img = cv2.resize(img, (800, 400))[:, :, ::-1]
            cv2.imshow('render', img)
            cv2.waitKey(1)
        return super(CarRacingTask, self).show_gui()


@gin.configurable
class PuzzlePongTask(RLTask):
    """Atari Pong."""

    def __init__(self,
                 permute_obs=False,
                 patch_size=6,
                 occlusion_ratio=0.,
                 render_mode = 'human'):
        super(PuzzlePongTask, self).__init__()
        self.render_mode = render_mode
        self.occlusion_ratio = occlusion_ratio
        self.env = atari_wrappers.wrap_deepmind(
            env=atari_wrappers.make_atari(env_id='PongNoFrameskip-v4'),
            episode_life=False,
            clip_rewards=False,
            flicker=False,
            frame_stack=True,
            permute_obs=permute_obs,
            patch_size=patch_size,
            rand_zero_out_ratio=occlusion_ratio,
        )

    def modify_obs(self, obs):
        # Convert from LazyFrames to numpy array.
        obs = np.array(obs)
        # Uncomment to confirm the env is indeed passing shuffled obs.
        # cv2.imshow('Pong debug', cv2.resize(obs[0], (200, 200)))
        # cv2.waitKey(1)
        if 0. < self.occlusion_ratio < 1.:
            return {'obs': obs, 'patches_to_use': self.env.patch_to_keep_ix}
        else:
            return obs


================================================================================
# End of file: tasks/rl_tasks.py
================================================================================


================================================================================
# File 26/28: test.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/test.py
# File type: Python
================================================================================


#!/usr/bin/env python3
"""
Script to collect all .py and .ipynb files from a directory tree
and output them to a single text file with directory annotations.
"""

import os
import json
import argparse
from pathlib import Path
from datetime import datetime


def read_ipynb_content(filepath):
    """Read and extract code from Jupyter notebook files."""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            notebook = json.load(f)
        
        code_cells = []
        for cell in notebook.get('cells', []):
            if cell.get('cell_type') == 'code':
                source = cell.get('source', [])
                if isinstance(source, list):
                    code_cells.append(''.join(source))
                else:
                    code_cells.append(source)
            elif cell.get('cell_type') == 'markdown':
                source = cell.get('source', [])
                if isinstance(source, list):
                    markdown_text = ''.join(source)
                else:
                    markdown_text = source
                # Add markdown cells as comments
                commented_markdown = '\n'.join(f'# {line}' for line in markdown_text.split('\n'))
                code_cells.append(f'\n# [Markdown Cell]\n{commented_markdown}\n')
        
        return '\n\n'.join(code_cells)
    except Exception as e:
        return f"# Error reading notebook: {str(e)}"


def read_py_content(filepath):
    """Read content from Python files."""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        return f"# Error reading file: {str(e)}"


def collect_python_files(root_dir, output_file, include_hidden=False):
    """
    Collect all .py and .ipynb files and write them to output file.
    
    Args:
        root_dir: Root directory to search for files
        output_file: Path to output text file
        include_hidden: Whether to include files in hidden directories
    """
    root_path = Path(root_dir).resolve()
    output_path = Path(output_file).resolve()
    
    # Collect all relevant files
    py_files = []
    ipynb_files = []
    
    for dirpath, dirnames, filenames in os.walk(root_path):
        # Skip hidden directories if requested
        if not include_hidden:
            dirnames[:] = [d for d in dirnames if not d.startswith('.')]
        
        dir_path = Path(dirpath)
        
        # Skip if we're in a hidden directory
        if not include_hidden and any(part.startswith('.') for part in dir_path.parts):
            continue
        
        for filename in filenames:
            if filename.endswith('.py'):
                py_files.append(dir_path / filename)
            elif filename.endswith('.ipynb') and not filename.startswith('.'):
                ipynb_files.append(dir_path / filename)
    
    # Sort files for consistent output
    all_files = sorted(py_files + ipynb_files)
    
    # Write to output file
    with open(output_path, 'w', encoding='utf-8') as out:
        # Write header
        out.write(f"# Python and Jupyter Notebook Files Export\n")
        out.write(f"# Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        out.write(f"# Root directory: {root_path}\n")
        out.write(f"# Total files: {len(all_files)}\n")
        out.write("=" * 80 + "\n\n")
        
        # Write file contents
        for i, filepath in enumerate(all_files, 1):
            # Get relative path from root directory
            rel_path = filepath.relative_to(root_path)
            
            # Write file header
            out.write(f"\n{'=' * 80}\n")
            out.write(f"# File {i}/{len(all_files)}: {rel_path}\n")
            out.write(f"# Full path: {filepath}\n")
            out.write(f"# File type: {'Python' if filepath.suffix == '.py' else 'Jupyter Notebook'}\n")
            out.write(f"{'=' * 80}\n\n")
            
            # Write file content
            if filepath.suffix == '.py':
                content = read_py_content(filepath)
            else:  # .ipynb
                content = read_ipynb_content(filepath)
            
            out.write(content)
            out.write(f"\n\n{'=' * 80}\n")
            out.write(f"# End of file: {rel_path}\n")
            out.write(f"{'=' * 80}\n\n")
    
    print(f"Successfully exported {len(all_files)} files to {output_path}")
    print(f"  - Python files: {len(py_files)}")
    print(f"  - Jupyter notebooks: {len(ipynb_files)}")


def main():
    parser = argparse.ArgumentParser(
        description='Export all .py and .ipynb files from a directory to a single text file'
    )
    parser.add_argument(
        'directory',
        help='Directory to search for Python and Jupyter notebook files'
    )
    parser.add_argument(
        '-o', '--output',
        default='python_files_export.txt',
        help='Output text file name (default: python_files_export.txt)'
    )
    parser.add_argument(
        '--include-hidden',
        action='store_true',
        help='Include files in hidden directories (starting with .)'
    )
    
    args = parser.parse_args()
    
    # Validate directory
    if not os.path.isdir(args.directory):
        print(f"Error: '{args.directory}' is not a valid directory")
        return 1
    
    # Run the collection
    try:
        collect_python_files(args.directory, args.output, args.include_hidden)
        return 0
    except Exception as e:
        print(f"Error: {str(e)}")
        return 1


if __name__ == "__main__":
    exit(main())

================================================================================
# End of file: test.py
================================================================================


================================================================================
# File 27/28: train_agent.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/train_agent.py
# File type: Python
================================================================================

import argparse
import gin
import os
import util
import numpy as np
import multiprocessing as mp
import cma


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--config', help='Path to config file.')
    parser.add_argument(
        '--log-dir', help='Directory of logs.')
    parser.add_argument(
        '--load-model', help='Path to model file.')
    parser.add_argument(
        '--population-size', help='Population size.', type=int, default=256)
    parser.add_argument(
        '--num-workers', help='Number of workers.', type=int, default=-1)
    parser.add_argument(
        '--num-gpus', help='Number of GPUs for training.', type=int, default=0)
    parser.add_argument(
        '--max-iter', help='Max training iterations.', type=int, default=10000)
    parser.add_argument(
        '--save-interval', help='Model saving period.', type=int, default=100)
    parser.add_argument(
        '--seed', help='Random seed for evaluation.', type=int, default=42)
    parser.add_argument(
        '--reps', help='Number of rollouts for fitness.', type=int, default=16)
    parser.add_argument(
        '--init-sigma', help='Initial std.', type=float, default=0.1)
    config, _ = parser.parse_known_args()
    return config


solution = None
task = None


def worker_init(config_file, device_type, num_devices):
    global task, solution
    gin.parse_config_file(config_file)
    task = util.create_task(logger=None)
    worker_id = int(mp.current_process().name.split('-')[-1])
    device = '{}:{}'.format(device_type, (worker_id - 1) % num_devices)
    solution = util.create_solution(device=device)


def get_fitness(params):
    global task, solution
    params, task_seed, num_rollouts = params
    task.seed(task_seed)
    solution.set_params(params)
    scores = []
    for _ in range(num_rollouts):
        scores.append(task.rollout(solution=solution, evaluation=False))
    return np.mean(scores)


def save_params(solver, solution, model_path):
    solution.set_params(solver.result.xfavorite)
    solution.save(model_path)


def main(config):
    logger = util.create_logger(name='train_log', log_dir=config.log_dir)
    if not os.path.exists(config.log_dir):
        os.makedirs(config.log_dir, exist_ok=True)
    util.save_config(config.log_dir, config.config)
    logger.info('Logs and models will be save in {}.'.format(config.log_dir))

    rnd = np.random.RandomState(seed=config.seed)
    solution = util.create_solution(device='cpu:0')
    num_params = solution.get_num_params()
    if config.load_model is not None:
        solution.load(config.load_model)
        print('Loaded model from {}'.format(config.load_model))
        init_params = solution.get_params()
    else:
        init_params = None
    solver = cma.CMAEvolutionStrategy(
        x0=np.zeros(num_params) if init_params is None else init_params,
        sigma0=config.init_sigma,
        inopts={
            'popsize': config.population_size,
            'seed': config.seed if config.seed > 0 else 42,
            'randn': np.random.randn,
        },
    )

    best_so_far = -float('Inf')
    ii32 = np.iinfo(np.int32)
    repeats = [config.reps] * config.population_size

    device_type = 'cpu' if args.num_gpus <= 0 else 'cuda'
    num_devices = mp.cpu_count() if args.num_gpus <= 0 else args.num_gpus
    with mp.get_context('spawn').Pool(
            initializer=worker_init,
            initargs=(args.config, device_type, num_devices),
            processes=config.num_workers,
    ) as pool:
        for n_iter in range(config.max_iter):
            params_set = solver.ask()
            task_seeds = [rnd.randint(0, ii32.max)] * config.population_size
            fitnesses = []
            ss = 0
            while ss < config.population_size:
                ee = ss + min(config.num_workers, config.population_size - ss)
                fitnesses.append(
                    pool.map(func=get_fitness,
                             iterable=zip(params_set[ss:ee],
                                          task_seeds[ss:ee],
                                          repeats[ss:ee]))
                )
                ss = ee
            fitnesses = np.concatenate(fitnesses)
            if isinstance(solver, cma.CMAEvolutionStrategy):
                # CMA minimizes.
                solver.tell(params_set, -fitnesses)
            else:
                solver.tell(fitnesses)
            logger.info(
                'Iter={0}, '
                'max={1:.2f}, avg={2:.2f}, min={3:.2f}, std={4:.2f}'.format(
                    n_iter, np.max(fitnesses), np.mean(fitnesses),
                    np.min(fitnesses), np.std(fitnesses)))

            best_fitness = max(fitnesses)
            if best_fitness > best_so_far:
                best_so_far = best_fitness
                model_path = os.path.join(config.log_dir, 'best.npz')
                save_params(
                    solver=solver, solution=solution, model_path=model_path)
                logger.info('Best model updated, score={}'.format(best_fitness))

            if (n_iter + 1) % config.save_interval == 0:
                model_path = os.path.join(
                    config.log_dir, 'iter_{}.npz'.format(n_iter + 1))
                save_params(
                    solver=solver, solution=solution, model_path=model_path)


if __name__ == '__main__':
    args = parse_args()
    if args.num_workers < 0:
        args.num_workers = mp.cpu_count()
    gin.parse_config_file(args.config)
    if args.num_gpus <= 0:
        os.environ['CUDA_VISIBLE_DEVICES'] = "-1"
    main(args)


================================================================================
# End of file: train_agent.py
================================================================================


================================================================================
# File 28/28: util.py
# Full path: /Users/n00bcak/programming/AttentionNeuron/util.py
# File type: Python
================================================================================

import gin
import logging
import os
import shutil
from solutions.base_solution import BaseSolution
from tasks.base_task import BaseTask


@gin.configurable
def create_task(task_loader, **kwargs):
    """Load and return a task."""

    if isinstance(task_loader, BaseTask):
        return task_loader
    else:
        return task_loader(**kwargs)


@gin.configurable
def create_solution(solution_loader, **kwargs):
    """Create a solution."""

    if isinstance(solution_loader, BaseSolution):
        return solution_loader
    else:
        return solution_loader(**kwargs)


def save_config(log_dir, config):
    """Create a log directory and save config in it.

    Create a log directory and save configurations.

    Args:
        log_dir: str. Path of the log directory.
        config: str. Path to configuration file.
    """

    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
    shutil.copy(config, os.path.join(log_dir, 'config.gin'))


def create_logger(name, log_dir=None, debug=False):
    """Create a logger.

    Create a logger that logs to log_dir.

    Args:
        name: str. Name of the logger.
        log_dir: str. Path to log directory.
        debug: bool. Whether to set debug level logging.
    Returns:
        logging.logger.
    """

    if log_dir and not os.path.exists(log_dir):
        os.makedirs(log_dir)
    log_format = '%(asctime)s %(process)d [%(levelname)s] %(message)s'
    logging.basicConfig(level=logging.DEBUG if debug else logging.INFO,
                        format=log_format)
    logger = logging.getLogger(name)
    if log_dir:
        log_file = os.path.join(log_dir, '{}.txt'.format(name))
        file_hdl = logging.FileHandler(log_file)
        formatter = logging.Formatter(fmt=log_format)
        file_hdl.setFormatter(formatter)
        logger.addHandler(file_hdl)
    return logger


================================================================================
# End of file: util.py
================================================================================

